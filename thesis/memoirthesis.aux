\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*{\memsetcounter}[2]{}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\par \penalty \@M \unhbox \voidb@x \hbox {}\hfill {\nag@@warning@vi  \bfseries  Page}\par \penalty \@M }
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vii}{section*.3}}
\@writefile{lot}{\par \penalty \@M \textbf  {{\scshape  Table} \hfill Page}\par \penalty \@M }
\citation{choi2012}
\citation{grepory2010}
\citation{alex2008}
\citation{wang2012}
\citation{cnn}
\citation{karpathy2014}
\citation{simonyan2014}
\citation{Tran2015}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{ix}{section*.4}}
\citation{Tran2015}
\citation{Tran2015}
\@writefile{lof}{\par \penalty \@M \textbf  {{\scshape  Figure} \hfill Page}\par \penalty \@M }
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Introduction}{1}{chapter.1}}
\newlabel{chap:intro}{{\M@TitleReference {1}{Introduction}}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background}{1}{section.1.1}}
\newlabel{sec:intro_sec01}{{\M@TitleReference {1.1}{Background}}{1}{Background}{section.1.1}{}}
\citation{patron2010}
\citation{Gemeren2015}
\citation{narayan2014}
\citation{choi2012}
\citation{patron2010}
\citation{Gemeren2015}
\citation{hog}
\citation{hof}
\citation{narayan2014}
\citation{choi2012}
\citation{bov}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Illustration of some challenges of video analysis. }}{3}{figure.1.1}}
\newlabel{fig:challenges}{{\M@TitleReference {1.1}{Illustration of some challenges of video analysis. }}{3}{Illustration of some challenges of video analysis. }{figure.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Project Goals}{3}{section.1.2}}
\newlabel{sec:intro_sec02}{{\M@TitleReference {1.2}{Project Goals}}{3}{Project Goals}{section.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Contributions}{3}{section.1.3}}
\newlabel{sec:intro_sec03}{{\M@TitleReference {1.3}{Contributions}}{3}{Contributions}{section.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Outline}{4}{section.1.4}}
\newlabel{sec:intro_outline}{{\M@TitleReference {1.4}{Outline}}{4}{Outline}{section.1.4}{}}
\citation{patron2010}
\citation{Gemeren2015}
\citation{narayan2014}
\citation{choi2012}
\citation{Ji2013}
\citation{Ng2015}
\citation{Tran2015}
\citation{alex2008}
\citation{grepory2010}
\citation{karpathy2014}
\citation{simonyan2014}
\citation{choi2012}
\citation{choi2012}
\citation{bov}
\citation{choi2012}
\citation{choi2012}
\citation{Gemeren2015}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Related Work}{5}{chapter.2}}
\newlabel{chap2}{{\M@TitleReference {2}{Related Work}}{5}{Related Work}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Architectures of Interaction video analysis related works}{5}{section.2.1}}
\newlabel{2_1}{{\M@TitleReference {2.1}{Architectures of Interaction video analysis related works}}{5}{Architectures of Interaction video analysis related works}{section.2.1}{}}
\citation{patron2010}
\citation{Gemeren2015}
\citation{yimeng}
\citation{yu}
\citation{lowe1999}
\citation{lowe2004}
\citation{hog}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The hierarchical activity recognition model and an example. Reprinted from \cite  {choi2012}.}}{6}{figure.2.1}}
\newlabel{fig:hierA}{{\M@TitleReference {2.1}{The hierarchical activity recognition model and an example. Reprinted from \cite  {choi2012}.}}{6}{The hierarchical activity recognition model and an example. Reprinted from \cite {choi2012}}{figure.2.1}{}}
\citation{grepory2010}
\citation{paul2007}
\citation{alex2008}
\citation{wang2012}
\citation{wang2013}
\citation{lowe1999}
\citation{lowe2004}
\citation{grepory2010}
\citation{paul2007}
\citation{grepory2010}
\citation{grepory2010}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Hand-crafted Feature Descriptor}{7}{section.2.2}}
\newlabel{2_2}{{\M@TitleReference {2.2}{Hand-crafted Feature Descriptor}}{7}{Hand-crafted Feature Descriptor}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}3D-SIFT Feature Descriptor}{7}{subsection.2.2.1}}
\newlabel{2_2_1}{{\M@TitleReference {2.2.1}{3D-SIFT Feature Descriptor}}{7}{3D-SIFT Feature Descriptor}{subsection.2.2.1}{}}
\citation{alex2008}
\citation{alex2008}
\citation{alex2008}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The SIFT descriptor. The left image shows the 2D SIFT descriptor. The center image shows how multiple 2D SIFT descriptor could be used on a video without modification to the original method. The right image shows the 3D SIFT descriptor with its 3D sub-volumes, each sub-volume is accumulated into its own sub-histogram. These histograms are what makes up the final descriptor. Reprinted from \cite  {grepory2010}.}}{8}{figure.2.2}}
\newlabel{fig:3DSIFT}{{\M@TitleReference {2.2}{The SIFT descriptor. The left image shows the 2D SIFT descriptor. The center image shows how multiple 2D SIFT descriptor could be used on a video without modification to the original method. The right image shows the 3D SIFT descriptor with its 3D sub-volumes, each sub-volume is accumulated into its own sub-histogram. These histograms are what makes up the final descriptor. Reprinted from \cite  {grepory2010}.}}{8}{The SIFT descriptor. The left image shows the 2D SIFT descriptor. The center image shows how multiple 2D SIFT descriptor could be used on a video without modification to the original method. The right image shows the 3D SIFT descriptor with its 3D sub-volumes, each sub-volume is accumulated into its own sub-histogram. These histograms are what makes up the final descriptor. Reprinted from \cite {grepory2010}}{figure.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}3D-HOG Feature descriptor}{8}{subsection.2.2.2}}
\newlabel{2_2_2}{{\M@TitleReference {2.2.2}{3D-HOG Feature descriptor}}{8}{3D-HOG Feature descriptor}{subsection.2.2.2}{}}
\citation{wang2012}
\citation{wang2013}
\citation{wang2012}
\citation{wang2013}
\citation{hog}
\citation{hof}
\citation{hof}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces  Overview of 3D-HOG descriptor computation; (a) the support region around a point of interest is divided into a grid of gradient orientation histograms; (b) each histogram is computed over a grid of mean gradients; (c) each gradient orientation is quantized using regular polyhedrons; (d) each mean gradient is computed using integral videos. Reprinted from \cite  {alex2008}.}}{9}{figure.2.3}}
\newlabel{fig:3DHOG}{{\M@TitleReference {2.3}{ Overview of 3D-HOG descriptor computation; (a) the support region around a point of interest is divided into a grid of gradient orientation histograms; (b) each histogram is computed over a grid of mean gradients; (c) each gradient orientation is quantized using regular polyhedrons; (d) each mean gradient is computed using integral videos. Reprinted from \cite  {alex2008}.}}{9}{ Overview of 3D-HOG descriptor computation; (a) the support region around a point of interest is divided into a grid of gradient orientation histograms; (b) each histogram is computed over a grid of mean gradients; (c) each gradient orientation is quantized using regular polyhedrons; (d) each mean gradient is computed using integral videos. Reprinted from \cite {alex2008}}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Improved Dense Trajectories feature descriptor}{9}{subsection.2.2.3}}
\newlabel{2_2_3}{{\M@TitleReference {2.2.3}{Improved Dense Trajectories feature descriptor}}{9}{Improved Dense Trajectories feature descriptor}{subsection.2.2.3}{}}
\citation{wang2012}
\citation{wang2012}
\citation{wang2013}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Illustration of DT algorithm to extract and characterize dense trajectories. Left: Feature points are densely sampled on a grid for each spatial scale. Middle: Tracking is carried out in the corresponding spatial scale for L frames by median filtering in a dense optical flow field. Right: The trajectory shape is represented by relative point coordinates, and the descriptors (HOG, HOF, MBH) are computed along the trajectory in a \(N * N\) pixels neighbourhood, which is divided into \(n\sigma * n\sigma * n\tau \) cells. Reprinted from \cite  {wang2012}.}}{10}{figure.2.4}}
\newlabel{fig:DT}{{\M@TitleReference {2.4}{Illustration of DT algorithm to extract and characterize dense trajectories. Left: Feature points are densely sampled on a grid for each spatial scale. Middle: Tracking is carried out in the corresponding spatial scale for L frames by median filtering in a dense optical flow field. Right: The trajectory shape is represented by relative point coordinates, and the descriptors (HOG, HOF, MBH) are computed along the trajectory in a \(N * N\) pixels neighbourhood, which is divided into \(n\sigma * n\sigma * n\tau \) cells. Reprinted from \cite  {wang2012}.}}{10}{Illustration of DT algorithm to extract and characterize dense trajectories. Left: Feature points are densely sampled on a grid for each spatial scale. Middle: Tracking is carried out in the corresponding spatial scale for L frames by median filtering in a dense optical flow field. Right: The trajectory shape is represented by relative point coordinates, and the descriptors (HOG, HOF, MBH) are computed along the trajectory in a \(N * N\) pixels neighbourhood, which is divided into \(n\sigma * n\sigma * n\tau \) cells. Reprinted from \cite {wang2012}}{figure.2.4}{}}
\citation{cnn}
\citation{kaiming}
\citation{cnn}
\citation{cnn}
\citation{cnn}
\citation{ning2005}
\citation{karpathy2014}
\citation{simonyan2014}
\citation{3dcnn_1}
\citation{Ji2013}
\citation{Tran2015}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Deep Learning Based Feature Descriptor}{11}{section.2.3}}
\newlabel{2_3}{{\M@TitleReference {2.3}{Deep Learning Based Feature Descriptor}}{11}{Deep Learning Based Feature Descriptor}{section.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces The architecture of a CNN example: LeNet5. Reprinted from \cite  {cnn}.}}{12}{figure.2.5}}
\newlabel{fig:cnn}{{\M@TitleReference {2.5}{The architecture of a CNN example: LeNet5. Reprinted from \cite  {cnn}.}}{12}{The architecture of a CNN example: LeNet5. Reprinted from \cite {cnn}}{figure.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The intuitive illustration of convolution over image.}}{12}{figure.2.6}}
\newlabel{fig:conv}{{\M@TitleReference {2.6}{The intuitive illustration of convolution over image.}}{12}{The intuitive illustration of convolution over image}{figure.2.6}{}}
\citation{karpathy2014}
\citation{karpathy2014}
\citation{kriz2012}
\citation{karpathy2014}
\citation{karpathy2014}
\citation{karpathy2014}
\citation{simonyan2014}
\citation{karpathy2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Spatial-Temporal CNNs feature descriptor}{13}{subsection.2.3.1}}
\newlabel{2_3_1}{{\M@TitleReference {2.3.1}{Spatial-Temporal CNNs feature descriptor}}{13}{Spatial-Temporal CNNs feature descriptor}{subsection.2.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Two-Stream ConvNet feature descriptor}{13}{subsection.2.3.2}}
\newlabel{2_3_2}{{\M@TitleReference {2.3.2}{Two-Stream ConvNet feature descriptor}}{13}{Two-Stream ConvNet feature descriptor}{subsection.2.3.2}{}}
\citation{simonyan2014}
\citation{simonyan2014}
\citation{Ji2013}
\citation{Tran2015}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Explored approaches for fusing information over temporal dimension through the network. Red, green and blue boxes indicate convolutional, normalization and pooling layers respectively. In the Slow Fusion model, the depicted columns share parameters. Reprinted from \cite  {karpathy2014}.}}{14}{figure.2.7}}
\newlabel{fig:STCNNs}{{\M@TitleReference {2.7}{Explored approaches for fusing information over temporal dimension through the network. Red, green and blue boxes indicate convolutional, normalization and pooling layers respectively. In the Slow Fusion model, the depicted columns share parameters. Reprinted from \cite  {karpathy2014}.}}{14}{Explored approaches for fusing information over temporal dimension through the network. Red, green and blue boxes indicate convolutional, normalization and pooling layers respectively. In the Slow Fusion model, the depicted columns share parameters. Reprinted from \cite {karpathy2014}}{figure.2.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces The architecture of Two Stream ConvNet. Reprinted from \cite  {simonyan2014}.}}{14}{figure.2.8}}
\newlabel{fig:tsconvnet_1}{{\M@TitleReference {2.8}{The architecture of Two Stream ConvNet. Reprinted from \cite  {simonyan2014}.}}{14}{The architecture of Two Stream ConvNet. Reprinted from \cite {simonyan2014}}{figure.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}3D ConvNet feature descriptor}{14}{subsection.2.3.3}}
\newlabel{2_3_3}{{\M@TitleReference {2.3.3}{3D ConvNet feature descriptor}}{14}{3D ConvNet feature descriptor}{subsection.2.3.3}{}}
\citation{Tran2015}
\citation{zeiler2014}
\citation{Tran2015}
\citation{Tran2015}
\citation{Tran2015}
\citation{Tran2015}
\citation{Tran2015}
\citation{Tran2015}
\citation{kth}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces 2D and 3D convolution operations. a) Applying 2D convolution on an image results in an image. b) Applying 2D convolution on a video volume (multiple frames as multiple channels) also results in an image. c) Applying 3D convolution on a video volume results in another volume, preserving temporal information of the input signal. Reprinted from \cite  {Tran2015}.}}{15}{figure.2.9}}
\newlabel{fig:3DConv}{{\M@TitleReference {2.9}{2D and 3D convolution operations. a) Applying 2D convolution on an image results in an image. b) Applying 2D convolution on a video volume (multiple frames as multiple channels) also results in an image. c) Applying 3D convolution on a video volume results in another volume, preserving temporal information of the input signal. Reprinted from \cite  {Tran2015}.}}{15}{2D and 3D convolution operations. a) Applying 2D convolution on an image results in an image. b) Applying 2D convolution on a video volume (multiple frames as multiple channels) also results in an image. c) Applying 3D convolution on a video volume results in another volume, preserving temporal information of the input signal. Reprinted from \cite {Tran2015}}{figure.2.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces The architecture of C3D. C3D has 8 convolution, 5 max-pooling, and 2 full connected layers, followed by a softmax output layer. All 3D convolution kernels are \(3 \times 3 \times 3\) with stride 1 in both spatial and temporal dimensions. Number of filters are denoted in each box. The 3D pooling layers are denoted from pool1 to pool5. All pooling kernels are \(2 \times 2 \times 2\) except for pool1 is \(1 \times 2 \times 2\). Each fully connected layer has 4096 output units. Reprinted from \cite  {Tran2015}.}}{15}{figure.2.10}}
\newlabel{fig:3DConvNet}{{\M@TitleReference {2.10}{The architecture of C3D. C3D has 8 convolution, 5 max-pooling, and 2 full connected layers, followed by a softmax output layer. All 3D convolution kernels are \(3 \times 3 \times 3\) with stride 1 in both spatial and temporal dimensions. Number of filters are denoted in each box. The 3D pooling layers are denoted from pool1 to pool5. All pooling kernels are \(2 \times 2 \times 2\) except for pool1 is \(1 \times 2 \times 2\). Each fully connected layer has 4096 output units. Reprinted from \cite  {Tran2015}.}}{15}{The architecture of C3D. C3D has 8 convolution, 5 max-pooling, and 2 full connected layers, followed by a softmax output layer. All 3D convolution kernels are \(3 \times 3 \times 3\) with stride 1 in both spatial and temporal dimensions. Number of filters are denoted in each box. The 3D pooling layers are denoted from pool1 to pool5. All pooling kernels are \(2 \times 2 \times 2\) except for pool1 is \(1 \times 2 \times 2\). Each fully connected layer has 4096 output units. Reprinted from \cite {Tran2015}}{figure.2.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Visualization of C3D model. Interestingly, C3D captures appearance for the first few frames but thereafter only attends to salient motion. Reprinted from \cite  {Tran2015}.}}{15}{figure.2.11}}
\newlabel{fig:3DConvNetV}{{\M@TitleReference {2.11}{Visualization of C3D model. Interestingly, C3D captures appearance for the first few frames but thereafter only attends to salient motion. Reprinted from \cite  {Tran2015}.}}{15}{Visualization of C3D model. Interestingly, C3D captures appearance for the first few frames but thereafter only attends to salient motion. Reprinted from \cite {Tran2015}}{figure.2.11}{}}
\citation{ucf101}
\citation{aslan}
\citation{activitynet200}
\citation{kth}
\citation{marszalek09}
\citation{ucf101}
\citation{activitynet200}
\citation{ut2010}
\citation{shakefive2}
\citation{m2i_tju}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Datasets}{16}{section.2.4}}
\newlabel{2_4}{{\M@TitleReference {2.4}{Datasets}}{16}{Datasets}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}List of human activity video datasets}{16}{subsection.2.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces List of human action video datasets}}{17}{table.2.1}}
\newlabel{table:action_datasets}{{\M@TitleReference {2.1}{List of human action video datasets}}{17}{List of human action video datasets}{table.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces List of human interaction video datasets}}{18}{table.2.2}}
\newlabel{table:interaction_datasets}{{\M@TitleReference {2.2}{List of human interaction video datasets}}{18}{List of human interaction video datasets}{table.2.2}{}}
\citation{patron2010}
\citation{narayan2014}
\citation{choi2012}
\citation{narayan2014}
\citation{patron2010}
\citation{choi2012}
\citation{patron2010}
\citation{Ji2013}
\citation{Tran2015}
\citation{simonyan2014}
\citation{Ng2015}
\citation{grepory2010}
\citation{alex2008}
\citation{paul2007}
\citation{wang2012}
\citation{wang2013}
\citation{ut2010}
\citation{shakefive2}
\citation{m2i_tju}
\citation{ucf101}
\citation{activitynet200}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Architecture}{19}{chapter.3}}
\newlabel{chap3}{{\M@TitleReference {3}{Architecture}}{19}{Architecture}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Overall Framework}{19}{section.3.1}}
\newlabel{3_1}{{\M@TitleReference {3.1}{Overall Framework}}{19}{Overall Framework}{section.3.1}{}}
\citation{choi2012}
\citation{patron2010}
\citation{choi2012}
\citation{patron2010}
\citation{inria_person}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Overall framework. }}{20}{figure.3.1}}
\newlabel{fig:overall_arch}{{\M@TitleReference {3.1}{Overall framework. }}{20}{Overall framework. }{figure.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Person Detection}{20}{section.3.2}}
\newlabel{3_2}{{\M@TitleReference {3.2}{Person Detection}}{20}{Person Detection}{section.3.2}{}}
\citation{Tran2015}
\citation{simonyan2014}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Illustration of Person detection }}{21}{figure.3.2}}
\newlabel{fig:person_detection}{{\M@TitleReference {3.2}{Illustration of Person detection }}{21}{Illustration of Person detection }{figure.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Feature Descriptors}{21}{section.3.3}}
\newlabel{3_3}{{\M@TitleReference {3.3}{Feature Descriptors}}{21}{Feature Descriptors}{section.3.3}{}}
\citation{Tran2015}
\citation{simonyan2014}
\citation{inria_person}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Overall Architecture of 3D-ConvNet. }}{22}{figure.3.3}}
\newlabel{fig:c3d}{{\M@TitleReference {3.3}{Overall Architecture of 3D-ConvNet. }}{22}{Overall Architecture of 3D-ConvNet. }{figure.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}3D-ConvNet}{22}{subsection.3.3.1}}
\newlabel{3_3_1}{{\M@TitleReference {3.3.1}{3D-ConvNet}}{22}{3D-ConvNet}{subsection.3.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Two-Stream ConvNet}{22}{subsection.3.3.2}}
\newlabel{3_3_2}{{\M@TitleReference {3.3.2}{Two-Stream ConvNet}}{22}{Two-Stream ConvNet}{subsection.3.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Training}{22}{section.3.4}}
\newlabel{3_4}{{\M@TitleReference {3.4}{Training}}{22}{Training}{section.3.4}{}}
\citation{ut2010}
\citation{shakefive2}
\citation{m2i_tju}
\citation{ucf101}
\citation{activitynet200}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Overall Architecture of Two-Stream ConvNet. }}{23}{figure.3.4}}
\newlabel{fig:tsconvnet}{{\M@TitleReference {3.4}{Overall Architecture of Two-Stream ConvNet. }}{23}{Overall Architecture of Two-Stream ConvNet. }{figure.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Train Person Detection Network}{23}{subsection.3.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Train 3D-ConvNet}{23}{subsection.3.4.2}}
\citation{ut2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Train The SVM Classifier}{24}{subsection.3.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Testing}{24}{section.3.5}}
\newlabel{3_5}{{\M@TitleReference {3.5}{Testing}}{24}{Testing}{section.3.5}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Design}{25}{chapter.4}}
\newlabel{chap4}{{\M@TitleReference {4}{Design}}{25}{Design}{chapter.4}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {5}Experimental Results}{27}{chapter.5}}
\newlabel{chap5}{{\M@TitleReference {5}{Experimental Results}}{27}{Experimental Results}{chapter.5}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {6}Conclusion}{29}{chapter.6}}
\newlabel{chap6}{{\M@TitleReference {6}{Conclusion}}{29}{Conclusion}{chapter.6}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {appendix}{\chapternumberline {A}Appendix A}{31}{appendix.A}}
\newlabel{app:app01}{{\M@TitleReference {A}{Appendix A}}{31}{Appendix A}{appendix.A}{}}
\bibstyle{siam}
\bibdata{thesisbiblio}
\bibcite{3dcnn_1}{{1}{}{{}}{{}}}
\bibcite{choi2012}{{2}{}{{}}{{}}}
\bibcite{hog}{{3}{}{{}}{{}}}
\bibcite{inria_person}{{4}{}{{}}{{}}}
\bibcite{hof}{{5}{}{{}}{{}}}
\bibcite{bov}{{6}{}{{}}{{}}}
\bibcite{grepory2010}{{7}{}{{}}{{}}}
\bibcite{kaiming}{{8}{}{{}}{{}}}
\bibcite{activitynet200}{{9}{}{{}}{{}}}
\bibcite{Ji2013}{{10}{}{{}}{{}}}
\bibcite{karpathy2014}{{11}{}{{}}{{}}}
\bibcite{alex2008}{{12}{}{{}}{{}}}
\bibcite{yu}{{13}{}{{}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{33}{section*.6}}
\bibcite{kriz2012}{{14}{}{{}}{{}}}
\bibcite{cnn}{{15}{}{{}}{{}}}
\bibcite{lowe1999}{{16}{}{{}}{{}}}
\bibcite{lowe2004}{{17}{}{{}}{{}}}
\bibcite{marszalek09}{{18}{}{{}}{{}}}
\bibcite{narayan2014}{{19}{}{{}}{{}}}
\bibcite{Ng2015}{{20}{}{{}}{{}}}
\bibcite{ning2005}{{21}{}{{}}{{}}}
\bibcite{aslan}{{22}{}{{}}{{}}}
\bibcite{patron2010}{{23}{}{{}}{{}}}
\bibcite{ut2010}{{24}{}{{}}{{}}}
\bibcite{kth}{{25}{}{{}}{{}}}
\bibcite{paul2007}{{26}{}{{}}{{}}}
\bibcite{simonyan2014}{{27}{}{{}}{{}}}
\bibcite{ucf101}{{28}{}{{}}{{}}}
\bibcite{Tran2015}{{29}{}{{}}{{}}}
\bibcite{Gemeren2015}{{30}{}{{}}{{}}}
\bibcite{shakefive2}{{31}{}{{}}{{}}}
\bibcite{wang2012}{{32}{}{{}}{{}}}
\bibcite{wang2013}{{33}{}{{}}{{}}}
\bibcite{m2i_tju}{{34}{}{{}}{{}}}
\bibcite{zeiler2014}{{35}{}{{}}{{}}}
\bibcite{yimeng}{{36}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\memsetcounter{lastsheet}{48}
\memsetcounter{lastpage}{36}
