Sat Jun 10 13:25:43 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq1, epoch0, step: 0, training: 0.25, loss_tr: 1.82288, loss_t: 1.89854, testing: 0.166667, t2y: 0.666667
seq1, epoch0, step: 10, training: 0.0625, loss_tr: 2.10271, loss_t: 1.80443, testing: 0.166667, t2y: 0.333333
seq1, epoch0, step: 20, training: 0.25, loss_tr: 2.36933, loss_t: 1.78319, testing: 0.222222, t2y: 0.666667
seq1, epoch0, step: 30, training: 0.375, loss_tr: 2.38391, loss_t: 1.58939, testing: 0.222222, t2y: 0.5
seq1, epoch0, step: 40, training: 0.625, loss_tr: 1.97549, loss_t: 1.45062, testing: 0.333333, t2y: 0.5
seq1, epoch0, step: 50, training: 0.8125, loss_tr: 1.55399, loss_t: 1.19483, testing: 0.333333, t2y: 0.666667
seq1, epoch0, step: 60, training: 0.625, loss_tr: 1.43389, loss_t: 1.10185, testing: 0.5, t2y: 0.833333
seq1, epoch0, step: 70, training: 0.8125, loss_tr: 1.25877, loss_t: 0.963587, testing: 0.611111, t2y: 0.833333
seq1, epoch1, step: 80, training: 0.6875, loss_tr: 1.19384, loss_t: 0.847774, testing: 0.666667, t2y: 1
seq1, epoch1, step: 90, training: 0.9375, loss_tr: 0.902748, loss_t: 0.704828, testing: 0.722222, t2y: 1
seq1, epoch1, step: 100, training: 0.8125, loss_tr: 1.03071, loss_t: 0.609757, testing: 0.777778, t2y: 1
seq1, epoch1, step: 110, training: 0.875, loss_tr: 0.895611, loss_t: 0.566064, testing: 0.888889, t2y: 0.833333
seq1, epoch1, step: 120, training: 0.875, loss_tr: 0.89404, loss_t: 0.494551, testing: 0.944444, t2y: 1
seq1, epoch1, step: 130, training: 0.75, loss_tr: 0.739608, loss_t: 0.542963, testing: 0.833333, t2y: 0.833333
seq1, epoch1, step: 140, training: 0.875, loss_tr: 0.660589, loss_t: 0.474798, testing: 0.833333, t2y: 1
seq1, epoch1, step: 150, training: 0.75, loss_tr: 0.653901, loss_t: 0.495127, testing: 0.777778, t2y: 1
seq1, epoch2, step: 160, training: 0.8125, loss_tr: 0.563291, loss_t: 0.399079, testing: 0.833333, t2y: 1
seq1, epoch2, step: 170, training: 1, loss_tr: 0.485002, loss_t: 0.347378, testing: 0.888889, t2y: 1
seq1, epoch2, step: 180, training: 0.9375, loss_tr: 0.388411, loss_t: 0.279778, testing: 0.888889, t2y: 1
seq1, epoch2, step: 190, training: 0.9375, loss_tr: 0.306384, loss_t: 0.25917, testing: 0.888889, t2y: 1
seq1, epoch2, step: 200, training: 0.9375, loss_tr: 0.293914, loss_t: 0.232822, testing: 0.888889, t2y: 1
seq1, epoch2, step: 210, training: 0.875, loss_tr: 0.403857, loss_t: 0.244801, testing: 0.888889, t2y: 1
seq1, epoch2, step: 220, training: 0.875, loss_tr: 0.469813, loss_t: 0.176315, testing: 0.944444, t2y: 1
seq1, epoch2, step: 230, training: 0.875, loss_tr: 0.507847, loss_t: 0.213554, testing: 0.888889, t2y: 1
seq1, epoch3, step: 240, training: 0.9375, loss_tr: 0.36999, loss_t: 0.142854, testing: 0.944444, t2y: 1
seq1, epoch3, step: 250, training: 1, loss_tr: 0.29993, loss_t: 0.154078, testing: 0.944444, t2y: 1
seq1, epoch3, step: 260, training: 1, loss_tr: 0.218145, loss_t: 0.0899818, testing: 1, t2y: 1
seq1, epoch3, step: 270, training: 1, loss_tr: 0.179392, loss_t: 0.110381, testing: 1, t2y: 1
seq1, epoch3, step: 280, training: 0.9375, loss_tr: 0.136728, loss_t: 0.0873329, testing: 1, t2y: 1
seq1, epoch3, step: 290, training: 1, loss_tr: 0.12794, loss_t: 0.11456, testing: 1, t2y: 1
seq1, epoch3, step: 300, training: 0.9375, loss_tr: 0.111831, loss_t: 0.0809994, testing: 1, t2y: 1
seq1, epoch3, step: 310, training: 1, loss_tr: 0.0739307, loss_t: 0.0723701, testing: 1, t2y: 1
seq1, epoch4, step: 320, training: 1, loss_tr: 0.0722073, loss_t: 0.0397485, testing: 1, t2y: 1
seq1, epoch4, step: 330, training: 1, loss_tr: 0.0898166, loss_t: 0.0385478, testing: 1, t2y: 1
seq1, epoch4, step: 340, training: 0.875, loss_tr: 0.170037, loss_t: 0.0406361, testing: 1, t2y: 1
seq1, epoch4, step: 350, training: 0.9375, loss_tr: 0.169388, loss_t: 0.0543904, testing: 1, t2y: 1
seq1, epoch4, step: 360, training: 1, loss_tr: 0.135458, loss_t: 0.0464961, testing: 1, t2y: 1
seq1, epoch4, step: 370, training: 1, loss_tr: 0.0649121, loss_t: 0.0568704, testing: 1, t2y: 1
seq1, epoch4, step: 380, training: 1, loss_tr: 0.1219, loss_t: 0.0312747, testing: 1, t2y: 1
seq1, epoch4, step: 390, training: 1, loss_tr: 0.127535, loss_t: 0.0566567, testing: 1, t2y: 1
seq1, epoch5, step: 400, training: 1, loss_tr: 0.105113, loss_t: 0.0566851, testing: 1, t2y: 1
seq1, epoch5, step: 410, training: 1, loss_tr: 0.0397349, loss_t: 0.0575623, testing: 1, t2y: 1
seq1, epoch5, step: 420, training: 1, loss_tr: 0.0376977, loss_t: 0.0769003, testing: 0.944444, t2y: 1
seq1, epoch5, step: 430, training: 1, loss_tr: 0.0420259, loss_t: 0.0597724, testing: 0.944444, t2y: 1
seq1, epoch5, step: 440, training: 1, loss_tr: 0.0416141, loss_t: 0.0784303, testing: 0.944444, t2y: 1
seq1, epoch5, step: 450, training: 1, loss_tr: 0.0491902, loss_t: 0.0360898, testing: 1, t2y: 1
seq1, epoch5, step: 460, training: 1, loss_tr: 0.0553791, loss_t: 0.0327115, testing: 1, t2y: 1
seq1, epoch5, step: 470, training: 1, loss_tr: 0.0571245, loss_t: 0.0107496, testing: 1, t2y: 1
seq1, epoch6, step: 480, training: 1, loss_tr: 0.0542126, loss_t: 0.00994787, testing: 1, t2y: 1
seq1, epoch6, step: 490, training: 1, loss_tr: 0.0702369, loss_t: 0.0119489, testing: 1, t2y: 1
seq1, epoch6, step: 500, training: 1, loss_tr: 0.0721888, loss_t: 0.00974521, testing: 1, t2y: 1
seq1, epoch6, step: 510, training: 1, loss_tr: 0.0596422, loss_t: 0.00761817, testing: 1, t2y: 1
 
****************************************
current sequence is 2
****************************************
seq2, epoch0, step: 0, training: 0.1875, loss_tr: 2.2166, loss_t: 1.91463, testing: 0, t2y: 0.166667
seq2, epoch0, step: 10, training: 0.1875, loss_tr: 2.19404, loss_t: 1.9503, testing: 0.0555556, t2y: 0.333333
seq2, epoch0, step: 20, training: 0.5, loss_tr: 2.12294, loss_t: 1.81363, testing: 0.166667, t2y: 0.5
seq2, epoch0, step: 30, training: 0.375, loss_tr: 1.95532, loss_t: 1.67228, testing: 0.277778, t2y: 0.5
seq2, epoch0, step: 40, training: 0.75, loss_tr: 1.5928, loss_t: 1.38702, testing: 0.388889, t2y: 0.666667
seq2, epoch0, step: 50, training: 0.6875, loss_tr: 1.26842, loss_t: 1.25622, testing: 0.444444, t2y: 0.833333
seq2, epoch0, step: 60, training: 0.6875, loss_tr: 1.14504, loss_t: 1.13836, testing: 0.444444, t2y: 0.666667
seq2, epoch0, step: 70, training: 0.875, loss_tr: 1.24061, loss_t: 1.0629, testing: 0.5, t2y: 0.833333
seq2, epoch1, step: 80, training: 1, loss_tr: 1.18582, loss_t: 1.00485, testing: 0.5, t2y: 0.833333
seq2, epoch1, step: 90, training: 0.875, loss_tr: 1.04993, loss_t: 0.881318, testing: 0.611111, t2y: 1
seq2, epoch1, step: 100, training: 0.875, loss_tr: 0.898098, loss_t: 0.822537, testing: 0.555556, t2y: 0.833333
seq2, epoch1, step: 110, training: 1, loss_tr: 0.840845, loss_t: 0.705498, testing: 0.666667, t2y: 1
seq2, epoch1, step: 120, training: 0.875, loss_tr: 0.795196, loss_t: 0.644807, testing: 0.666667, t2y: 0.833333
seq2, epoch1, step: 130, training: 0.875, loss_tr: 0.739939, loss_t: 0.553616, testing: 0.722222, t2y: 1
seq2, epoch1, step: 140, training: 0.9375, loss_tr: 0.617322, loss_t: 0.496253, testing: 0.777778, t2y: 1
seq2, epoch1, step: 150, training: 0.9375, loss_tr: 0.506211, loss_t: 0.473386, testing: 0.833333, t2y: 1
seq2, epoch2, step: 160, training: 1, loss_tr: 0.364464, loss_t: 0.481328, testing: 0.888889, t2y: 1
seq2, epoch2, step: 170, training: 0.8125, loss_tr: 0.386746, loss_t: 0.500843, testing: 0.777778, t2y: 1
seq2, epoch2, step: 180, training: 0.9375, loss_tr: 0.339441, loss_t: 0.487513, testing: 0.777778, t2y: 1
seq2, epoch2, step: 190, training: 0.9375, loss_tr: 0.338343, loss_t: 0.434254, testing: 0.833333, t2y: 1
seq2, epoch2, step: 200, training: 1, loss_tr: 0.331492, loss_t: 0.405807, testing: 0.944444, t2y: 1
seq2, epoch2, step: 210, training: 0.9375, loss_tr: 0.283234, loss_t: 0.37776, testing: 0.944444, t2y: 1
seq2, epoch2, step: 220, training: 1, loss_tr: 0.239217, loss_t: 0.453581, testing: 0.888889, t2y: 0.833333
seq2, epoch2, step: 230, training: 0.9375, loss_tr: 0.216338, loss_t: 0.469932, testing: 0.833333, t2y: 1
seq2, epoch3, step: 240, training: 1, loss_tr: 0.212848, loss_t: 0.629352, testing: 0.666667, t2y: 1
seq2, epoch3, step: 250, training: 1, loss_tr: 0.198385, loss_t: 0.55067, testing: 0.722222, t2y: 1
seq2, epoch3, step: 260, training: 1, loss_tr: 0.111977, loss_t: 0.587477, testing: 0.666667, t2y: 1
seq2, epoch3, step: 270, training: 1, loss_tr: 0.110101, loss_t: 0.445669, testing: 0.833333, t2y: 1
seq2, epoch3, step: 280, training: 1, loss_tr: 0.0736847, loss_t: 0.4683, testing: 0.777778, t2y: 0.833333
seq2, epoch3, step: 290, training: 1, loss_tr: 0.0777494, loss_t: 0.396569, testing: 0.833333, t2y: 1
seq2, epoch3, step: 300, training: 1, loss_tr: 0.082319, loss_t: 0.330093, testing: 0.888889, t2y: 1
seq2, epoch3, step: 310, training: 1, loss_tr: 0.110376, loss_t: 0.367019, testing: 0.833333, t2y: 1
seq2, epoch4, step: 320, training: 1, loss_tr: 0.113317, loss_t: 0.356184, testing: 0.833333, t2y: 1
seq2, epoch4, step: 330, training: 1, loss_tr: 0.116183, loss_t: 0.423094, testing: 0.722222, t2y: 1
seq2, epoch4, step: 340, training: 1, loss_tr: 0.0851308, loss_t: 0.345013, testing: 0.777778, t2y: 1
seq2, epoch4, step: 350, training: 1, loss_tr: 0.08048, loss_t: 0.342932, testing: 0.777778, t2y: 1
seq2, epoch4, step: 360, training: 1, loss_tr: 0.0356479, loss_t: 0.300793, testing: 0.833333, t2y: 1
seq2, epoch4, step: 370, training: 1, loss_tr: 0.0564985, loss_t: 0.272492, testing: 0.888889, t2y: 1
seq2, epoch4, step: 380, training: 1, loss_tr: 0.0463901, loss_t: 0.271682, testing: 0.833333, t2y: 1
seq2, epoch4, step: 390, training: 1, loss_tr: 0.0841237, loss_t: 0.215962, testing: 0.888889, t2y: 1
seq2, epoch5, step: 400, training: 1, loss_tr: 0.0727481, loss_t: 0.31103, testing: 0.777778, t2y: 1
seq2, epoch5, step: 410, training: 1, loss_tr: 0.0808896, loss_t: 0.327141, testing: 0.777778, t2y: 1
seq2, epoch5, step: 420, training: 1, loss_tr: 0.0386084, loss_t: 0.33415, testing: 0.777778, t2y: 1
seq2, epoch5, step: 430, training: 1, loss_tr: 0.0485279, loss_t: 0.232541, testing: 0.833333, t2y: 1
seq2, epoch5, step: 440, training: 1, loss_tr: 0.0435361, loss_t: 0.188891, testing: 0.944444, t2y: 1
seq2, epoch5, step: 450, training: 1, loss_tr: 0.0333887, loss_t: 0.201757, testing: 0.888889, t2y: 1
seq2, epoch5, step: 460, training: 1, loss_tr: 0.0209602, loss_t: 0.19514, testing: 0.944444, t2y: 1
seq2, epoch5, step: 470, training: 1, loss_tr: 0.0271469, loss_t: 0.215972, testing: 0.888889, t2y: 1
seq2, epoch6, step: 480, training: 1, loss_tr: 0.0399634, loss_t: 0.218604, testing: 0.944444, t2y: 1
seq2, epoch6, step: 490, training: 1, loss_tr: 0.0434654, loss_t: 0.244578, testing: 0.888889, t2y: 1
seq2, epoch6, step: 500, training: 1, loss_tr: 0.0374773, loss_t: 0.207925, testing: 0.944444, t2y: 1
seq2, epoch6, step: 510, training: 1, loss_tr: 0.0278232, loss_t: 0.188107, testing: 0.944444, t2y: 1
 
****************************************
current sequence is 3
****************************************
seq3, epoch0, step: 0, training: 0.4375, loss_tr: 2.5013, loss_t: 2.01971, testing: 0.166667, t2y: 0.333333
seq3, epoch0, step: 10, training: 0.5, loss_tr: 2.18499, loss_t: 2.00522, testing: 0.166667, t2y: 0.5
seq3, epoch0, step: 20, training: 0.3125, loss_tr: 1.92001, loss_t: 1.87143, testing: 0.277778, t2y: 0.5
seq3, epoch0, step: 30, training: 0.6875, loss_tr: 1.63046, loss_t: 1.66502, testing: 0.333333, t2y: 0.833333
seq3, epoch0, step: 40, training: 0.75, loss_tr: 1.47365, loss_t: 1.50014, testing: 0.444444, t2y: 0.833333
seq3, epoch0, step: 50, training: 0.625, loss_tr: 1.44049, loss_t: 1.36575, testing: 0.444444, t2y: 0.833333
seq3, epoch0, step: 60, training: 0.5625, loss_tr: 1.36976, loss_t: 1.30063, testing: 0.555556, t2y: 0.833333
seq3, epoch0, step: 70, training: 0.75, loss_tr: 1.35974, loss_t: 1.12391, testing: 0.666667, t2y: 1
seq3, epoch1, step: 80, training: 0.875, loss_tr: 1.10992, loss_t: 1.06536, testing: 0.777778, t2y: 0.833333
seq3, epoch1, step: 90, training: 0.875, loss_tr: 0.997576, loss_t: 0.98141, testing: 0.722222, t2y: 0.666667
seq3, epoch1, step: 100, training: 0.6875, loss_tr: 1.03156, loss_t: 0.923793, testing: 0.722222, t2y: 1
seq3, epoch1, step: 110, training: 0.9375, loss_tr: 0.969659, loss_t: 0.814503, testing: 0.722222, t2y: 1
seq3, epoch1, step: 120, training: 0.9375, loss_tr: 0.935158, loss_t: 0.806652, testing: 0.722222, t2y: 0.833333
seq3, epoch1, step: 130, training: 0.9375, loss_tr: 0.661941, loss_t: 0.80291, testing: 0.611111, t2y: 0.833333
seq3, epoch1, step: 140, training: 1, loss_tr: 0.694381, loss_t: 0.884997, testing: 0.555556, t2y: 1
seq3, epoch1, step: 150, training: 0.875, loss_tr: 0.548689, loss_t: 0.804326, testing: 0.555556, t2y: 1
seq3, epoch2, step: 160, training: 0.875, loss_tr: 0.547252, loss_t: 0.879386, testing: 0.555556, t2y: 0.666667
seq3, epoch2, step: 170, training: 0.9375, loss_tr: 0.462378, loss_t: 0.768158, testing: 0.5, t2y: 0.833333
seq3, epoch2, step: 180, training: 0.9375, loss_tr: 0.386592, loss_t: 0.739031, testing: 0.555556, t2y: 1
seq3, epoch2, step: 190, training: 1, loss_tr: 0.38488, loss_t: 0.624657, testing: 0.555556, t2y: 0.833333
seq3, epoch2, step: 200, training: 0.875, loss_tr: 0.299993, loss_t: 0.583136, testing: 0.555556, t2y: 1
seq3, epoch2, step: 210, training: 0.75, loss_tr: 0.379806, loss_t: 0.624882, testing: 0.5, t2y: 1
seq3, epoch2, step: 220, training: 0.9375, loss_tr: 0.419394, loss_t: 0.549604, testing: 0.555556, t2y: 1
seq3, epoch2, step: 230, training: 0.9375, loss_tr: 0.406745, loss_t: 0.640185, testing: 0.611111, t2y: 1
seq3, epoch3, step: 240, training: 1, loss_tr: 0.296699, loss_t: 0.57347, testing: 0.666667, t2y: 1
seq3, epoch3, step: 250, training: 1, loss_tr: 0.177004, loss_t: 0.662081, testing: 0.611111, t2y: 1
seq3, epoch3, step: 260, training: 1, loss_tr: 0.127791, loss_t: 0.55253, testing: 0.611111, t2y: 1
seq3, epoch3, step: 270, training: 1, loss_tr: 0.100316, loss_t: 0.582792, testing: 0.555556, t2y: 1
seq3, epoch3, step: 280, training: 1, loss_tr: 0.127667, loss_t: 0.498294, testing: 0.555556, t2y: 0.833333
seq3, epoch3, step: 290, training: 1, loss_tr: 0.118371, loss_t: 0.588445, testing: 0.555556, t2y: 1
seq3, epoch3, step: 300, training: 1, loss_tr: 0.136333, loss_t: 0.472462, testing: 0.611111, t2y: 1
seq3, epoch3, step: 310, training: 1, loss_tr: 0.0840275, loss_t: 0.509745, testing: 0.611111, t2y: 1
seq3, epoch4, step: 320, training: 0.9375, loss_tr: 0.0983597, loss_t: 0.439923, testing: 0.555556, t2y: 1
seq3, epoch4, step: 330, training: 0.9375, loss_tr: 0.0585961, loss_t: 0.462118, testing: 0.611111, t2y: 1
seq3, epoch4, step: 340, training: 1, loss_tr: 0.0777385, loss_t: 0.491354, testing: 0.666667, t2y: 1
seq3, epoch4, step: 350, training: 1, loss_tr: 0.0580126, loss_t: 0.486006, testing: 0.722222, t2y: 1
seq3, epoch4, step: 360, training: 1, loss_tr: 0.0490288, loss_t: 0.516809, testing: 0.666667, t2y: 1
seq3, epoch4, step: 370, training: 1, loss_tr: 0.0897469, loss_t: 0.446424, testing: 0.722222, t2y: 1
seq3, epoch4, step: 380, training: 1, loss_tr: 0.134624, loss_t: 0.646505, testing: 0.722222, t2y: 0.833333
seq3, epoch4, step: 390, training: 1, loss_tr: 0.143074, loss_t: 0.62355, testing: 0.722222, t2y: 1
seq3, epoch5, step: 400, training: 1, loss_tr: 0.106454, loss_t: 0.675954, testing: 0.611111, t2y: 1
seq3, epoch5, step: 410, training: 1, loss_tr: 0.0730615, loss_t: 0.502264, testing: 0.666667, t2y: 1
seq3, epoch5, step: 420, training: 1, loss_tr: 0.0546992, loss_t: 0.616421, testing: 0.666667, t2y: 1
seq3, epoch5, step: 430, training: 1, loss_tr: 0.0471085, loss_t: 0.487869, testing: 0.833333, t2y: 1
seq3, epoch5, step: 440, training: 0.9375, loss_tr: 0.0519609, loss_t: 0.586481, testing: 0.833333, t2y: 1
seq3, epoch5, step: 450, training: 1, loss_tr: 0.145893, loss_t: 0.60787, testing: 0.833333, t2y: 0.833333
seq3, epoch5, step: 460, training: 1, loss_tr: 0.153873, loss_t: 0.829606, testing: 0.722222, t2y: 1
seq3, epoch5, step: 470, training: 0.8125, loss_tr: 0.221315, loss_t: 0.608712, testing: 0.722222, t2y: 1
seq3, epoch6, step: 480, training: 1, loss_tr: 0.127132, loss_t: 0.741603, testing: 0.722222, t2y: 0.833333
seq3, epoch6, step: 490, training: 1, loss_tr: 0.104503, loss_t: 0.534207, testing: 0.777778, t2y: 1
seq3, epoch6, step: 500, training: 1, loss_tr: 0.0211847, loss_t: 0.604083, testing: 0.777778, t2y: 1
seq3, epoch6, step: 510, training: 1, loss_tr: 0.0531952, loss_t: 0.539699, testing: 0.777778, t2y: 1
 
The list of Classification Accuracy: [1.0, 1.0, 0.66666666666666663]
 [1.0, 1.0, 1.0]
 Mean Classification Accuracy is 0.888888888889, and top2 mean accuracy is 1.0
__________________________________________________________________________________________________
 
-------------------------------------------------------------------------
---------------------------- RUN 1 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq1, epoch0, step: 0, training: 0.4375, loss_tr: 2.19371, loss_t: 1.76867, testing: 0.5, t2y: 0.666667
seq1, epoch0, step: 10, training: 0.25, loss_tr: 2.13607, loss_t: 1.72043, testing: 0.388889, t2y: 0.5
seq1, epoch0, step: 20, training: 0.5625, loss_tr: 2.0284, loss_t: 1.53982, testing: 0.444444, t2y: 0.666667
seq1, epoch0, step: 30, training: 0.6875, loss_tr: 1.84975, loss_t: 1.32517, testing: 0.555556, t2y: 0.833333
