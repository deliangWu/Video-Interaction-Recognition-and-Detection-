Wed Apr  5 15:55:24 2017 Finetune the dual-nets model with two independent feature variables on UT-Interaction set1! 
****************************************
current sequence is 1
****************************************
step 0, training: 0.15, testing: 0.166667, anv: 0.0166667, best 0.0166667 
step 20, training: 0.1, testing: 0.166667, anv: 0.0333333, best 0.0333333 
step 40, training: 0.15, testing: 0.166667, anv: 0.05, best 0.05 
step 60, training: 0.15, testing: 0.166667, anv: 0.0666667, best 0.0666667 
step 80, training: 0.2, testing: 0.333333, anv: 0.1, best 0.1 
step 100, training: 0.3, testing: 0.333333, anv: 0.133333, best 0.133333 
step 120, training: 0.15, testing: 0.166667, anv: 0.15, best 0.15 
step 140, training: 0.55, testing: 0.166667, anv: 0.166667, best 0.166667 
step 160, training: 0.4, testing: 0.333333, anv: 0.2, best 0.2 
step 180, training: 0.6, testing: 0.666667, anv: 0.266667, best 0.266667 
step 200, training: 0.6, testing: 0.333333, anv: 0.283333, best 0.283333 
step 220, training: 0.2, testing: 0.333333, anv: 0.3, best 0.3 
step 240, training: 0.5, testing: 0.333333, anv: 0.316667, best 0.316667 
step 260, training: 0.35, testing: 0.333333, anv: 0.333333, best 0.333333 
step 280, training: 0.8, testing: 0.333333, anv: 0.333333, best 0.333333 
step 300, training: 0.6, testing: 0.666667, anv: 0.366667, best 0.366667 
step 320, training: 0.9, testing: 0.5, anv: 0.4, best 0.4 
step 340, training: 0.7, testing: 0.5, anv: 0.433333, best 0.433333 
step 360, training: 0.85, testing: 0.5, anv: 0.45, best 0.45 
step 380, training: 0.6, testing: 0.666667, anv: 0.45, best 0.45 
step 400, training: 0.85, testing: 0.5, anv: 0.466667, best 0.466667 
step 420, training: 0.9, testing: 0.666667, anv: 0.5, best 0.5 
step 440, training: 1, testing: 0.666667, anv: 0.533333, best 0.533333 
step 460, training: 0.6, testing: 0.666667, anv: 0.566667, best 0.566667 
step 480, training: 0.85, testing: 0.833333, anv: 0.616667, best 0.616667 
step 500, training: 0.85, testing: 0.666667, anv: 0.616667, best 0.616667 
step 520, training: 0.85, testing: 0.833333, anv: 0.65, best 0.65 
step 540, training: 0.9, testing: 0.666667, anv: 0.666667, best 0.666667 
step 560, training: 0.9, testing: 0.666667, anv: 0.683333, best 0.683333 
step 580, training: 0.95, testing: 0.666667, anv: 0.683333, best 0.683333 
step 600, training: 0.85, testing: 0.666667, anv: 0.7, best 0.7 
step 620, training: 0.95, testing: 0.5, anv: 0.683333, best 0.7 
step 640, training: 1, testing: 0.666667, anv: 0.683333, best 0.7 
step 660, training: 1, testing: 0.666667, anv: 0.683333, best 0.7 
step 680, training: 0.95, testing: 0.666667, anv: 0.666667, best 0.7 
step 700, training: 1, testing: 0.666667, anv: 0.666667, best 0.7 
step 720, training: 1, testing: 0.666667, anv: 0.65, best 0.7 
step 740, training: 1, testing: 0.666667, anv: 0.65, best 0.7 
step 760, training: 1, testing: 0.666667, anv: 0.65, best 0.7 
step 780, training: 1, testing: 0.666667, anv: 0.65, best 0.7 
step 800, training: 1, testing: 0.666667, anv: 0.65, best 0.7 
step 820, training: 0.95, testing: 0.666667, anv: 0.666667, best 0.7 
step 840, training: 1, testing: 0.666667, anv: 0.666667, best 0.7 
step 860, training: 1, testing: 0.666667, anv: 0.666667, best 0.7 
step 880, training: 1, testing: 0.666667, anv: 0.666667, best 0.7 
step 900, training: 1, testing: 0.666667, anv: 0.666667, best 0.7 
step 920, training: 0.95, testing: 0.666667, anv: 0.666667, best 0.7 
step 940, training: 1, testing: 0.666667, anv: 0.666667, best 0.7 
step 960, training: 1, testing: 0.833333, anv: 0.683333, best 0.7 
step 980, training: 1, testing: 0.666667, anv: 0.683333, best 0.7 
step 1000, training: 1, testing: 0.666667, anv: 0.683333, best 0.7 
step 1020, training: 1, testing: 0.666667, anv: 0.683333, best 0.7 
step 1040, training: 1, testing: 0.666667, anv: 0.683333, best 0.7 
step 1060, training: 1, testing: 0.666667, anv: 0.683333, best 0.7 
step 1080, training: 1, testing: 0.666667, anv: 0.683333, best 0.7 
step 1100, training: 0.95, testing: 0.833333, anv: 0.7, best 0.7 
step 1120, training: 1, testing: 0.833333, anv: 0.716667, best 0.716667 
step 1140, training: 1, testing: 0.666667, anv: 0.716667, best 0.716667 
step 1160, training: 1, testing: 0.666667, anv: 0.7, best 0.716667 
step 1180, training: 1, testing: 0.833333, anv: 0.716667, best 0.716667 
step 1200, training: 1, testing: 0.666667, anv: 0.716667, best 0.716667 
step 1220, training: 1, testing: 0.666667, anv: 0.716667, best 0.716667 
step 1240, training: 1, testing: 0.666667, anv: 0.716667, best 0.716667 
step 1260, training: 1, testing: 0.666667, anv: 0.716667, best 0.716667 
step 1280, training: 0.95, testing: 0.666667, anv: 0.716667, best 0.716667 
step 1300, training: 1, testing: 0.666667, anv: 0.7, best 0.716667 
step 1320, training: 0.95, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1340, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1360, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1380, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1400, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1420, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1440, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1460, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1480, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1500, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1520, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1540, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1560, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1580, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1600, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
step 1620, training: 1, testing: 0.833333, anv: 0.683333, best 0.716667 
step 1640, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1660, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1680, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1700, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1720, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1740, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1760, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1780, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1800, training: 1, testing: 0.666667, anv: 0.683333, best 0.716667 
step 1820, training: 1, testing: 0.666667, anv: 0.666667, best 0.716667 
