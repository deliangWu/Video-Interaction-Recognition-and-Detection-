Fri Jun  9 18:49:17 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq1, epoch0, step: 0, training: 0.3125, loss_tr: 22662.7, loss_t: 5783.83, testing: 0.166667, t2y: 0.333333
seq1, epoch0, step: 10, training: 0.1875, loss_tr: 20511.5, loss_t: 7200.85, testing: 0.222222, t2y: 0.5
seq1, epoch0, step: 20, training: 0.5625, loss_tr: 20439, loss_t: 6955.17, testing: 0.222222, t2y: 0.666667
seq1, epoch0, step: 30, training: 0.375, loss_tr: 20271, loss_t: 7391.9, testing: 0.277778, t2y: 0.5
seq1, epoch0, step: 40, training: 0.875, loss_tr: 18986.8, loss_t: 4519.97, testing: 0.388889, t2y: 1
seq1, epoch0, step: 50, training: 0.8125, loss_tr: 15905.5, loss_t: 5181.13, testing: 0.444444, t2y: 0.666667
seq1, epoch0, step: 60, training: 0.5, loss_tr: 11581.5, loss_t: 3593.39, testing: 0.444444, t2y: 0.666667
seq1, epoch0, step: 70, training: 0.8125, loss_tr: 9716.75, loss_t: 4173.91, testing: 0.388889, t2y: 0.666667
seq1, epoch1, step: 80, training: 0.875, loss_tr: 8834.4, loss_t: 2737.23, testing: 0.444444, t2y: 0.666667
seq1, epoch1, step: 90, training: 0.5, loss_tr: 6981.98, loss_t: 2879.44, testing: 0.388889, t2y: 0.666667
seq1, epoch1, step: 100, training: 0.75, loss_tr: 6817.75, loss_t: 2421.69, testing: 0.444444, t2y: 0.833333
seq1, epoch1, step: 110, training: 0.75, loss_tr: 5060.01, loss_t: 1589.2, testing: 0.5, t2y: 0.833333
seq1, epoch1, step: 120, training: 0.625, loss_tr: 5516.51, loss_t: 1147.13, testing: 0.611111, t2y: 0.666667
seq1, epoch1, step: 130, training: 0.9375, loss_tr: 3916.35, loss_t: 703.922, testing: 0.611111, t2y: 0.833333
seq1, epoch1, step: 140, training: 0.875, loss_tr: 3154.05, loss_t: 742.587, testing: 0.611111, t2y: 0.833333
seq1, epoch1, step: 150, training: 0.8125, loss_tr: 1806.39, loss_t: 525.313, testing: 0.611111, t2y: 1
seq1, epoch2, step: 160, training: 0.875, loss_tr: 1568.02, loss_t: 797.48, testing: 0.611111, t2y: 0.666667
seq1, epoch2, step: 170, training: 0.8125, loss_tr: 1403.17, loss_t: 684.556, testing: 0.666667, t2y: 1
seq1, epoch2, step: 180, training: 0.8125, loss_tr: 1648.15, loss_t: 883.366, testing: 0.722222, t2y: 1
seq1, epoch2, step: 190, training: 0.9375, loss_tr: 1668.39, loss_t: 458.592, testing: 0.777778, t2y: 1
seq1, epoch2, step: 200, training: 0.9375, loss_tr: 1553.65, loss_t: 507.898, testing: 0.722222, t2y: 0.833333
seq1, epoch2, step: 210, training: 0.875, loss_tr: 1494.19, loss_t: 179.562, testing: 0.722222, t2y: 0.833333
seq1, epoch2, step: 220, training: 0.875, loss_tr: 1607.51, loss_t: 189.91, testing: 0.666667, t2y: 1
seq1, epoch2, step: 230, training: 0.875, loss_tr: 1921.76, loss_t: 140.605, testing: 0.777778, t2y: 1
seq1, epoch3, step: 240, training: 1, loss_tr: 1970.27, loss_t: 91.9695, testing: 0.777778, t2y: 0.833333
seq1, epoch3, step: 250, training: 0.9375, loss_tr: 2770.88, loss_t: 274.907, testing: 0.777778, t2y: 0.833333
seq1, epoch3, step: 260, training: 1, loss_tr: 2003.35, loss_t: 274.907, testing: 0.722222, t2y: 1
seq1, epoch3, step: 270, training: 0.9375, loss_tr: 1873.23, loss_t: 305.588, testing: 0.722222, t2y: 1
seq1, epoch3, step: 280, training: 1, loss_tr: 1003.02, loss_t: 128.435, testing: 0.722222, t2y: 1
seq1, epoch3, step: 290, training: 0.875, loss_tr: 955.063, loss_t: 365.323, testing: 0.722222, t2y: 1
seq1, epoch3, step: 300, training: 0.9375, loss_tr: 672.177, loss_t: 431.879, testing: 0.722222, t2y: 0.833333
seq1, epoch3, step: 310, training: 0.9375, loss_tr: 543.492, loss_t: 582.887, testing: 0.777778, t2y: 0.833333
seq1, epoch4, step: 320, training: 1, loss_tr: 478.075, loss_t: 538.728, testing: 0.777778, t2y: 1
seq1, epoch4, step: 330, training: 1, loss_tr: 452.869, loss_t: 384.329, testing: 0.777778, t2y: 1
seq1, epoch4, step: 340, training: 1, loss_tr: 476.191, loss_t: 217.188, testing: 0.777778, t2y: 0.833333
seq1, epoch4, step: 350, training: 1, loss_tr: 337.417, loss_t: 24.4591, testing: 0.777778, t2y: 0.833333
seq1, epoch4, step: 360, training: 0.875, loss_tr: 317.494, loss_t: 84.2355, testing: 0.722222, t2y: 0.833333
seq1, epoch4, step: 370, training: 0.9375, loss_tr: 212.283, loss_t: 84.2355, testing: 0.722222, t2y: 0.833333
seq1, epoch4, step: 380, training: 1, loss_tr: 275.465, loss_t: 84.2355, testing: 0.722222, t2y: 0.833333
seq1, epoch4, step: 390, training: 1, loss_tr: 546.588, loss_t: 149.593, testing: 0.777778, t2y: 0.833333
seq1, epoch5, step: 400, training: 0.9375, loss_tr: 783.393, loss_t: 149.593, testing: 0.777778, t2y: 0.833333
seq1, epoch5, step: 410, training: 1, loss_tr: 897.286, loss_t: 162.375, testing: 0.722222, t2y: 0.833333
seq1, epoch5, step: 420, training: 1, loss_tr: 583.747, loss_t: 104.571, testing: 0.777778, t2y: 0.833333
seq1, epoch5, step: 430, training: 1, loss_tr: 242.139, loss_t: 104.571, testing: 0.833333, t2y: 1
seq1, epoch5, step: 440, training: 1, loss_tr: 330.16, loss_t: 102.177, testing: 0.833333, t2y: 1
seq1, epoch5, step: 450, training: 1, loss_tr: 370.016, loss_t: 219.055, testing: 0.777778, t2y: 0.833333
seq1, epoch5, step: 460, training: 1, loss_tr: 417.817, loss_t: 219.055, testing: 0.666667, t2y: 1
seq1, epoch5, step: 470, training: 0.9375, loss_tr: 139.854, loss_t: 208.668, testing: 0.722222, t2y: 0.833333
seq1, epoch6, step: 480, training: 1, loss_tr: 228.146, loss_t: 0, testing: 0.722222, t2y: 0.833333
seq1, epoch6, step: 490, training: 1, loss_tr: 221.172, loss_t: 171.682, testing: 0.722222, t2y: 0.833333
seq1, epoch6, step: 500, training: 0.9375, loss_tr: 542.275, loss_t: 562.53, testing: 0.722222, t2y: 0.833333
seq1, epoch6, step: 510, training: 1, loss_tr: 424.183, loss_t: 621.319, testing: 0.777778, t2y: 1
 
****************************************
current sequence is 2
****************************************
seq2, epoch0, step: 0, training: 0.375, loss_tr: 19903.9, loss_t: 23310.3, testing: 0.166667, t2y: 0.333333
seq2, epoch0, step: 10, training: 0.5625, loss_tr: 18078.5, loss_t: 16844.4, testing: 0.222222, t2y: 0.5
seq2, epoch0, step: 20, training: 0.1875, loss_tr: 18107.8, loss_t: 10854, testing: 0.222222, t2y: 0.5
seq2, epoch0, step: 30, training: 0.4375, loss_tr: 13635, loss_t: 7499.48, testing: 0.222222, t2y: 0.333333
seq2, epoch0, step: 40, training: 0.4375, loss_tr: 13654, loss_t: 7525.3, testing: 0.222222, t2y: 0.5
seq2, epoch0, step: 50, training: 0.5625, loss_tr: 10266.4, loss_t: 6850.3, testing: 0.388889, t2y: 0.666667
seq2, epoch0, step: 60, training: 0.875, loss_tr: 10828.7, loss_t: 3979.79, testing: 0.444444, t2y: 0.333333
seq2, epoch0, step: 70, training: 0.875, loss_tr: 7841.87, loss_t: 3801.44, testing: 0.5, t2y: 0.666667
seq2, epoch1, step: 80, training: 0.75, loss_tr: 6659.49, loss_t: 3601.57, testing: 0.444444, t2y: 0.666667
seq2, epoch1, step: 90, training: 0.875, loss_tr: 6122.38, loss_t: 2380.38, testing: 0.555556, t2y: 0.833333
seq2, epoch1, step: 100, training: 0.6875, loss_tr: 5931.8, loss_t: 2192.05, testing: 0.555556, t2y: 0.5
seq2, epoch1, step: 110, training: 0.75, loss_tr: 5194.52, loss_t: 1942.27, testing: 0.555556, t2y: 0.666667
seq2, epoch1, step: 120, training: 0.75, loss_tr: 5020.54, loss_t: 1732.84, testing: 0.555556, t2y: 0.833333
seq2, epoch1, step: 130, training: 0.875, loss_tr: 4030.41, loss_t: 1138.78, testing: 0.555556, t2y: 0.666667
seq2, epoch1, step: 140, training: 0.75, loss_tr: 3894.46, loss_t: 549.724, testing: 0.611111, t2y: 0.833333
seq2, epoch1, step: 150, training: 0.875, loss_tr: 2042.84, loss_t: 656.91, testing: 0.611111, t2y: 0.666667
seq2, epoch2, step: 160, training: 0.9375, loss_tr: 1477.68, loss_t: 287.651, testing: 0.722222, t2y: 0.833333
seq2, epoch2, step: 170, training: 0.9375, loss_tr: 1058.59, loss_t: 441.104, testing: 0.722222, t2y: 0.833333
seq2, epoch2, step: 180, training: 1, loss_tr: 1446.67, loss_t: 545.281, testing: 0.722222, t2y: 0.666667
seq2, epoch2, step: 190, training: 0.9375, loss_tr: 2094.1, loss_t: 746.056, testing: 0.666667, t2y: 0.833333
seq2, epoch2, step: 200, training: 1, loss_tr: 1703.07, loss_t: 526.559, testing: 0.722222, t2y: 1
seq2, epoch2, step: 210, training: 1, loss_tr: 2103.44, loss_t: 200.775, testing: 0.777778, t2y: 1
seq2, epoch2, step: 220, training: 0.9375, loss_tr: 1728.05, loss_t: 165.473, testing: 0.833333, t2y: 1
seq2, epoch2, step: 230, training: 1, loss_tr: 1654.36, loss_t: 165.473, testing: 0.888889, t2y: 1
seq2, epoch3, step: 240, training: 0.875, loss_tr: 1697.1, loss_t: 283.657, testing: 0.833333, t2y: 0.666667
seq2, epoch3, step: 250, training: 1, loss_tr: 1357.84, loss_t: 118.184, testing: 0.833333, t2y: 1
seq2, epoch3, step: 260, training: 1, loss_tr: 1280.15, loss_t: 118.184, testing: 0.777778, t2y: 1
seq2, epoch3, step: 270, training: 0.9375, loss_tr: 853.217, loss_t: 0, testing: 0.888889, t2y: 1
 
****************************************
current sequence is 3
****************************************
seq3, epoch0, step: 0, training: 0.25, loss_tr: 27287.7, loss_t: 16993.5, testing: 0.166667, t2y: 0.333333
seq3, epoch0, step: 10, training: 0.5, loss_tr: 24425.9, loss_t: 16536.9, testing: 0.166667, t2y: 0.5
seq3, epoch0, step: 20, training: 0.125, loss_tr: 22820.8, loss_t: 15182.7, testing: 0.166667, t2y: 0.333333
seq3, epoch0, step: 30, training: 0.3125, loss_tr: 18494.5, loss_t: 14117.3, testing: 0.277778, t2y: 0.5
seq3, epoch0, step: 40, training: 0.375, loss_tr: 15690.2, loss_t: 13304.3, testing: 0.277778, t2y: 0.5
seq3, epoch0, step: 50, training: 0.5, loss_tr: 13319.1, loss_t: 11536.2, testing: 0.333333, t2y: 0.5
seq3, epoch0, step: 60, training: 0.625, loss_tr: 12260.2, loss_t: 8008.85, testing: 0.333333, t2y: 0.666667
seq3, epoch0, step: 70, training: 0.75, loss_tr: 13111.1, loss_t: 6084.87, testing: 0.388889, t2y: 0.666667
seq3, epoch1, step: 80, training: 0.75, loss_tr: 8987.7, loss_t: 4464.5, testing: 0.444444, t2y: 0.666667
seq3, epoch1, step: 90, training: 0.9375, loss_tr: 5845.6, loss_t: 3875.85, testing: 0.388889, t2y: 0.833333
seq3, epoch1, step: 100, training: 0.75, loss_tr: 3387.02, loss_t: 3571.74, testing: 0.388889, t2y: 0.666667
seq3, epoch1, step: 110, training: 0.75, loss_tr: 3721.85, loss_t: 3533.27, testing: 0.333333, t2y: 0.666667
seq3, epoch1, step: 120, training: 0.9375, loss_tr: 4624.99, loss_t: 4671.12, testing: 0.333333, t2y: 0.666667
seq3, epoch1, step: 130, training: 0.8125, loss_tr: 4692.52, loss_t: 3401.93, testing: 0.444444, t2y: 0.666667
seq3, epoch1, step: 140, training: 1, loss_tr: 4337.89, loss_t: 3059.17, testing: 0.5, t2y: 0.666667
seq3, epoch1, step: 150, training: 0.9375, loss_tr: 4048.25, loss_t: 2143.07, testing: 0.555556, t2y: 0.666667
seq3, epoch2, step: 160, training: 1, loss_tr: 2495.09, loss_t: 1647.41, testing: 0.555556, t2y: 0.666667
