Tue Jun 13 19:02:20 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 2
****************************************
seq: 2, epoch: 0, step: 0, training: 0.125, testing: 0.0714286, loss_tr: 2.00048, loss_t: 1.97584  
seq: 2, epoch: 0, step: 10, training: 0.625, testing: 0.642857, loss_tr: 1.62165, loss_t: 1.53914  
seq: 2, epoch: 0, step: 20, training: 0.8125, testing: 0.642857, loss_tr: 0.784476, loss_t: 1.47783  
seq: 2, epoch: 0, step: 30, training: 0.625, testing: 0.642857, loss_tr: 1.38086, loss_t: 1.24474  
seq: 2, epoch: 0, step: 40, training: 0.6875, testing: 0.642857, loss_tr: 1.16261, loss_t: 1.24953  
seq: 2, epoch: 0, step: 50, training: 0.6875, testing: 0.642857, loss_tr: 1.18845, loss_t: 1.30453  
seq: 2, epoch: 0, step: 60, training: 0.5625, testing: 0.642857, loss_tr: 1.52438, loss_t: 1.27235  
seq: 2, epoch: 0, step: 70, training: 0.6875, testing: 0.642857, loss_tr: 1.11721, loss_t: 1.25604  
seq: 2, epoch: 0, step: 80, training: 0.75, testing: 0.642857, loss_tr: 1.02035, loss_t: 1.25893  
seq: 2, epoch: 0, step: 90, training: 0.75, testing: 0.642857, loss_tr: 0.987457, loss_t: 1.28981  
seq: 2, epoch: 0, step: 100, training: 0.625, testing: 0.642857, loss_tr: 1.28599, loss_t: 1.22934  
seq: 2, epoch: 0, step: 110, training: 0.5625, testing: 0.642857, loss_tr: 1.5781, loss_t: 1.26674  
seq: 2, epoch: 0, step: 120, training: 0.5625, testing: 0.642857, loss_tr: 1.46821, loss_t: 1.24101  
seq: 2, epoch: 0, step: 130, training: 0.6875, testing: 0.642857, loss_tr: 1.10716, loss_t: 1.28047  
seq: 2, epoch: 0, step: 140, training: 0.625, testing: 0.642857, loss_tr: 1.21895, loss_t: 1.21422  
seq: 2, epoch: 0, step: 150, training: 0.6875, testing: 0.642857, loss_tr: 1.11221, loss_t: 1.228  
seq: 2, epoch: 0, step: 160, training: 0.9375, testing: 0.642857, loss_tr: 0.519456, loss_t: 1.21405  
seq: 2, epoch: 0, step: 170, training: 0.5625, testing: 0.642857, loss_tr: 1.31828, loss_t: 1.21075  
seq: 2, epoch: 0, step: 180, training: 0.8125, testing: 0.642857, loss_tr: 0.741385, loss_t: 1.25566  
seq: 2, epoch: 0, step: 190, training: 0.6875, testing: 0.642857, loss_tr: 1.14942, loss_t: 1.20556  
seq: 2, epoch: 1, step: 200, training: 0.6875, testing: 0.642857, loss_tr: 1.02156, loss_t: 1.20245  
seq: 2, epoch: 1, step: 210, training: 0.5, testing: 0.642857, loss_tr: 1.5968, loss_t: 1.20873  
seq: 2, epoch: 1, step: 220, training: 0.8125, testing: 0.642857, loss_tr: 0.784861, loss_t: 1.17907  
seq: 2, epoch: 1, step: 230, training: 0.5625, testing: 0.642857, loss_tr: 1.54026, loss_t: 1.29479  
seq: 2, epoch: 1, step: 240, training: 0.6875, testing: 0.642857, loss_tr: 1.18507, loss_t: 1.15108  
seq: 2, epoch: 1, step: 250, training: 0.75, testing: 0.642857, loss_tr: 0.968156, loss_t: 1.21778  
seq: 2, epoch: 1, step: 260, training: 0.625, testing: 0.642857, loss_tr: 1.11434, loss_t: 1.12591  
seq: 2, epoch: 1, step: 270, training: 0.75, testing: 0.642857, loss_tr: 0.822068, loss_t: 1.0975  
seq: 2, epoch: 1, step: 280, training: 0.75, testing: 0.642857, loss_tr: 0.940516, loss_t: 1.08808  
seq: 2, epoch: 1, step: 290, training: 0.75, testing: 0.642857, loss_tr: 0.933261, loss_t: 1.06398  
seq: 2, epoch: 1, step: 300, training: 0.625, testing: 0.642857, loss_tr: 1.23026, loss_t: 1.06506  
seq: 2, epoch: 1, step: 310, training: 0.8125, testing: 0.642857, loss_tr: 0.704605, loss_t: 1.02992  
seq: 2, epoch: 1, step: 320, training: 0.8125, testing: 0.642857, loss_tr: 0.760179, loss_t: 0.999792  
seq: 2, epoch: 1, step: 330, training: 0.625, testing: 0.642857, loss_tr: 0.986384, loss_t: 0.96649  
seq: 2, epoch: 1, step: 340, training: 0.6875, testing: 0.642857, loss_tr: 0.851068, loss_t: 0.960752  
seq: 2, epoch: 1, step: 350, training: 0.6875, testing: 0.642857, loss_tr: 1.08541, loss_t: 0.897937  
seq: 2, epoch: 1, step: 360, training: 0.5, testing: 0.642857, loss_tr: 1.35265, loss_t: 0.898347  
seq: 2, epoch: 1, step: 370, training: 0.625, testing: 0.642857, loss_tr: 0.997213, loss_t: 0.873976  
seq: 2, epoch: 1, step: 380, training: 0.5625, testing: 0.642857, loss_tr: 1.36093, loss_t: 0.84623  
seq: 2, epoch: 1, step: 390, training: 0.75, testing: 0.642857, loss_tr: 0.788332, loss_t: 0.807835  
seq: 2, epoch: 2, step: 400, training: 0.75, testing: 0.714286, loss_tr: 0.739316, loss_t: 0.757796  
seq: 2, epoch: 2, step: 410, training: 0.9375, testing: 0.714286, loss_tr: 0.360774, loss_t: 0.738539  
seq: 2, epoch: 2, step: 420, training: 0.5625, testing: 0.857143, loss_tr: 0.982496, loss_t: 0.712  
seq: 2, epoch: 2, step: 430, training: 0.6875, testing: 0.714286, loss_tr: 1.0984, loss_t: 0.726865  
seq: 2, epoch: 2, step: 440, training: 0.8125, testing: 0.714286, loss_tr: 0.647386, loss_t: 0.739262  
seq: 2, epoch: 2, step: 450, training: 0.6875, testing: 0.785714, loss_tr: 0.674841, loss_t: 0.723404  
seq: 2, epoch: 2, step: 460, training: 0.5625, testing: 0.785714, loss_tr: 1.08516, loss_t: 0.660491  
seq: 2, epoch: 2, step: 470, training: 0.8125, testing: 0.857143, loss_tr: 0.561257, loss_t: 0.718349  
seq: 2, epoch: 2, step: 480, training: 0.75, testing: 0.642857, loss_tr: 0.742204, loss_t: 0.705472  
seq: 2, epoch: 2, step: 490, training: 0.75, testing: 0.785714, loss_tr: 0.623569, loss_t: 0.718115  
seq: 2, epoch: 2, step: 500, training: 0.75, testing: 0.714286, loss_tr: 0.769914, loss_t: 0.844766  
seq: 2, epoch: 2, step: 510, training: 0.6875, testing: 0.785714, loss_tr: 0.940604, loss_t: 0.652066  
seq: 2, epoch: 2, step: 520, training: 0.8125, testing: 0.785714, loss_tr: 0.893612, loss_t: 0.620362  
seq: 2, epoch: 2, step: 530, training: 0.5, testing: 0.785714, loss_tr: 1.14801, loss_t: 0.650089  
seq: 2, epoch: 2, step: 540, training: 0.6875, testing: 0.857143, loss_tr: 1.06672, loss_t: 0.622218  
seq: 2, epoch: 2, step: 550, training: 0.875, testing: 0.785714, loss_tr: 0.495293, loss_t: 0.62995  
seq: 2, epoch: 2, step: 560, training: 0.75, testing: 0.857143, loss_tr: 0.789486, loss_t: 0.604891  
seq: 2, epoch: 2, step: 570, training: 0.5625, testing: 0.857143, loss_tr: 1.31783, loss_t: 0.621872  
seq: 2, epoch: 2, step: 580, training: 0.75, testing: 0.785714, loss_tr: 0.780807, loss_t: 0.603637  
seq: 2, epoch: 2, step: 590, training: 1, testing: 0.785714, loss_tr: 0.290168, loss_t: 0.54833  
seq: 2, epoch: 3, step: 600, training: 0.75, testing: 0.928571, loss_tr: 0.592147, loss_t: 0.553965  
seq: 2, epoch: 3, step: 610, training: 0.9375, testing: 0.785714, loss_tr: 0.246546, loss_t: 0.605627  
seq: 2, epoch: 3, step: 620, training: 0.5, testing: 0.785714, loss_tr: 0.95633, loss_t: 0.764704  
seq: 2, epoch: 3, step: 630, training: 0.875, testing: 0.857143, loss_tr: 0.559656, loss_t: 0.588004  
seq: 2, epoch: 3, step: 640, training: 0.8125, testing: 0.928571, loss_tr: 0.42452, loss_t: 0.613663  
seq: 2, epoch: 3, step: 650, training: 0.8125, testing: 0.857143, loss_tr: 0.563757, loss_t: 0.59458  
seq: 2, epoch: 3, step: 660, training: 0.625, testing: 0.857143, loss_tr: 0.783195, loss_t: 0.687957  
seq: 2, epoch: 3, step: 670, training: 0.6875, testing: 0.857143, loss_tr: 0.589497, loss_t: 0.609647  
seq: 2, epoch: 3, step: 680, training: 0.75, testing: 0.785714, loss_tr: 0.78062, loss_t: 0.727962  
seq: 2, epoch: 3, step: 690, training: 0.8125, testing: 0.857143, loss_tr: 0.506292, loss_t: 0.485717  
seq: 2, epoch: 3, step: 700, training: 0.75, testing: 0.857143, loss_tr: 0.533436, loss_t: 0.588635  
seq: 2, epoch: 3, step: 710, training: 0.6875, testing: 0.857143, loss_tr: 0.745995, loss_t: 0.575141  
seq: 2, epoch: 3, step: 720, training: 0.5625, testing: 0.857143, loss_tr: 0.901825, loss_t: 0.598939  
seq: 2, epoch: 3, step: 730, training: 0.5, testing: 0.857143, loss_tr: 1.25323, loss_t: 0.486827  
seq: 2, epoch: 3, step: 740, training: 0.8125, testing: 0.857143, loss_tr: 0.499776, loss_t: 0.624189  
seq: 2, epoch: 3, step: 750, training: 1, testing: 0.857143, loss_tr: 0.259626, loss_t: 0.492898  
seq: 2, epoch: 3, step: 760, training: 0.875, testing: 0.785714, loss_tr: 0.678296, loss_t: 0.647414  
seq: 2, epoch: 3, step: 770, training: 0.8125, testing: 0.857143, loss_tr: 0.577681, loss_t: 0.542257  
seq: 2, epoch: 3, step: 780, training: 0.8125, testing: 0.785714, loss_tr: 0.353014, loss_t: 0.575295  
seq: 2, epoch: 3, step: 790, training: 0.9375, testing: 0.785714, loss_tr: 0.250918, loss_t: 0.582102  
seq: 2, epoch: 4, step: 800, training: 0.875, testing: 0.785714, loss_tr: 0.31085, loss_t: 0.575056  
seq: 2, epoch: 4, step: 810, training: 0.875, testing: 0.785714, loss_tr: 0.387937, loss_t: 0.594791  
seq: 2, epoch: 4, step: 820, training: 0.8125, testing: 0.857143, loss_tr: 0.627938, loss_t: 0.582377  
seq: 2, epoch: 4, step: 830, training: 0.8125, testing: 0.857143, loss_tr: 0.512747, loss_t: 0.547653  
seq: 2, epoch: 4, step: 840, training: 0.9375, testing: 0.857143, loss_tr: 0.284971, loss_t: 0.540927  
seq: 2, epoch: 4, step: 850, training: 0.8125, testing: 0.785714, loss_tr: 0.420428, loss_t: 0.558872  
seq: 2, epoch: 4, step: 860, training: 0.9375, testing: 0.785714, loss_tr: 0.0986976, loss_t: 0.511317  
seq: 2, epoch: 4, step: 870, training: 0.8125, testing: 0.857143, loss_tr: 0.52754, loss_t: 0.538069  
seq: 2, epoch: 4, step: 880, training: 0.875, testing: 0.857143, loss_tr: 0.373888, loss_t: 0.559033  
seq: 2, epoch: 4, step: 890, training: 0.875, testing: 0.857143, loss_tr: 0.368569, loss_t: 0.55097  
seq: 2, epoch: 4, step: 900, training: 1, testing: 0.857143, loss_tr: 0.207814, loss_t: 0.543292  
seq: 2, epoch: 4, step: 910, training: 0.8125, testing: 0.857143, loss_tr: 0.449778, loss_t: 0.54  
seq: 2, epoch: 4, step: 920, training: 0.9375, testing: 0.857143, loss_tr: 0.22881, loss_t: 0.578638  
seq: 2, epoch: 4, step: 930, training: 0.9375, testing: 0.857143, loss_tr: 0.230563, loss_t: 0.518497  
seq: 2, epoch: 4, step: 940, training: 0.8125, testing: 0.857143, loss_tr: 0.695142, loss_t: 0.541339  
seq: 2, epoch: 4, step: 950, training: 0.9375, testing: 0.857143, loss_tr: 0.220735, loss_t: 0.480841  
seq: 2, epoch: 4, step: 960, training: 0.9375, testing: 0.857143, loss_tr: 0.154795, loss_t: 0.505152  
seq: 2, epoch: 4, step: 970, training: 0.875, testing: 0.857143, loss_tr: 0.332967, loss_t: 0.546297  
seq: 2, epoch: 4, step: 980, training: 0.875, testing: 0.857143, loss_tr: 0.324166, loss_t: 0.526454  
seq: 2, epoch: 4, step: 990, training: 1, testing: 0.857143, loss_tr: 0.108605, loss_t: 0.526957  
seq: 2, epoch: 5, step: 1000, training: 0.875, testing: 0.857143, loss_tr: 0.168896, loss_t: 0.454335  
 
