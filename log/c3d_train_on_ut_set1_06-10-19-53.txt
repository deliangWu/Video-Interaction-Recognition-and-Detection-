Sat Jun 10 19:53:55 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq1, epoch0, step: 0, training: 0.3125, loss_tr: 1.66605, loss_t: 1.93964, testing: 0.166667, t2y: 0.166667
seq1, epoch0, step: 10, training: 0.4375, loss_tr: 1.65218, loss_t: 1.74925, testing: 0.277778, t2y: 0.666667
seq1, epoch0, step: 20, training: 0.375, loss_tr: 1.51616, loss_t: 1.50022, testing: 0.388889, t2y: 0.666667
seq1, epoch0, step: 30, training: 0.5, loss_tr: 1.39879, loss_t: 1.21789, testing: 0.444444, t2y: 0.833333
seq1, epoch0, step: 40, training: 0.6875, loss_tr: 1.15721, loss_t: 1.15798, testing: 0.444444, t2y: 0.833333
seq1, epoch0, step: 50, training: 0.5625, loss_tr: 1.04286, loss_t: 1.01162, testing: 0.444444, t2y: 1
seq1, epoch0, step: 60, training: 0.6875, loss_tr: 0.927173, loss_t: 0.98046, testing: 0.611111, t2y: 0.833333
seq1, epoch0, step: 70, training: 0.8125, loss_tr: 0.800132, loss_t: 0.770267, testing: 0.722222, t2y: 1
seq1, epoch1, step: 80, training: 0.6875, loss_tr: 0.696206, loss_t: 0.773148, testing: 0.833333, t2y: 0.833333
seq1, epoch1, step: 90, training: 1, loss_tr: 0.506789, loss_t: 0.584542, testing: 0.888889, t2y: 1
seq1, epoch1, step: 100, training: 0.75, loss_tr: 0.536062, loss_t: 0.601901, testing: 0.888889, t2y: 0.833333
seq1, epoch1, step: 110, training: 0.875, loss_tr: 0.556882, loss_t: 0.464043, testing: 0.944444, t2y: 1
seq1, epoch1, step: 120, training: 0.75, loss_tr: 0.606276, loss_t: 0.464564, testing: 0.888889, t2y: 1
seq1, epoch1, step: 130, training: 0.875, loss_tr: 0.536444, loss_t: 0.35592, testing: 0.944444, t2y: 1
seq1, epoch1, step: 140, training: 1, loss_tr: 0.381631, loss_t: 0.358203, testing: 0.944444, t2y: 1
seq1, epoch1, step: 150, training: 0.8125, loss_tr: 0.294326, loss_t: 0.347754, testing: 0.944444, t2y: 0.833333
seq1, epoch2, step: 160, training: 0.875, loss_tr: 0.241786, loss_t: 0.321703, testing: 0.944444, t2y: 1
seq1, epoch2, step: 170, training: 0.9375, loss_tr: 0.2512, loss_t: 0.272494, testing: 0.944444, t2y: 1
seq1, epoch2, step: 180, training: 1, loss_tr: 0.198101, loss_t: 0.195195, testing: 1, t2y: 1
seq1, epoch2, step: 190, training: 1, loss_tr: 0.16199, loss_t: 0.16026, testing: 1, t2y: 1
seq1, epoch2, step: 200, training: 0.9375, loss_tr: 0.147386, loss_t: 0.145211, testing: 1, t2y: 1
seq1, epoch2, step: 210, training: 1, loss_tr: 0.125826, loss_t: 0.12815, testing: 1, t2y: 1
seq1, epoch2, step: 220, training: 1, loss_tr: 0.107455, loss_t: 0.130366, testing: 1, t2y: 1
seq1, epoch2, step: 230, training: 0.9375, loss_tr: 0.0723835, loss_t: 0.108312, testing: 1, t2y: 1
seq1, epoch3, step: 240, training: 1, loss_tr: 0.0938427, loss_t: 0.120019, testing: 1, t2y: 1
seq1, epoch3, step: 250, training: 1, loss_tr: 0.0751797, loss_t: 0.0967475, testing: 1, t2y: 1
seq1, epoch3, step: 260, training: 1, loss_tr: 0.0558039, loss_t: 0.0830696, testing: 1, t2y: 1
seq1, epoch3, step: 270, training: 1, loss_tr: 0.0209935, loss_t: 0.0464529, testing: 1, t2y: 1
seq1, epoch3, step: 280, training: 0.875, loss_tr: 0.0241705, loss_t: 0.0582471, testing: 1, t2y: 1
seq1, epoch3, step: 290, training: 0.9375, loss_tr: 0.0708906, loss_t: 0.0875837, testing: 1, t2y: 1
seq1, epoch3, step: 300, training: 0.9375, loss_tr: 0.0814534, loss_t: 0.0875476, testing: 1, t2y: 1
seq1, epoch3, step: 310, training: 1, loss_tr: 0.0836888, loss_t: 0.0706526, testing: 1, t2y: 1
seq1, epoch4, step: 320, training: 1, loss_tr: 0.0337832, loss_t: 0.0477856, testing: 1, t2y: 1
seq1, epoch4, step: 330, training: 1, loss_tr: 0.0214078, loss_t: 0.040512, testing: 1, t2y: 1
seq1, epoch4, step: 340, training: 1, loss_tr: 0.0160542, loss_t: 0.0370493, testing: 1, t2y: 1
seq1, epoch4, step: 350, training: 1, loss_tr: 0.0181301, loss_t: 0.0187322, testing: 1, t2y: 1
seq1, epoch4, step: 360, training: 1, loss_tr: 0.0288468, loss_t: 0.0172757, testing: 1, t2y: 1
seq1, epoch4, step: 370, training: 1, loss_tr: 0.0408494, loss_t: 0.0174777, testing: 1, t2y: 1
seq1, epoch4, step: 380, training: 1, loss_tr: 0.0364569, loss_t: 0.0216893, testing: 1, t2y: 1
seq1, epoch4, step: 390, training: 1, loss_tr: 0.0249304, loss_t: 0.0192978, testing: 1, t2y: 1
seq1, epoch5, step: 400, training: 0.9375, loss_tr: 0.0256046, loss_t: 0.0198058, testing: 1, t2y: 1
seq1, epoch5, step: 410, training: 1, loss_tr: 0.0246897, loss_t: 0.0107543, testing: 1, t2y: 1
seq1, epoch5, step: 420, training: 1, loss_tr: 0.0221448, loss_t: 0.0083845, testing: 1, t2y: 1
seq1, epoch5, step: 430, training: 1, loss_tr: 0.00299354, loss_t: 0.00773512, testing: 1, t2y: 1
seq1, epoch5, step: 440, training: 1, loss_tr: 0.00235973, loss_t: 0.007463, testing: 1, t2y: 1
seq1, epoch5, step: 450, training: 1, loss_tr: 0.0013718, loss_t: 0.00639517, testing: 1, t2y: 1
seq1, epoch5, step: 460, training: 1, loss_tr: 0.00331233, loss_t: 0.011601, testing: 1, t2y: 1
seq1, epoch5, step: 470, training: 1, loss_tr: 0.00486218, loss_t: 0.0129245, testing: 1, t2y: 1
seq1, epoch6, step: 480, training: 1, loss_tr: 0.0048815, loss_t: 0.0132809, testing: 1, t2y: 1
seq1, epoch6, step: 490, training: 1, loss_tr: 0.00542783, loss_t: 0.00804135, testing: 1, t2y: 1
seq1, epoch6, step: 500, training: 0.9375, loss_tr: 0.00794767, loss_t: 0.0304296, testing: 0.944444, t2y: 1
seq1, epoch6, step: 510, training: 1, loss_tr: 0.00889828, loss_t: 0.0305573, testing: 0.944444, t2y: 1
 
****************************************
current sequence is 2
****************************************
seq2, epoch0, step: 0, training: 0.1875, loss_tr: 1.73393, loss_t: 2.00249, testing: 0.166667, t2y: 0.166667
seq2, epoch0, step: 10, training: 0.3125, loss_tr: 1.67765, loss_t: 1.86365, testing: 0.222222, t2y: 0.666667
seq2, epoch0, step: 20, training: 0.375, loss_tr: 1.58456, loss_t: 1.78195, testing: 0.222222, t2y: 0.333333
seq2, epoch0, step: 30, training: 0.8125, loss_tr: 1.2856, loss_t: 1.5667, testing: 0.277778, t2y: 0.666667
seq2, epoch0, step: 40, training: 0.625, loss_tr: 1.1321, loss_t: 1.5559, testing: 0.222222, t2y: 0.333333
seq2, epoch0, step: 50, training: 0.8125, loss_tr: 0.996343, loss_t: 1.34871, testing: 0.222222, t2y: 0.666667
seq2, epoch0, step: 60, training: 0.875, loss_tr: 0.993235, loss_t: 1.17043, testing: 0.333333, t2y: 0.833333
seq2, epoch0, step: 70, training: 0.875, loss_tr: 0.796063, loss_t: 0.916741, testing: 0.5, t2y: 1
seq2, epoch1, step: 80, training: 0.625, loss_tr: 0.671083, loss_t: 0.844158, testing: 0.611111, t2y: 0.833333
seq2, epoch1, step: 90, training: 0.8125, loss_tr: 0.586213, loss_t: 0.784552, testing: 0.611111, t2y: 1
seq2, epoch1, step: 100, training: 0.9375, loss_tr: 0.568812, loss_t: 0.771424, testing: 0.611111, t2y: 0.833333
seq2, epoch1, step: 110, training: 0.8125, loss_tr: 0.573783, loss_t: 0.723175, testing: 0.611111, t2y: 0.833333
seq2, epoch1, step: 120, training: 0.875, loss_tr: 0.511743, loss_t: 0.726937, testing: 0.611111, t2y: 1
seq2, epoch1, step: 130, training: 0.875, loss_tr: 0.463391, loss_t: 0.724455, testing: 0.5, t2y: 1
seq2, epoch1, step: 140, training: 1, loss_tr: 0.319073, loss_t: 0.633737, testing: 0.555556, t2y: 1
seq2, epoch1, step: 150, training: 0.8125, loss_tr: 0.304914, loss_t: 0.587467, testing: 0.555556, t2y: 1
seq2, epoch2, step: 160, training: 0.9375, loss_tr: 0.268502, loss_t: 0.505267, testing: 0.666667, t2y: 1
seq2, epoch2, step: 170, training: 0.875, loss_tr: 0.253304, loss_t: 0.479794, testing: 0.722222, t2y: 1
seq2, epoch2, step: 180, training: 1, loss_tr: 0.190635, loss_t: 0.513881, testing: 0.722222, t2y: 1
seq2, epoch2, step: 190, training: 1, loss_tr: 0.145006, loss_t: 0.535716, testing: 0.611111, t2y: 1
seq2, epoch2, step: 200, training: 0.9375, loss_tr: 0.114831, loss_t: 0.546444, testing: 0.611111, t2y: 1
seq2, epoch2, step: 210, training: 1, loss_tr: 0.0820377, loss_t: 0.446884, testing: 0.666667, t2y: 1
seq2, epoch2, step: 220, training: 0.9375, loss_tr: 0.0991268, loss_t: 0.482827, testing: 0.722222, t2y: 1
seq2, epoch2, step: 230, training: 1, loss_tr: 0.077774, loss_t: 0.439867, testing: 0.666667, t2y: 1
seq2, epoch3, step: 240, training: 1, loss_tr: 0.0801643, loss_t: 0.417292, testing: 0.666667, t2y: 1
seq2, epoch3, step: 250, training: 1, loss_tr: 0.0471358, loss_t: 0.366288, testing: 0.777778, t2y: 1
seq2, epoch3, step: 260, training: 1, loss_tr: 0.0405244, loss_t: 0.444925, testing: 0.833333, t2y: 1
seq2, epoch3, step: 270, training: 1, loss_tr: 0.0368041, loss_t: 0.505109, testing: 0.833333, t2y: 1
seq2, epoch3, step: 280, training: 1, loss_tr: 0.0378268, loss_t: 0.519588, testing: 0.833333, t2y: 1
seq2, epoch3, step: 290, training: 0.9375, loss_tr: 0.063761, loss_t: 0.48256, testing: 0.777778, t2y: 1
seq2, epoch3, step: 300, training: 1, loss_tr: 0.0568522, loss_t: 0.427312, testing: 0.777778, t2y: 1
seq2, epoch3, step: 310, training: 1, loss_tr: 0.0565756, loss_t: 0.438596, testing: 0.666667, t2y: 1
seq2, epoch4, step: 320, training: 1, loss_tr: 0.0227524, loss_t: 0.416126, testing: 0.666667, t2y: 1
seq2, epoch4, step: 330, training: 1, loss_tr: 0.0171138, loss_t: 0.473174, testing: 0.611111, t2y: 1
seq2, epoch4, step: 340, training: 1, loss_tr: 0.01489, loss_t: 0.41196, testing: 0.666667, t2y: 1
seq2, epoch4, step: 350, training: 1, loss_tr: 0.0138213, loss_t: 0.459574, testing: 0.666667, t2y: 1
seq2, epoch4, step: 360, training: 1, loss_tr: 0.0239328, loss_t: 0.628573, testing: 0.722222, t2y: 1
seq2, epoch4, step: 370, training: 1, loss_tr: 0.0253904, loss_t: 0.675724, testing: 0.777778, t2y: 1
seq2, epoch4, step: 380, training: 1, loss_tr: 0.0261855, loss_t: 0.685526, testing: 0.777778, t2y: 1
seq2, epoch4, step: 390, training: 1, loss_tr: 0.0193039, loss_t: 0.504031, testing: 0.777778, t2y: 1
seq2, epoch5, step: 400, training: 1, loss_tr: 0.0151607, loss_t: 0.53102, testing: 0.722222, t2y: 1
seq2, epoch5, step: 410, training: 1, loss_tr: 0.0136003, loss_t: 0.460515, testing: 0.777778, t2y: 1
seq2, epoch5, step: 420, training: 1, loss_tr: 0.012434, loss_t: 0.446776, testing: 0.777778, t2y: 1
seq2, epoch5, step: 430, training: 1, loss_tr: 0.0113054, loss_t: 0.337098, testing: 0.833333, t2y: 1
seq2, epoch5, step: 440, training: 1, loss_tr: 0.0106931, loss_t: 0.309552, testing: 0.833333, t2y: 1
seq2, epoch5, step: 450, training: 1, loss_tr: 0.00550546, loss_t: 0.357778, testing: 0.833333, t2y: 1
seq2, epoch5, step: 460, training: 1, loss_tr: 0.00561069, loss_t: 0.336389, testing: 0.833333, t2y: 1
seq2, epoch5, step: 470, training: 1, loss_tr: 0.00513966, loss_t: 0.539744, testing: 0.833333, t2y: 1
seq2, epoch6, step: 480, training: 1, loss_tr: 0.00416456, loss_t: 0.57952, testing: 0.833333, t2y: 1
seq2, epoch6, step: 490, training: 1, loss_tr: 0.00579155, loss_t: 0.584157, testing: 0.833333, t2y: 1
seq2, epoch6, step: 500, training: 1, loss_tr: 0.00755222, loss_t: 0.513982, testing: 0.833333, t2y: 1
seq2, epoch6, step: 510, training: 1, loss_tr: 0.00848735, loss_t: 0.468316, testing: 0.833333, t2y: 1
 
****************************************
current sequence is 3
****************************************
seq3, epoch0, step: 0, training: 0.3125, loss_tr: 1.58202, loss_t: 1.98921, testing: 0.166667, t2y: 0.333333
seq3, epoch0, step: 10, training: 0.1875, loss_tr: 1.69143, loss_t: 1.94029, testing: 0.166667, t2y: 0.5
seq3, epoch0, step: 20, training: 0.375, loss_tr: 1.72922, loss_t: 1.9506, testing: 0.222222, t2y: 0.666667
seq3, epoch0, step: 30, training: 0.5625, loss_tr: 1.50569, loss_t: 1.73241, testing: 0.277778, t2y: 0.666667
seq3, epoch0, step: 40, training: 0.625, loss_tr: 1.18907, loss_t: 1.52549, testing: 0.444444, t2y: 0.666667
seq3, epoch0, step: 50, training: 0.375, loss_tr: 0.97507, loss_t: 1.27987, testing: 0.444444, t2y: 0.666667
seq3, epoch0, step: 60, training: 0.6875, loss_tr: 0.959011, loss_t: 1.25548, testing: 0.5, t2y: 0.833333
seq3, epoch0, step: 70, training: 0.75, loss_tr: 0.927288, loss_t: 1.20491, testing: 0.5, t2y: 0.666667
seq3, epoch1, step: 80, training: 0.75, loss_tr: 0.800866, loss_t: 1.09837, testing: 0.611111, t2y: 0.833333
seq3, epoch1, step: 90, training: 0.8125, loss_tr: 0.713854, loss_t: 1.01273, testing: 0.611111, t2y: 0.833333
seq3, epoch1, step: 100, training: 0.875, loss_tr: 0.615568, loss_t: 0.964146, testing: 0.555556, t2y: 1
seq3, epoch1, step: 110, training: 0.8125, loss_tr: 0.535892, loss_t: 0.94129, testing: 0.5, t2y: 0.833333
seq3, epoch1, step: 120, training: 0.9375, loss_tr: 0.468358, loss_t: 0.966872, testing: 0.444444, t2y: 0.833333
seq3, epoch1, step: 130, training: 0.875, loss_tr: 0.491588, loss_t: 0.973992, testing: 0.5, t2y: 0.833333
seq3, epoch1, step: 140, training: 0.8125, loss_tr: 0.493692, loss_t: 0.897198, testing: 0.5, t2y: 1
seq3, epoch1, step: 150, training: 0.875, loss_tr: 0.487761, loss_t: 0.83751, testing: 0.611111, t2y: 0.833333
seq3, epoch2, step: 160, training: 1, loss_tr: 0.342887, loss_t: 0.724417, testing: 0.555556, t2y: 1
seq3, epoch2, step: 170, training: 0.9375, loss_tr: 0.28307, loss_t: 0.78285, testing: 0.666667, t2y: 0.833333
seq3, epoch2, step: 180, training: 0.9375, loss_tr: 0.211314, loss_t: 0.659741, testing: 0.722222, t2y: 0.833333
seq3, epoch2, step: 190, training: 0.9375, loss_tr: 0.205752, loss_t: 0.777714, testing: 0.777778, t2y: 0.833333
seq3, epoch2, step: 200, training: 0.9375, loss_tr: 0.159716, loss_t: 0.659525, testing: 0.777778, t2y: 1
seq3, epoch2, step: 210, training: 1, loss_tr: 0.161364, loss_t: 0.767252, testing: 0.666667, t2y: 0.833333
seq3, epoch2, step: 220, training: 0.8125, loss_tr: 0.162391, loss_t: 0.619263, testing: 0.666667, t2y: 1
seq3, epoch2, step: 230, training: 0.9375, loss_tr: 0.150746, loss_t: 0.717757, testing: 0.611111, t2y: 1
seq3, epoch3, step: 240, training: 1, loss_tr: 0.129292, loss_t: 0.648348, testing: 0.666667, t2y: 0.833333
seq3, epoch3, step: 250, training: 0.9375, loss_tr: 0.10962, loss_t: 0.652913, testing: 0.611111, t2y: 1
seq3, epoch3, step: 260, training: 1, loss_tr: 0.0941311, loss_t: 0.605332, testing: 0.555556, t2y: 0.833333
seq3, epoch3, step: 270, training: 1, loss_tr: 0.0827334, loss_t: 0.551173, testing: 0.555556, t2y: 1
seq3, epoch3, step: 280, training: 1, loss_tr: 0.0442147, loss_t: 0.523136, testing: 0.666667, t2y: 1
seq3, epoch3, step: 290, training: 1, loss_tr: 0.0451406, loss_t: 0.445636, testing: 0.777778, t2y: 1
