Sat Jun 10 22:38:44 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq1, epoch0, step: 0, training: 0.1875, loss_tr: 1.71167, loss_t: 1.97767, testing: 0, t2y: 0
seq1, epoch0, step: 10, training: 0.25, loss_tr: 1.67061, loss_t: 1.96609, testing: 0.111111, t2y: 0.666667
seq1, epoch0, step: 20, training: 0.3125, loss_tr: 1.73128, loss_t: 1.98486, testing: 0.222222, t2y: 0.5
seq1, epoch0, step: 30, training: 0.4375, loss_tr: 1.53545, loss_t: 1.74017, testing: 0.388889, t2y: 0.5
seq1, epoch0, step: 40, training: 0.4375, loss_tr: 1.50718, loss_t: 1.45986, testing: 0.5, t2y: 0.833333
seq1, epoch0, step: 50, training: 0.5, loss_tr: 1.28274, loss_t: 1.09538, testing: 0.555556, t2y: 0.833333
seq1, epoch0, step: 60, training: 0.625, loss_tr: 1.27116, loss_t: 0.930427, testing: 0.666667, t2y: 0.833333
seq1, epoch0, step: 70, training: 0.875, loss_tr: 1.05447, loss_t: 0.806409, testing: 0.722222, t2y: 0.833333
seq1, epoch1, step: 80, training: 0.875, loss_tr: 0.832314, loss_t: 0.700782, testing: 0.833333, t2y: 1
seq1, epoch1, step: 90, training: 0.9375, loss_tr: 0.716623, loss_t: 0.687261, testing: 0.833333, t2y: 1
seq1, epoch1, step: 100, training: 0.875, loss_tr: 0.611712, loss_t: 0.668652, testing: 0.777778, t2y: 0.833333
seq1, epoch1, step: 110, training: 0.9375, loss_tr: 0.554936, loss_t: 0.62865, testing: 0.777778, t2y: 1
seq1, epoch1, step: 120, training: 0.8125, loss_tr: 0.485549, loss_t: 0.534224, testing: 0.777778, t2y: 1
seq1, epoch1, step: 130, training: 0.875, loss_tr: 0.455872, loss_t: 0.456126, testing: 0.888889, t2y: 1
seq1, epoch1, step: 140, training: 0.875, loss_tr: 0.470078, loss_t: 0.426199, testing: 0.888889, t2y: 1
seq1, epoch1, step: 150, training: 1, loss_tr: 0.37616, loss_t: 0.386799, testing: 0.888889, t2y: 1
seq1, epoch2, step: 160, training: 0.875, loss_tr: 0.313068, loss_t: 0.38054, testing: 0.833333, t2y: 0.833333
seq1, epoch2, step: 170, training: 1, loss_tr: 0.281572, loss_t: 0.323489, testing: 0.888889, t2y: 1
seq1, epoch2, step: 180, training: 1, loss_tr: 0.260697, loss_t: 0.318412, testing: 0.888889, t2y: 1
seq1, epoch2, step: 190, training: 0.875, loss_tr: 0.287374, loss_t: 0.236389, testing: 0.888889, t2y: 1
seq1, epoch2, step: 200, training: 1, loss_tr: 0.199828, loss_t: 0.204425, testing: 0.833333, t2y: 1
seq1, epoch2, step: 210, training: 1, loss_tr: 0.170471, loss_t: 0.166128, testing: 0.833333, t2y: 1
seq1, epoch2, step: 220, training: 1, loss_tr: 0.0772732, loss_t: 0.137609, testing: 0.888889, t2y: 1
seq1, epoch2, step: 230, training: 1, loss_tr: 0.0762472, loss_t: 0.178351, testing: 0.888889, t2y: 1
seq1, epoch3, step: 240, training: 1, loss_tr: 0.066687, loss_t: 0.152616, testing: 0.944444, t2y: 1
seq1, epoch3, step: 250, training: 1, loss_tr: 0.0687505, loss_t: 0.167929, testing: 0.888889, t2y: 1
seq1, epoch3, step: 260, training: 0.875, loss_tr: 0.126829, loss_t: 0.119631, testing: 0.888889, t2y: 1
seq1, epoch3, step: 270, training: 0.9375, loss_tr: 0.154002, loss_t: 0.110771, testing: 0.833333, t2y: 1
seq1, epoch3, step: 280, training: 0.9375, loss_tr: 0.153026, loss_t: 0.0834427, testing: 0.888889, t2y: 1
seq1, epoch3, step: 290, training: 0.9375, loss_tr: 0.0925229, loss_t: 0.0811845, testing: 0.888889, t2y: 1
seq1, epoch3, step: 300, training: 1, loss_tr: 0.0553324, loss_t: 0.0883677, testing: 0.888889, t2y: 1
seq1, epoch3, step: 310, training: 1, loss_tr: 0.0470736, loss_t: 0.0866351, testing: 0.888889, t2y: 1
seq1, epoch4, step: 320, training: 1, loss_tr: 0.0387028, loss_t: 0.0840873, testing: 0.888889, t2y: 1
seq1, epoch4, step: 330, training: 1, loss_tr: 0.0411997, loss_t: 0.0696463, testing: 0.944444, t2y: 1
seq1, epoch4, step: 340, training: 1, loss_tr: 0.0346041, loss_t: 0.108121, testing: 0.888889, t2y: 1
seq1, epoch4, step: 350, training: 1, loss_tr: 0.0460681, loss_t: 0.0877546, testing: 0.944444, t2y: 1
seq1, epoch4, step: 360, training: 1, loss_tr: 0.0350784, loss_t: 0.0852097, testing: 0.944444, t2y: 1
seq1, epoch4, step: 370, training: 1, loss_tr: 0.0367006, loss_t: 0.130278, testing: 0.944444, t2y: 1
seq1, epoch4, step: 380, training: 1, loss_tr: 0.017374, loss_t: 0.132316, testing: 0.888889, t2y: 1
seq1, epoch4, step: 390, training: 1, loss_tr: 0.0128116, loss_t: 0.126618, testing: 0.888889, t2y: 1
seq1, epoch5, step: 400, training: 0.9375, loss_tr: 0.0279626, loss_t: 0.076722, testing: 0.888889, t2y: 1
seq1, epoch5, step: 410, training: 1, loss_tr: 0.0310573, loss_t: 0.0676531, testing: 0.944444, t2y: 1
seq1, epoch5, step: 420, training: 0.9375, loss_tr: 0.04149, loss_t: 0.110435, testing: 0.888889, t2y: 1
seq1, epoch5, step: 430, training: 1, loss_tr: 0.0342254, loss_t: 0.0778732, testing: 0.944444, t2y: 1
seq1, epoch5, step: 440, training: 1, loss_tr: 0.0315607, loss_t: 0.147347, testing: 0.888889, t2y: 1
seq1, epoch5, step: 450, training: 1, loss_tr: 0.0300524, loss_t: 0.116596, testing: 0.888889, t2y: 1
seq1, epoch5, step: 460, training: 1, loss_tr: 0.0149843, loss_t: 0.115974, testing: 0.833333, t2y: 1
seq1, epoch5, step: 470, training: 1, loss_tr: 0.0141211, loss_t: 0.0727785, testing: 0.833333, t2y: 1
seq1, epoch6, step: 480, training: 1, loss_tr: 0.0047916, loss_t: 0.0620814, testing: 0.833333, t2y: 1
seq1, epoch6, step: 490, training: 0.9375, loss_tr: 0.0128444, loss_t: 0.0508306, testing: 0.888889, t2y: 1
seq1, epoch6, step: 500, training: 1, loss_tr: 0.0111857, loss_t: 0.0289168, testing: 0.888889, t2y: 1
seq1, epoch6, step: 510, training: 1, loss_tr: 0.0109185, loss_t: 0.0278046, testing: 0.888889, t2y: 1
 
****************************************
current sequence is 2
****************************************
seq2, epoch0, step: 0, training: 0.1875, loss_tr: 1.9019, loss_t: 2.13412, testing: 0.333333, t2y: 0.5
seq2, epoch0, step: 10, training: 0.1875, loss_tr: 1.73276, loss_t: 1.96508, testing: 0.277778, t2y: 0.333333
seq2, epoch0, step: 20, training: 0.5, loss_tr: 1.45956, loss_t: 1.81928, testing: 0.277778, t2y: 0.5
seq2, epoch0, step: 30, training: 0.4375, loss_tr: 1.24034, loss_t: 1.55769, testing: 0.277778, t2y: 0.5
seq2, epoch0, step: 40, training: 0.5, loss_tr: 1.29374, loss_t: 1.55024, testing: 0.388889, t2y: 0.5
seq2, epoch0, step: 50, training: 0.5625, loss_tr: 1.17237, loss_t: 1.3714, testing: 0.333333, t2y: 0.833333
seq2, epoch0, step: 60, training: 0.625, loss_tr: 1.00822, loss_t: 1.27729, testing: 0.444444, t2y: 1
seq2, epoch0, step: 70, training: 0.875, loss_tr: 0.710454, loss_t: 1.10889, testing: 0.333333, t2y: 0.5
seq2, epoch1, step: 80, training: 0.8125, loss_tr: 0.663612, loss_t: 1.09391, testing: 0.444444, t2y: 0.666667
seq2, epoch1, step: 90, training: 1, loss_tr: 0.544098, loss_t: 1.02636, testing: 0.388889, t2y: 0.833333
seq2, epoch1, step: 100, training: 0.8125, loss_tr: 0.51265, loss_t: 0.989023, testing: 0.444444, t2y: 0.5
seq2, epoch1, step: 110, training: 0.875, loss_tr: 0.485042, loss_t: 0.869766, testing: 0.388889, t2y: 1
seq2, epoch1, step: 120, training: 0.875, loss_tr: 0.48717, loss_t: 0.808107, testing: 0.444444, t2y: 1
seq2, epoch1, step: 130, training: 0.9375, loss_tr: 0.421477, loss_t: 0.674487, testing: 0.555556, t2y: 0.833333
seq2, epoch1, step: 140, training: 0.9375, loss_tr: 0.361552, loss_t: 0.639615, testing: 0.611111, t2y: 1
seq2, epoch1, step: 150, training: 0.8125, loss_tr: 0.354145, loss_t: 0.600044, testing: 0.611111, t2y: 1
seq2, epoch2, step: 160, training: 0.875, loss_tr: 0.305025, loss_t: 0.68335, testing: 0.555556, t2y: 0.833333
seq2, epoch2, step: 170, training: 1, loss_tr: 0.260284, loss_t: 0.640334, testing: 0.611111, t2y: 0.833333
seq2, epoch2, step: 180, training: 1, loss_tr: 0.186537, loss_t: 0.758893, testing: 0.611111, t2y: 0.666667
seq2, epoch2, step: 190, training: 0.9375, loss_tr: 0.175562, loss_t: 0.609546, testing: 0.666667, t2y: 1
seq2, epoch2, step: 200, training: 1, loss_tr: 0.172932, loss_t: 0.707441, testing: 0.555556, t2y: 0.833333
seq2, epoch2, step: 210, training: 0.9375, loss_tr: 0.179774, loss_t: 0.532515, testing: 0.611111, t2y: 1
seq2, epoch2, step: 220, training: 0.9375, loss_tr: 0.171994, loss_t: 0.647577, testing: 0.666667, t2y: 0.833333
seq2, epoch2, step: 230, training: 0.9375, loss_tr: 0.164302, loss_t: 0.478272, testing: 0.888889, t2y: 1
seq2, epoch3, step: 240, training: 1, loss_tr: 0.121962, loss_t: 0.558997, testing: 0.833333, t2y: 0.833333
seq2, epoch3, step: 250, training: 1, loss_tr: 0.105821, loss_t: 0.441172, testing: 0.722222, t2y: 1
seq2, epoch3, step: 260, training: 0.9375, loss_tr: 0.100181, loss_t: 0.512888, testing: 0.611111, t2y: 1
seq2, epoch3, step: 270, training: 1, loss_tr: 0.0994245, loss_t: 0.530378, testing: 0.611111, t2y: 1
seq2, epoch3, step: 280, training: 1, loss_tr: 0.0713426, loss_t: 0.555723, testing: 0.611111, t2y: 1
seq2, epoch3, step: 290, training: 1, loss_tr: 0.0483772, loss_t: 0.58413, testing: 0.611111, t2y: 1
seq2, epoch3, step: 300, training: 1, loss_tr: 0.0506222, loss_t: 0.479719, testing: 0.666667, t2y: 1
seq2, epoch3, step: 310, training: 1, loss_tr: 0.0466571, loss_t: 0.57206, testing: 0.777778, t2y: 1
seq2, epoch4, step: 320, training: 1, loss_tr: 0.0388935, loss_t: 0.523916, testing: 0.777778, t2y: 1
seq2, epoch4, step: 330, training: 1, loss_tr: 0.0237861, loss_t: 0.61473, testing: 0.722222, t2y: 1
seq2, epoch4, step: 340, training: 1, loss_tr: 0.0212307, loss_t: 0.535756, testing: 0.722222, t2y: 1
seq2, epoch4, step: 350, training: 1, loss_tr: 0.0138149, loss_t: 0.692341, testing: 0.777778, t2y: 1
seq2, epoch4, step: 360, training: 1, loss_tr: 0.022043, loss_t: 0.708058, testing: 0.777778, t2y: 1
seq2, epoch4, step: 370, training: 0.9375, loss_tr: 0.0242744, loss_t: 0.771898, testing: 0.777778, t2y: 1
seq2, epoch4, step: 380, training: 1, loss_tr: 0.0281723, loss_t: 0.63065, testing: 0.722222, t2y: 1
seq2, epoch4, step: 390, training: 1, loss_tr: 0.0213283, loss_t: 0.631476, testing: 0.722222, t2y: 1
seq2, epoch5, step: 400, training: 1, loss_tr: 0.016, loss_t: 0.703667, testing: 0.666667, t2y: 0.833333
seq2, epoch5, step: 410, training: 1, loss_tr: 0.0121511, loss_t: 0.795917, testing: 0.722222, t2y: 0.833333
seq2, epoch5, step: 420, training: 1, loss_tr: 0.00961696, loss_t: 0.810983, testing: 0.777778, t2y: 1
seq2, epoch5, step: 430, training: 1, loss_tr: 0.0184057, loss_t: 0.652407, testing: 0.833333, t2y: 1
seq2, epoch5, step: 440, training: 1, loss_tr: 0.0147962, loss_t: 0.583702, testing: 0.777778, t2y: 1
seq2, epoch5, step: 450, training: 1, loss_tr: 0.0154026, loss_t: 0.551909, testing: 0.777778, t2y: 1
seq2, epoch5, step: 460, training: 1, loss_tr: 0.00645098, loss_t: 0.556689, testing: 0.777778, t2y: 1
seq2, epoch5, step: 470, training: 1, loss_tr: 0.00605637, loss_t: 0.534662, testing: 0.777778, t2y: 1
seq2, epoch6, step: 480, training: 1, loss_tr: 0.00620382, loss_t: 0.516444, testing: 0.777778, t2y: 1
seq2, epoch6, step: 490, training: 0.9375, loss_tr: 0.0143092, loss_t: 0.510158, testing: 0.722222, t2y: 1
seq2, epoch6, step: 500, training: 1, loss_tr: 0.0130144, loss_t: 0.577186, testing: 0.777778, t2y: 1
seq2, epoch6, step: 510, training: 1, loss_tr: 0.0141861, loss_t: 0.659648, testing: 0.777778, t2y: 1
 
****************************************
current sequence is 3
****************************************
seq3, epoch0, step: 0, training: 0.1875, loss_tr: 1.82311, loss_t: 2.42479, testing: 0.166667, t2y: 0.333333
seq3, epoch0, step: 10, training: 0.125, loss_tr: 1.8211, loss_t: 2.29523, testing: 0.111111, t2y: 0.166667
seq3, epoch0, step: 20, training: 0.375, loss_tr: 1.78446, loss_t: 2.07184, testing: 0.166667, t2y: 0.666667
seq3, epoch0, step: 30, training: 0.3125, loss_tr: 1.70171, loss_t: 1.82543, testing: 0.222222, t2y: 0.5
seq3, epoch0, step: 40, training: 0.5625, loss_tr: 1.44296, loss_t: 1.65773, testing: 0.388889, t2y: 0.5
seq3, epoch0, step: 50, training: 0.625, loss_tr: 1.31342, loss_t: 1.55628, testing: 0.333333, t2y: 0.5
seq3, epoch0, step: 60, training: 0.6875, loss_tr: 1.06904, loss_t: 1.41044, testing: 0.388889, t2y: 0.666667
seq3, epoch0, step: 70, training: 0.8125, loss_tr: 1.02384, loss_t: 1.28193, testing: 0.388889, t2y: 0.833333
seq3, epoch1, step: 80, training: 0.75, loss_tr: 0.855766, loss_t: 1.18901, testing: 0.444444, t2y: 0.666667
seq3, epoch1, step: 90, training: 0.875, loss_tr: 0.783526, loss_t: 1.13938, testing: 0.5, t2y: 0.666667
seq3, epoch1, step: 100, training: 0.75, loss_tr: 0.714586, loss_t: 1.09805, testing: 0.5, t2y: 1
seq3, epoch1, step: 110, training: 0.8125, loss_tr: 0.690329, loss_t: 1.04395, testing: 0.555556, t2y: 0.833333
seq3, epoch1, step: 120, training: 0.875, loss_tr: 0.637289, loss_t: 0.950713, testing: 0.555556, t2y: 0.666667
seq3, epoch1, step: 130, training: 1, loss_tr: 0.513032, loss_t: 0.898899, testing: 0.611111, t2y: 0.833333
seq3, epoch1, step: 140, training: 0.875, loss_tr: 0.412652, loss_t: 0.810393, testing: 0.666667, t2y: 0.833333
seq3, epoch1, step: 150, training: 1, loss_tr: 0.357718, loss_t: 0.797193, testing: 0.611111, t2y: 0.833333
seq3, epoch2, step: 160, training: 0.875, loss_tr: 0.336089, loss_t: 0.742403, testing: 0.611111, t2y: 1
seq3, epoch2, step: 170, training: 0.8125, loss_tr: 0.332375, loss_t: 0.73054, testing: 0.555556, t2y: 0.833333
seq3, epoch2, step: 180, training: 1, loss_tr: 0.299183, loss_t: 0.747834, testing: 0.611111, t2y: 0.666667
seq3, epoch2, step: 190, training: 1, loss_tr: 0.284768, loss_t: 0.755136, testing: 0.611111, t2y: 1
seq3, epoch2, step: 200, training: 1, loss_tr: 0.197021, loss_t: 0.780288, testing: 0.611111, t2y: 1
seq3, epoch2, step: 210, training: 0.9375, loss_tr: 0.205803, loss_t: 0.795803, testing: 0.611111, t2y: 0.833333
seq3, epoch2, step: 220, training: 1, loss_tr: 0.169997, loss_t: 0.928381, testing: 0.555556, t2y: 1
seq3, epoch2, step: 230, training: 1, loss_tr: 0.143013, loss_t: 0.8908, testing: 0.611111, t2y: 1
seq3, epoch3, step: 240, training: 1, loss_tr: 0.106984, loss_t: 0.817511, testing: 0.555556, t2y: 1
seq3, epoch3, step: 250, training: 0.875, loss_tr: 0.119415, loss_t: 0.618923, testing: 0.611111, t2y: 1
seq3, epoch3, step: 260, training: 1, loss_tr: 0.10911, loss_t: 0.731226, testing: 0.555556, t2y: 0.833333
seq3, epoch3, step: 270, training: 0.875, loss_tr: 0.144869, loss_t: 0.741791, testing: 0.611111, t2y: 1
seq3, epoch3, step: 280, training: 1, loss_tr: 0.10986, loss_t: 0.749214, testing: 0.666667, t2y: 1
seq3, epoch3, step: 290, training: 1, loss_tr: 0.108778, loss_t: 0.592425, testing: 0.722222, t2y: 1
seq3, epoch3, step: 300, training: 1, loss_tr: 0.0465894, loss_t: 0.566612, testing: 0.722222, t2y: 0.833333
seq3, epoch3, step: 310, training: 1, loss_tr: 0.0519023, loss_t: 0.619357, testing: 0.666667, t2y: 1
seq3, epoch4, step: 320, training: 0.9375, loss_tr: 0.04013, loss_t: 0.546078, testing: 0.777778, t2y: 1
seq3, epoch4, step: 330, training: 1, loss_tr: 0.0321923, loss_t: 0.640277, testing: 0.777778, t2y: 1
seq3, epoch4, step: 340, training: 1, loss_tr: 0.018241, loss_t: 0.547098, testing: 0.777778, t2y: 1
seq3, epoch4, step: 350, training: 1, loss_tr: 0.024613, loss_t: 0.640296, testing: 0.666667, t2y: 1
seq3, epoch4, step: 360, training: 0.9375, loss_tr: 0.0324086, loss_t: 0.541367, testing: 0.666667, t2y: 1
seq3, epoch4, step: 370, training: 1, loss_tr: 0.0323143, loss_t: 0.545738, testing: 0.666667, t2y: 1
seq3, epoch4, step: 380, training: 1, loss_tr: 0.0297528, loss_t: 0.445956, testing: 0.777778, t2y: 1
seq3, epoch4, step: 390, training: 1, loss_tr: 0.0254299, loss_t: 0.37929, testing: 0.777778, t2y: 1
seq3, epoch5, step: 400, training: 1, loss_tr: 0.029703, loss_t: 0.429972, testing: 0.777778, t2y: 1
seq3, epoch5, step: 410, training: 1, loss_tr: 0.0219799, loss_t: 0.498506, testing: 0.722222, t2y: 1
seq3, epoch5, step: 420, training: 1, loss_tr: 0.0169943, loss_t: 0.633528, testing: 0.722222, t2y: 1
seq3, epoch5, step: 430, training: 1, loss_tr: 0.0182739, loss_t: 0.597043, testing: 0.722222, t2y: 1
seq3, epoch5, step: 440, training: 0.9375, loss_tr: 0.0216251, loss_t: 0.657732, testing: 0.666667, t2y: 1
seq3, epoch5, step: 450, training: 1, loss_tr: 0.0190335, loss_t: 0.481655, testing: 0.777778, t2y: 1
seq3, epoch5, step: 460, training: 1, loss_tr: 0.0120817, loss_t: 0.458656, testing: 0.833333, t2y: 1
seq3, epoch5, step: 470, training: 1, loss_tr: 0.00791223, loss_t: 0.460318, testing: 0.888889, t2y: 1
seq3, epoch6, step: 480, training: 1, loss_tr: 0.0112876, loss_t: 0.587301, testing: 0.777778, t2y: 1
seq3, epoch6, step: 490, training: 1, loss_tr: 0.0106068, loss_t: 0.614572, testing: 0.722222, t2y: 1
