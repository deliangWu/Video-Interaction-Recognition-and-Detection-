Sun May  7 20:06:11 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
****************************************
current sequence is 4
****************************************
epoch: 0, step: 0, training: 0.375, loss: 1.83035e+11, testing: 0.166667, anv: 0.0555556, best: 0.0555556 
epoch: 1, step: 20, training: 0.1875, loss: 2.99658e+10, testing: 0.166667, anv: 0.111111, best: 0.111111 
epoch: 2, step: 40, training: 0.375, loss: 1.22593e+10, testing: 0.333333, anv: 0.222222, best: 0.222222 
epoch: 3, step: 60, training: 0.625, loss: 5.92647e+09, testing: 0.5, anv: 0.333333, best: 0.333333 
epoch: 4, step: 80, training: 0.5625, loss: 1.20081e+09, testing: 0.333333, anv: 0.388889, best: 0.388889 
epoch: 5, step: 100, training: 0.5, loss: 8.86693e+08, testing: 0.166667, anv: 0.333333, best: 0.388889 
epoch: 6, step: 120, training: 0.625, loss: 5.40352e+08, testing: 0.333333, anv: 0.277778, best: 0.388889 
epoch: 7, step: 140, training: 0.4375, loss: 8.15789e+08, testing: 0.166667, anv: 0.222222, best: 0.388889 
epoch: 8, step: 160, training: 0.625, loss: 5.3709e+08, testing: 0.166667, anv: 0.222222, best: 0.388889 
epoch: 9, step: 180, training: 0.8125, loss: 1.90265e+08, testing: 0.166667, anv: 0.166667, best: 0.388889 
epoch: 10, step: 200, training: 0.6875, loss: 1.22765e+08, testing: 0.333333, anv: 0.222222, best: 0.388889 
epoch: 11, step: 220, training: 0.75, loss: 1.00272e+08, testing: 0.333333, anv: 0.277778, best: 0.388889 
epoch: 12, step: 240, training: 0.5625, loss: 1.21218e+08, testing: 0.333333, anv: 0.333333, best: 0.388889 
epoch: 13, step: 260, training: 0.6875, loss: 2.04188e+08, testing: 0.166667, anv: 0.277778, best: 0.388889 
epoch: 14, step: 280, training: 0.6875, loss: 5.72285e+07, testing: 0.333333, anv: 0.277778, best: 0.388889 
epoch: 15, step: 300, training: 0.5625, loss: 9.04778e+07, testing: 0.333333, anv: 0.277778, best: 0.388889 
epoch: 16, step: 320, training: 0.8125, loss: 5.95353e+07, testing: 0.333333, anv: 0.333333, best: 0.388889 
epoch: 17, step: 340, training: 0.875, loss: 3.96403e+07, testing: 0.333333, anv: 0.333333, best: 0.388889 
epoch: 18, step: 360, training: 0.9375, loss: 2.4199e+07, testing: 0.5, anv: 0.388889, best: 0.388889 
epoch: 19, step: 380, training: 0.625, loss: 5.25288e+07, testing: 0.333333, anv: 0.388889, best: 0.388889 
epoch: 20, step: 400, training: 0.8125, loss: 1.82421e+07, testing: 0.5, anv: 0.444444, best: 0.444444 
epoch: 21, step: 420, training: 1, loss: 2.07683e+07, testing: 0.333333, anv: 0.388889, best: 0.444444 
epoch: 22, step: 440, training: 0.875, loss: 2.59483e+07, testing: 0.166667, anv: 0.333333, best: 0.444444 
epoch: 23, step: 460, training: 0.8125, loss: 2.52042e+07, testing: 0.333333, anv: 0.277778, best: 0.444444 
epoch: 24, step: 480, training: 0.75, loss: 1.43367e+07, testing: 0.5, anv: 0.333333, best: 0.444444 
epoch: 25, step: 500, training: 0.875, loss: 9.87672e+06, testing: 0.5, anv: 0.444444, best: 0.444444 
epoch: 26, step: 520, training: 0.8125, loss: 1.70857e+07, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 27, step: 540, training: 0.875, loss: 3.61408e+06, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 28, step: 560, training: 0.875, loss: 1.00848e+07, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 29, step: 580, training: 0.6875, loss: 1.05021e+07, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 30, step: 600, training: 0.875, loss: 1.24544e+07, testing: 0.333333, anv: 0.444444, best: 0.5 
epoch: 31, step: 620, training: 0.75, loss: 1.25814e+07, testing: 0.5, anv: 0.444444, best: 0.5 
epoch: 32, step: 640, training: 1, loss: 5.03141e+06, testing: 0.5, anv: 0.444444, best: 0.5 
epoch: 33, step: 660, training: 0.5625, loss: 1.60381e+07, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 34, step: 680, training: 0.8125, loss: 7.57698e+06, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 35, step: 700, training: 0.8125, loss: 1.05146e+07, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 36, step: 720, training: 0.8125, loss: 6.22513e+06, testing: 0.333333, anv: 0.444444, best: 0.5 
epoch: 37, step: 740, training: 0.5625, loss: 6.64024e+06, testing: 0.5, anv: 0.444444, best: 0.5 
epoch: 38, step: 760, training: 0.625, loss: 5.97153e+06, testing: 0.5, anv: 0.444444, best: 0.5 
epoch: 39, step: 780, training: 0.5625, loss: 5.12658e+06, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 40, step: 800, training: 0.8125, loss: 2.90408e+06, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 41, step: 820, training: 0.6875, loss: 1.0099e+07, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 42, step: 840, training: 0.6875, loss: 9.44918e+06, testing: 0.5, anv: 0.5, best: 0.5 
epoch: 43, step: 860, training: 0.75, loss: 3.16989e+06, testing: 0.333333, anv: 0.444444, best: 0.5 
epoch: 44, step: 880, training: 0.75, loss: 1.64033e+06, testing: 0.333333, anv: 0.388889, best: 0.5 
epoch: 45, step: 900, training: 0.6875, loss: 2.89151e+06, testing: 0.333333, anv: 0.333333, best: 0.5 
epoch: 46, step: 920, training: 0.625, loss: 1.74468e+06, testing: 0.333333, anv: 0.333333, best: 0.5 
epoch: 47, step: 940, training: 0.625, loss: 887071, testing: 0.333333, anv: 0.333333, best: 0.5 
epoch: 48, step: 960, training: 0.6875, loss: 267036, testing: 0.333333, anv: 0.333333, best: 0.5 
epoch: 49, step: 980, training: 0.625, loss: 5.06272e+06, testing: 0.333333, anv: 0.333333, best: 0.5 
epoch: 50, step: 1000, training: 0.6875, loss: 3.12967e+06, testing: 0.333333, anv: 0.333333, best: 0.5 
epoch: 51, step: 1020, training: 0.625, loss: 88214.2, testing: 0.333333, anv: 0.333333, best: 0.5 
epoch: 52, step: 1040, training: 0.6875, loss: 308151, testing: 0.333333, anv: 0.333333, best: 0.5 
epoch: 53, step: 1060, training: 0.625, loss: 1.31111e+06, testing: 0.666667, anv: 0.444444, best: 0.5 
epoch: 54, step: 1080, training: 0.625, loss: 2.4494e+06, testing: 0.333333, anv: 0.444444, best: 0.5 
epoch: 55, step: 1100, training: 0.625, loss: 7.78281e+06, testing: 0.166667, anv: 0.388889, best: 0.5 
epoch: 56, step: 1120, training: 0.75, loss: 294640, testing: 0.333333, anv: 0.277778, best: 0.5 
epoch: 57, step: 1140, training: 0.6875, loss: 34041.4, testing: 0.333333, anv: 0.277778, best: 0.5 
epoch: 58, step: 1160, training: 0.5625, loss: 4.52349e+06, testing: 0.333333, anv: 0.333333, best: 0.5 
