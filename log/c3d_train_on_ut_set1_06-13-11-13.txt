Tue Jun 13 11:13:22 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq: 1, epoch: 0, step: 0, training: 0.5, testing: 0.736842, loss_tr: 0.733091, loss_t: 0.601506  
seq: 1, epoch: 0, step: 10, training: 0.4375, testing: 0.736842, loss_tr: 0.844594, loss_t: 0.578333  
seq: 1, epoch: 0, step: 20, training: 0.6875, testing: 0.736842, loss_tr: 0.638078, loss_t: 0.617649  
seq: 1, epoch: 0, step: 30, training: 0.625, testing: 0.736842, loss_tr: 0.690187, loss_t: 0.575061  
seq: 1, epoch: 0, step: 40, training: 0.6875, testing: 0.736842, loss_tr: 0.630099, loss_t: 0.604506  
seq: 1, epoch: 0, step: 50, training: 0.625, testing: 0.736842, loss_tr: 0.68574, loss_t: 0.572756  
seq: 1, epoch: 0, step: 60, training: 0.5, testing: 0.736842, loss_tr: 0.979735, loss_t: 0.603665  
seq: 1, epoch: 0, step: 70, training: 0.6875, testing: 0.736842, loss_tr: 0.6167, loss_t: 0.57303  
seq: 1, epoch: 0, step: 80, training: 0.875, testing: 0.736842, loss_tr: 0.389105, loss_t: 0.585049  
seq: 1, epoch: 0, step: 90, training: 0.5625, testing: 0.736842, loss_tr: 0.866465, loss_t: 0.595592  
seq: 1, epoch: 0, step: 100, training: 0.6875, testing: 0.736842, loss_tr: 0.611998, loss_t: 0.580814  
seq: 1, epoch: 0, step: 110, training: 0.5625, testing: 0.736842, loss_tr: 0.678854, loss_t: 0.56779  
seq: 1, epoch: 0, step: 120, training: 0.8125, testing: 0.736842, loss_tr: 0.528758, loss_t: 0.569203  
seq: 1, epoch: 0, step: 130, training: 0.875, testing: 0.736842, loss_tr: 0.3929, loss_t: 0.578964  
seq: 1, epoch: 0, step: 140, training: 0.5, testing: 0.736842, loss_tr: 0.94598, loss_t: 0.592866  
seq: 1, epoch: 0, step: 150, training: 0.75, testing: 0.736842, loss_tr: 0.553352, loss_t: 0.5659  
seq: 1, epoch: 0, step: 160, training: 0.5625, testing: 0.736842, loss_tr: 0.658968, loss_t: 0.577802  
seq: 1, epoch: 0, step: 170, training: 0.75, testing: 0.736842, loss_tr: 0.576577, loss_t: 0.56408  
seq: 1, epoch: 0, step: 180, training: 0.6875, testing: 0.736842, loss_tr: 0.636478, loss_t: 0.556356  
seq: 1, epoch: 0, step: 190, training: 0.6875, testing: 0.736842, loss_tr: 0.585913, loss_t: 0.5834  
seq: 1, epoch: 0, step: 200, training: 0.6875, testing: 0.736842, loss_tr: 0.58324, loss_t: 0.563174  
seq: 1, epoch: 1, step: 210, training: 0.5625, testing: 0.736842, loss_tr: 0.668203, loss_t: 0.553741  
seq: 1, epoch: 1, step: 220, training: 0.5625, testing: 0.736842, loss_tr: 0.702421, loss_t: 0.55148  
seq: 1, epoch: 1, step: 230, training: 0.6875, testing: 0.736842, loss_tr: 0.646135, loss_t: 0.562916  
seq: 1, epoch: 1, step: 240, training: 0.6875, testing: 0.736842, loss_tr: 0.603684, loss_t: 0.558231  
seq: 1, epoch: 1, step: 250, training: 0.75, testing: 0.736842, loss_tr: 0.54044, loss_t: 0.542827  
seq: 1, epoch: 1, step: 260, training: 0.6875, testing: 0.736842, loss_tr: 0.58347, loss_t: 0.538689  
seq: 1, epoch: 1, step: 270, training: 0.625, testing: 0.736842, loss_tr: 0.622527, loss_t: 0.582307  
seq: 1, epoch: 1, step: 280, training: 0.75, testing: 0.736842, loss_tr: 0.518662, loss_t: 0.550282  
seq: 1, epoch: 1, step: 290, training: 0.75, testing: 0.789474, loss_tr: 0.618675, loss_t: 0.576003  
seq: 1, epoch: 1, step: 300, training: 0.5, testing: 0.736842, loss_tr: 0.743127, loss_t: 0.520991  
seq: 1, epoch: 1, step: 310, training: 0.5, testing: 0.736842, loss_tr: 0.69419, loss_t: 0.51873  
seq: 1, epoch: 1, step: 320, training: 0.6875, testing: 0.736842, loss_tr: 0.624755, loss_t: 0.512233  
seq: 1, epoch: 1, step: 330, training: 0.625, testing: 0.736842, loss_tr: 0.643331, loss_t: 0.517499  
seq: 1, epoch: 1, step: 340, training: 0.9375, testing: 0.736842, loss_tr: 0.483378, loss_t: 0.494837  
seq: 1, epoch: 1, step: 350, training: 0.625, testing: 0.736842, loss_tr: 0.571225, loss_t: 0.475317  
seq: 1, epoch: 1, step: 360, training: 0.9375, testing: 0.736842, loss_tr: 0.393199, loss_t: 0.459608  
seq: 1, epoch: 1, step: 370, training: 0.8125, testing: 0.736842, loss_tr: 0.340719, loss_t: 0.448072  
seq: 1, epoch: 1, step: 380, training: 0.6875, testing: 0.789474, loss_tr: 0.596151, loss_t: 0.427646  
seq: 1, epoch: 1, step: 390, training: 0.875, testing: 0.736842, loss_tr: 0.305749, loss_t: 0.444022  
seq: 1, epoch: 1, step: 400, training: 0.875, testing: 0.789474, loss_tr: 0.469841, loss_t: 0.406892  
seq: 1, epoch: 1, step: 410, training: 0.875, testing: 0.789474, loss_tr: 0.355329, loss_t: 0.387614  
seq: 1, epoch: 2, step: 420, training: 0.625, testing: 0.736842, loss_tr: 0.643334, loss_t: 0.397989  
seq: 1, epoch: 2, step: 430, training: 0.875, testing: 0.736842, loss_tr: 0.409294, loss_t: 0.35719  
seq: 1, epoch: 2, step: 440, training: 0.75, testing: 0.894737, loss_tr: 0.47618, loss_t: 0.336006  
seq: 1, epoch: 2, step: 450, training: 0.9375, testing: 0.842105, loss_tr: 0.327793, loss_t: 0.324879  
seq: 1, epoch: 2, step: 460, training: 0.6875, testing: 0.736842, loss_tr: 0.53766, loss_t: 0.391  
seq: 1, epoch: 2, step: 470, training: 0.75, testing: 0.894737, loss_tr: 0.448645, loss_t: 0.301608  
seq: 1, epoch: 2, step: 480, training: 0.9375, testing: 0.894737, loss_tr: 0.39058, loss_t: 0.303673  
seq: 1, epoch: 2, step: 490, training: 0.75, testing: 0.736842, loss_tr: 0.376199, loss_t: 0.360431  
seq: 1, epoch: 2, step: 500, training: 0.875, testing: 0.894737, loss_tr: 0.401437, loss_t: 0.296098  
seq: 1, epoch: 2, step: 510, training: 0.9375, testing: 0.894737, loss_tr: 0.251705, loss_t: 0.289512  
seq: 1, epoch: 2, step: 520, training: 0.625, testing: 0.894737, loss_tr: 0.514982, loss_t: 0.283948  
seq: 1, epoch: 2, step: 530, training: 0.8125, testing: 0.894737, loss_tr: 0.38588, loss_t: 0.272046  
seq: 1, epoch: 2, step: 540, training: 0.8125, testing: 0.894737, loss_tr: 0.441954, loss_t: 0.274628  
seq: 1, epoch: 2, step: 550, training: 0.9375, testing: 0.894737, loss_tr: 0.328365, loss_t: 0.255437  
seq: 1, epoch: 2, step: 560, training: 0.6875, testing: 0.894737, loss_tr: 0.669454, loss_t: 0.261865  
seq: 1, epoch: 2, step: 570, training: 0.75, testing: 0.894737, loss_tr: 0.428704, loss_t: 0.301406  
seq: 1, epoch: 2, step: 580, training: 0.75, testing: 0.894737, loss_tr: 0.627881, loss_t: 0.24977  
seq: 1, epoch: 2, step: 590, training: 0.875, testing: 0.894737, loss_tr: 0.254445, loss_t: 0.327136  
seq: 1, epoch: 2, step: 600, training: 0.875, testing: 0.894737, loss_tr: 0.191358, loss_t: 0.233445  
seq: 1, epoch: 2, step: 610, training: 0.875, testing: 0.894737, loss_tr: 0.344785, loss_t: 0.251577  
seq: 1, epoch: 2, step: 620, training: 1, testing: 0.947368, loss_tr: 0.226895, loss_t: 0.229309  
seq: 1, epoch: 3, step: 630, training: 0.875, testing: 0.947368, loss_tr: 0.191636, loss_t: 0.231487  
seq: 1, epoch: 3, step: 640, training: 0.8125, testing: 0.894737, loss_tr: 0.377481, loss_t: 0.241683  
seq: 1, epoch: 3, step: 650, training: 1, testing: 0.894737, loss_tr: 0.186384, loss_t: 0.214463  
seq: 1, epoch: 3, step: 660, training: 0.875, testing: 0.894737, loss_tr: 0.366484, loss_t: 0.191729  
seq: 1, epoch: 3, step: 670, training: 0.9375, testing: 0.894737, loss_tr: 0.248957, loss_t: 0.190781  
seq: 1, epoch: 3, step: 680, training: 0.9375, testing: 0.894737, loss_tr: 0.265875, loss_t: 0.276305  
seq: 1, epoch: 3, step: 690, training: 0.6875, testing: 0.894737, loss_tr: 0.4812, loss_t: 0.269636  
seq: 1, epoch: 3, step: 700, training: 0.9375, testing: 0.894737, loss_tr: 0.213416, loss_t: 0.193654  
seq: 1, epoch: 3, step: 710, training: 0.6875, testing: 0.894737, loss_tr: 0.601103, loss_t: 0.254039  
seq: 1, epoch: 3, step: 720, training: 1, testing: 0.894737, loss_tr: 0.18353, loss_t: 0.194235  
seq: 1, epoch: 3, step: 730, training: 1, testing: 0.894737, loss_tr: 0.0968968, loss_t: 0.259851  
seq: 1, epoch: 3, step: 740, training: 0.6875, testing: 0.894737, loss_tr: 0.33979, loss_t: 0.224741  
seq: 1, epoch: 3, step: 750, training: 0.875, testing: 0.894737, loss_tr: 0.497719, loss_t: 0.254362  
seq: 1, epoch: 3, step: 760, training: 0.6875, testing: 0.894737, loss_tr: 0.553481, loss_t: 0.284204  
seq: 1, epoch: 3, step: 770, training: 0.9375, testing: 0.894737, loss_tr: 0.268365, loss_t: 0.169816  
seq: 1, epoch: 3, step: 780, training: 1, testing: 0.894737, loss_tr: 0.0956123, loss_t: 0.167145  
seq: 1, epoch: 3, step: 790, training: 0.875, testing: 0.894737, loss_tr: 0.356122, loss_t: 0.285085  
seq: 1, epoch: 3, step: 800, training: 0.8125, testing: 0.894737, loss_tr: 0.297191, loss_t: 0.221273  
seq: 1, epoch: 3, step: 810, training: 0.875, testing: 0.894737, loss_tr: 0.41435, loss_t: 0.182651  
seq: 1, epoch: 3, step: 820, training: 0.9375, testing: 0.894737, loss_tr: 0.253719, loss_t: 0.143511  
seq: 1, epoch: 3, step: 830, training: 1, testing: 0.894737, loss_tr: 0.256373, loss_t: 0.160314  
seq: 1, epoch: 4, step: 840, training: 1, testing: 0.894737, loss_tr: 0.135966, loss_t: 0.165897  
seq: 1, epoch: 4, step: 850, training: 0.75, testing: 0.894737, loss_tr: 0.475076, loss_t: 0.19923  
seq: 1, epoch: 4, step: 860, training: 0.875, testing: 0.947368, loss_tr: 0.349529, loss_t: 0.136505  
seq: 1, epoch: 4, step: 870, training: 1, testing: 0.894737, loss_tr: 0.0806481, loss_t: 0.161516  
seq: 1, epoch: 4, step: 880, training: 0.9375, testing: 0.894737, loss_tr: 0.193647, loss_t: 0.170952  
seq: 1, epoch: 4, step: 890, training: 0.9375, testing: 0.894737, loss_tr: 0.173627, loss_t: 0.204674  
seq: 1, epoch: 4, step: 900, training: 1, testing: 0.894737, loss_tr: 0.0848414, loss_t: 0.198414  
seq: 1, epoch: 4, step: 910, training: 0.875, testing: 0.894737, loss_tr: 0.282364, loss_t: 0.227809  
seq: 1, epoch: 4, step: 920, training: 0.9375, testing: 0.894737, loss_tr: 0.161866, loss_t: 0.142232  
seq: 1, epoch: 4, step: 930, training: 1, testing: 0.894737, loss_tr: 0.0702605, loss_t: 0.224162  
seq: 1, epoch: 4, step: 940, training: 0.875, testing: 0.894737, loss_tr: 0.34798, loss_t: 0.17559  
seq: 1, epoch: 4, step: 950, training: 1, testing: 0.894737, loss_tr: 0.184169, loss_t: 0.184134  
seq: 1, epoch: 4, step: 960, training: 0.875, testing: 0.894737, loss_tr: 0.199706, loss_t: 0.152727  
seq: 1, epoch: 4, step: 970, training: 0.875, testing: 0.894737, loss_tr: 0.189167, loss_t: 0.251027  
seq: 1, epoch: 4, step: 980, training: 1, testing: 0.894737, loss_tr: 0.0987287, loss_t: 0.150789  
seq: 1, epoch: 4, step: 990, training: 1, testing: 0.894737, loss_tr: 0.0595703, loss_t: 0.187502  
seq: 1, epoch: 4, step: 1000, training: 1, testing: 0.894737, loss_tr: 0.095735, loss_t: 0.230159  
 
