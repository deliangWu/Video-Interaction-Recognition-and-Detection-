Sat Jun 10 12:13:42 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq1, epoch0, step: 0, training: 0, loss_tr: 3.06702, loss_t: 2.10415, testing: 0.333333, t2y: 0.333333
seq1, epoch0, step: 10, training: 0.125, loss_tr: 2.86669, loss_t: 1.98771, testing: 0.333333, t2y: 0.333333
seq1, epoch0, step: 20, training: 0.125, loss_tr: 2.95028, loss_t: 1.89602, testing: 0.333333, t2y: 0.333333
seq1, epoch0, step: 30, training: 0.25, loss_tr: 2.51098, loss_t: 1.77409, testing: 0.277778, t2y: 0.5
seq1, epoch0, step: 40, training: 0.25, loss_tr: 2.39818, loss_t: 1.71746, testing: 0.222222, t2y: 0.5
seq1, epoch0, step: 50, training: 0.1875, loss_tr: 2.17797, loss_t: 1.6609, testing: 0.222222, t2y: 0.666667
seq1, epoch0, step: 60, training: 0.4375, loss_tr: 2.16299, loss_t: 1.56874, testing: 0.333333, t2y: 0.666667
seq1, epoch0, step: 70, training: 0.375, loss_tr: 1.89663, loss_t: 1.55009, testing: 0.388889, t2y: 0.666667
seq1, epoch1, step: 80, training: 0.625, loss_tr: 1.684, loss_t: 1.46997, testing: 0.444444, t2y: 0.666667
seq1, epoch1, step: 90, training: 0.4375, loss_tr: 1.91497, loss_t: 1.44141, testing: 0.388889, t2y: 0.5
seq1, epoch1, step: 100, training: 0.875, loss_tr: 2.13727, loss_t: 1.34403, testing: 0.444444, t2y: 0.666667
seq1, epoch1, step: 110, training: 0.6875, loss_tr: 1.93462, loss_t: 1.28816, testing: 0.388889, t2y: 0.666667
seq1, epoch1, step: 120, training: 0.5625, loss_tr: 1.73076, loss_t: 1.23429, testing: 0.444444, t2y: 0.666667
seq1, epoch1, step: 130, training: 0.75, loss_tr: 1.71732, loss_t: 1.22124, testing: 0.5, t2y: 0.833333
seq1, epoch1, step: 140, training: 0.75, loss_tr: 1.66774, loss_t: 1.19792, testing: 0.555556, t2y: 0.666667
seq1, epoch1, step: 150, training: 0.6875, loss_tr: 1.42078, loss_t: 1.17135, testing: 0.555556, t2y: 0.833333
seq1, epoch2, step: 160, training: 0.75, loss_tr: 1.16262, loss_t: 1.12007, testing: 0.555556, t2y: 1
seq1, epoch2, step: 170, training: 0.625, loss_tr: 1.52285, loss_t: 1.04938, testing: 0.611111, t2y: 0.833333
seq1, epoch2, step: 180, training: 0.875, loss_tr: 1.69886, loss_t: 1.00839, testing: 0.666667, t2y: 0.833333
seq1, epoch2, step: 190, training: 0.625, loss_tr: 1.73219, loss_t: 0.973653, testing: 0.666667, t2y: 0.833333
seq1, epoch2, step: 200, training: 0.625, loss_tr: 1.57319, loss_t: 0.958111, testing: 0.722222, t2y: 0.833333
seq1, epoch2, step: 210, training: 0.75, loss_tr: 1.34084, loss_t: 0.90136, testing: 0.777778, t2y: 1
seq1, epoch2, step: 220, training: 0.8125, loss_tr: 1.34315, loss_t: 0.86324, testing: 0.833333, t2y: 1
seq1, epoch2, step: 230, training: 0.75, loss_tr: 1.11624, loss_t: 0.853808, testing: 0.777778, t2y: 0.833333
seq1, epoch3, step: 240, training: 0.9375, loss_tr: 1.28019, loss_t: 0.859697, testing: 0.722222, t2y: 1
seq1, epoch3, step: 250, training: 0.875, loss_tr: 1.24842, loss_t: 0.846317, testing: 0.666667, t2y: 1
seq1, epoch3, step: 260, training: 0.8125, loss_tr: 1.29192, loss_t: 0.821311, testing: 0.722222, t2y: 0.833333
seq1, epoch3, step: 270, training: 0.9375, loss_tr: 1.21251, loss_t: 0.769818, testing: 0.777778, t2y: 1
seq1, epoch3, step: 280, training: 0.5625, loss_tr: 1.20428, loss_t: 0.771098, testing: 0.833333, t2y: 1
seq1, epoch3, step: 290, training: 0.6875, loss_tr: 1.21343, loss_t: 0.751921, testing: 0.833333, t2y: 1
seq1, epoch3, step: 300, training: 0.6875, loss_tr: 1.23946, loss_t: 0.748014, testing: 0.833333, t2y: 0.833333
seq1, epoch3, step: 310, training: 0.75, loss_tr: 1.08924, loss_t: 0.710001, testing: 0.833333, t2y: 0.833333
seq1, epoch4, step: 320, training: 0.875, loss_tr: 0.94762, loss_t: 0.68425, testing: 0.722222, t2y: 1
seq1, epoch4, step: 330, training: 0.875, loss_tr: 0.776612, loss_t: 0.669496, testing: 0.666667, t2y: 1
seq1, epoch4, step: 340, training: 0.9375, loss_tr: 0.708763, loss_t: 0.636901, testing: 0.666667, t2y: 1
seq1, epoch4, step: 350, training: 1, loss_tr: 0.866223, loss_t: 0.587053, testing: 0.833333, t2y: 1
seq1, epoch4, step: 360, training: 0.9375, loss_tr: 0.822827, loss_t: 0.587922, testing: 0.833333, t2y: 0.833333
seq1, epoch4, step: 370, training: 0.875, loss_tr: 0.863224, loss_t: 0.582109, testing: 0.833333, t2y: 1
seq1, epoch4, step: 380, training: 0.75, loss_tr: 0.600455, loss_t: 0.572735, testing: 0.777778, t2y: 1
seq1, epoch4, step: 390, training: 0.6875, loss_tr: 0.664411, loss_t: 0.51754, testing: 0.888889, t2y: 1
seq1, epoch5, step: 400, training: 0.8125, loss_tr: 0.694085, loss_t: 0.512066, testing: 0.833333, t2y: 1
seq1, epoch5, step: 410, training: 0.875, loss_tr: 0.65882, loss_t: 0.502126, testing: 0.833333, t2y: 1
seq1, epoch5, step: 420, training: 0.9375, loss_tr: 0.684656, loss_t: 0.491748, testing: 0.777778, t2y: 1
seq1, epoch5, step: 430, training: 0.9375, loss_tr: 0.612279, loss_t: 0.459189, testing: 0.833333, t2y: 1
seq1, epoch5, step: 440, training: 0.875, loss_tr: 0.740875, loss_t: 0.446807, testing: 0.833333, t2y: 1
seq1, epoch5, step: 450, training: 1, loss_tr: 0.740579, loss_t: 0.449273, testing: 0.833333, t2y: 1
seq1, epoch5, step: 460, training: 0.875, loss_tr: 0.763349, loss_t: 0.48154, testing: 0.833333, t2y: 1
seq1, epoch5, step: 470, training: 0.875, loss_tr: 0.727073, loss_t: 0.455892, testing: 0.888889, t2y: 1
seq1, epoch6, step: 480, training: 0.9375, loss_tr: 0.634353, loss_t: 0.418952, testing: 0.944444, t2y: 1
seq1, epoch6, step: 490, training: 0.9375, loss_tr: 0.651912, loss_t: 0.375481, testing: 0.944444, t2y: 1
seq1, epoch6, step: 500, training: 0.75, loss_tr: 0.578287, loss_t: 0.404989, testing: 0.888889, t2y: 1
seq1, epoch6, step: 510, training: 0.9375, loss_tr: 0.634924, loss_t: 0.392207, testing: 0.888889, t2y: 1
 
****************************************
current sequence is 2
****************************************
seq2, epoch0, step: 0, training: 0.1875, loss_tr: 3.06066, loss_t: 2.07202, testing: 0.166667, t2y: 0.166667
seq2, epoch0, step: 10, training: 0.1875, loss_tr: 2.96154, loss_t: 1.99066, testing: 0.222222, t2y: 0.666667
seq2, epoch0, step: 20, training: 0.25, loss_tr: 2.83969, loss_t: 1.93945, testing: 0.277778, t2y: 0.666667
seq2, epoch0, step: 30, training: 0.3125, loss_tr: 2.62334, loss_t: 1.87105, testing: 0.333333, t2y: 0.5
seq2, epoch0, step: 40, training: 0.3125, loss_tr: 2.40851, loss_t: 1.83161, testing: 0.277778, t2y: 0.5
seq2, epoch0, step: 50, training: 0.375, loss_tr: 2.29715, loss_t: 1.75795, testing: 0.277778, t2y: 0.5
seq2, epoch0, step: 60, training: 0.75, loss_tr: 2.16992, loss_t: 1.65121, testing: 0.277778, t2y: 0.5
seq2, epoch0, step: 70, training: 0.5625, loss_tr: 2.2247, loss_t: 1.58024, testing: 0.388889, t2y: 0.666667
seq2, epoch1, step: 80, training: 0.4375, loss_tr: 2.10029, loss_t: 1.53845, testing: 0.333333, t2y: 0.666667
seq2, epoch1, step: 90, training: 0.625, loss_tr: 2.14364, loss_t: 1.4992, testing: 0.333333, t2y: 0.666667
seq2, epoch1, step: 100, training: 0.625, loss_tr: 2.05445, loss_t: 1.41392, testing: 0.388889, t2y: 0.666667
seq2, epoch1, step: 110, training: 0.5625, loss_tr: 1.9929, loss_t: 1.31892, testing: 0.555556, t2y: 0.666667
seq2, epoch1, step: 120, training: 0.6875, loss_tr: 1.70263, loss_t: 1.314, testing: 0.611111, t2y: 0.5
seq2, epoch1, step: 130, training: 0.625, loss_tr: 1.43142, loss_t: 1.30729, testing: 0.5, t2y: 0.666667
seq2, epoch1, step: 140, training: 0.625, loss_tr: 1.40136, loss_t: 1.2403, testing: 0.555556, t2y: 0.833333
seq2, epoch1, step: 150, training: 0.6875, loss_tr: 1.30502, loss_t: 1.12531, testing: 0.666667, t2y: 0.833333
seq2, epoch2, step: 160, training: 0.625, loss_tr: 1.30953, loss_t: 1.08158, testing: 0.777778, t2y: 0.666667
seq2, epoch2, step: 170, training: 1, loss_tr: 1.11126, loss_t: 1.06169, testing: 0.722222, t2y: 0.833333
seq2, epoch2, step: 180, training: 0.75, loss_tr: 1.22406, loss_t: 1.02089, testing: 0.666667, t2y: 0.666667
seq2, epoch2, step: 190, training: 0.75, loss_tr: 1.15049, loss_t: 0.955701, testing: 0.666667, t2y: 0.666667
seq2, epoch2, step: 200, training: 0.5625, loss_tr: 1.17368, loss_t: 0.908878, testing: 0.666667, t2y: 0.666667
seq2, epoch2, step: 210, training: 0.875, loss_tr: 1.05437, loss_t: 0.873547, testing: 0.722222, t2y: 0.833333
seq2, epoch2, step: 220, training: 0.9375, loss_tr: 1.12453, loss_t: 0.838917, testing: 0.777778, t2y: 1
seq2, epoch2, step: 230, training: 0.6875, loss_tr: 1.07628, loss_t: 0.80444, testing: 0.833333, t2y: 0.833333
seq2, epoch3, step: 240, training: 0.9375, loss_tr: 0.983677, loss_t: 0.779138, testing: 0.833333, t2y: 1
seq2, epoch3, step: 250, training: 0.9375, loss_tr: 0.855197, loss_t: 0.76138, testing: 0.777778, t2y: 1
seq2, epoch3, step: 260, training: 0.9375, loss_tr: 0.815692, loss_t: 0.754836, testing: 0.722222, t2y: 0.833333
seq2, epoch3, step: 270, training: 0.8125, loss_tr: 0.865367, loss_t: 0.739723, testing: 0.666667, t2y: 1
seq2, epoch3, step: 280, training: 1, loss_tr: 0.874033, loss_t: 0.718431, testing: 0.722222, t2y: 1
seq2, epoch3, step: 290, training: 0.9375, loss_tr: 0.85428, loss_t: 0.69954, testing: 0.777778, t2y: 0.833333
seq2, epoch3, step: 300, training: 1, loss_tr: 0.880576, loss_t: 0.687372, testing: 0.833333, t2y: 0.833333
seq2, epoch3, step: 310, training: 0.9375, loss_tr: 0.837731, loss_t: 0.675752, testing: 0.777778, t2y: 1
seq2, epoch4, step: 320, training: 0.9375, loss_tr: 0.7574, loss_t: 0.647476, testing: 0.833333, t2y: 1
seq2, epoch4, step: 330, training: 1, loss_tr: 0.72971, loss_t: 0.612991, testing: 0.888889, t2y: 1
seq2, epoch4, step: 340, training: 0.9375, loss_tr: 0.717995, loss_t: 0.614427, testing: 0.944444, t2y: 0.833333
seq2, epoch4, step: 350, training: 0.875, loss_tr: 0.739986, loss_t: 0.609456, testing: 0.888889, t2y: 1
seq2, epoch4, step: 360, training: 0.75, loss_tr: 0.855528, loss_t: 0.598403, testing: 0.833333, t2y: 1
seq2, epoch4, step: 370, training: 0.875, loss_tr: 0.875908, loss_t: 0.570004, testing: 0.888889, t2y: 1
seq2, epoch4, step: 380, training: 0.9375, loss_tr: 0.880687, loss_t: 0.548714, testing: 0.944444, t2y: 1
seq2, epoch4, step: 390, training: 0.9375, loss_tr: 0.664294, loss_t: 0.521883, testing: 1, t2y: 1
seq2, epoch5, step: 400, training: 0.9375, loss_tr: 0.608096, loss_t: 0.474794, testing: 1, t2y: 1
seq2, epoch5, step: 410, training: 0.75, loss_tr: 0.602276, loss_t: 0.450828, testing: 1, t2y: 1
seq2, epoch5, step: 420, training: 0.9375, loss_tr: 0.712535, loss_t: 0.465917, testing: 0.944444, t2y: 1
seq2, epoch5, step: 430, training: 0.875, loss_tr: 0.74363, loss_t: 0.478997, testing: 0.944444, t2y: 1
seq2, epoch5, step: 440, training: 1, loss_tr: 0.791441, loss_t: 0.474358, testing: 0.944444, t2y: 1
seq2, epoch5, step: 450, training: 0.9375, loss_tr: 0.65658, loss_t: 0.45316, testing: 1, t2y: 1
seq2, epoch5, step: 460, training: 0.9375, loss_tr: 0.664954, loss_t: 0.441948, testing: 1, t2y: 1
seq2, epoch5, step: 470, training: 0.9375, loss_tr: 0.576432, loss_t: 0.42081, testing: 1, t2y: 1
seq2, epoch6, step: 480, training: 1, loss_tr: 0.558868, loss_t: 0.40179, testing: 1, t2y: 1
seq2, epoch6, step: 490, training: 0.9375, loss_tr: 0.475147, loss_t: 0.397611, testing: 1, t2y: 1
seq2, epoch6, step: 500, training: 1, loss_tr: 0.388849, loss_t: 0.393925, testing: 0.944444, t2y: 1
seq2, epoch6, step: 510, training: 1, loss_tr: 0.389098, loss_t: 0.408928, testing: 0.888889, t2y: 1
 
****************************************
current sequence is 3
****************************************
seq3, epoch0, step: 0, training: 0.1875, loss_tr: 3.79494, loss_t: 3.00055, testing: 0.166667, t2y: 0.333333
seq3, epoch0, step: 10, training: 0.25, loss_tr: 3.25, loss_t: 2.57874, testing: 0.111111, t2y: 0.333333
seq3, epoch0, step: 20, training: 0.3125, loss_tr: 2.76834, loss_t: 2.14812, testing: 0.222222, t2y: 0.666667
seq3, epoch0, step: 30, training: 0.375, loss_tr: 2.41237, loss_t: 1.75696, testing: 0.277778, t2y: 0.333333
seq3, epoch0, step: 40, training: 0.5, loss_tr: 2.37773, loss_t: 1.672, testing: 0.388889, t2y: 0.666667
seq3, epoch0, step: 50, training: 0.375, loss_tr: 2.37401, loss_t: 1.5349, testing: 0.388889, t2y: 0.833333
seq3, epoch0, step: 60, training: 0.5, loss_tr: 2.10158, loss_t: 1.34444, testing: 0.5, t2y: 0.833333
seq3, epoch0, step: 70, training: 0.6875, loss_tr: 1.9332, loss_t: 1.26166, testing: 0.611111, t2y: 0.666667
seq3, epoch1, step: 80, training: 0.5, loss_tr: 1.76024, loss_t: 1.22018, testing: 0.666667, t2y: 0.666667
seq3, epoch1, step: 90, training: 0.8125, loss_tr: 1.66431, loss_t: 1.16893, testing: 0.666667, t2y: 0.666667
seq3, epoch1, step: 100, training: 0.5625, loss_tr: 1.5932, loss_t: 1.1117, testing: 0.666667, t2y: 0.833333
seq3, epoch1, step: 110, training: 0.75, loss_tr: 1.5735, loss_t: 1.06583, testing: 0.666667, t2y: 0.666667
seq3, epoch1, step: 120, training: 0.875, loss_tr: 1.32678, loss_t: 1.03654, testing: 0.666667, t2y: 0.666667
seq3, epoch1, step: 130, training: 0.9375, loss_tr: 1.21471, loss_t: 0.998795, testing: 0.666667, t2y: 0.666667
seq3, epoch1, step: 140, training: 0.625, loss_tr: 1.1406, loss_t: 0.959271, testing: 0.666667, t2y: 0.666667
seq3, epoch1, step: 150, training: 0.8125, loss_tr: 1.23175, loss_t: 0.928643, testing: 0.666667, t2y: 0.666667
seq3, epoch2, step: 160, training: 0.8125, loss_tr: 1.42331, loss_t: 0.915865, testing: 0.666667, t2y: 0.666667
seq3, epoch2, step: 170, training: 0.875, loss_tr: 1.28355, loss_t: 0.928066, testing: 0.666667, t2y: 0.666667
seq3, epoch2, step: 180, training: 0.8125, loss_tr: 1.35813, loss_t: 0.900433, testing: 0.666667, t2y: 1
seq3, epoch2, step: 190, training: 1, loss_tr: 1.10533, loss_t: 0.87242, testing: 0.666667, t2y: 0.833333
seq3, epoch2, step: 200, training: 0.8125, loss_tr: 1.19686, loss_t: 0.830171, testing: 0.666667, t2y: 0.666667
seq3, epoch2, step: 210, training: 0.875, loss_tr: 1.11758, loss_t: 0.846463, testing: 0.722222, t2y: 0.833333
seq3, epoch2, step: 220, training: 0.875, loss_tr: 1.16759, loss_t: 0.81815, testing: 0.722222, t2y: 0.833333
seq3, epoch2, step: 230, training: 0.75, loss_tr: 1.07618, loss_t: 0.790863, testing: 0.722222, t2y: 0.666667
seq3, epoch3, step: 240, training: 0.875, loss_tr: 1.00167, loss_t: 0.73417, testing: 0.666667, t2y: 0.666667
seq3, epoch3, step: 250, training: 0.875, loss_tr: 0.985871, loss_t: 0.71577, testing: 0.666667, t2y: 1
seq3, epoch3, step: 260, training: 1, loss_tr: 0.769355, loss_t: 0.735773, testing: 0.666667, t2y: 0.666667
seq3, epoch3, step: 270, training: 0.8125, loss_tr: 0.664345, loss_t: 0.768629, testing: 0.666667, t2y: 0.666667
seq3, epoch3, step: 280, training: 1, loss_tr: 0.690815, loss_t: 0.754327, testing: 0.666667, t2y: 1
seq3, epoch3, step: 290, training: 0.9375, loss_tr: 0.828866, loss_t: 0.728261, testing: 0.666667, t2y: 0.833333
seq3, epoch3, step: 300, training: 1, loss_tr: 0.877311, loss_t: 0.721632, testing: 0.666667, t2y: 0.666667
seq3, epoch3, step: 310, training: 0.875, loss_tr: 0.795165, loss_t: 0.735973, testing: 0.666667, t2y: 0.666667
seq3, epoch4, step: 320, training: 0.9375, loss_tr: 0.653532, loss_t: 0.672215, testing: 0.722222, t2y: 1
seq3, epoch4, step: 330, training: 0.9375, loss_tr: 0.586182, loss_t: 0.637973, testing: 0.722222, t2y: 0.833333
seq3, epoch4, step: 340, training: 0.9375, loss_tr: 0.599671, loss_t: 0.606275, testing: 0.722222, t2y: 0.833333
seq3, epoch4, step: 350, training: 0.875, loss_tr: 0.665296, loss_t: 0.60761, testing: 0.666667, t2y: 1
seq3, epoch4, step: 360, training: 0.9375, loss_tr: 0.681753, loss_t: 0.579855, testing: 0.666667, t2y: 0.833333
seq3, epoch4, step: 370, training: 0.9375, loss_tr: 0.539504, loss_t: 0.582262, testing: 0.666667, t2y: 0.666667
seq3, epoch4, step: 380, training: 0.9375, loss_tr: 0.60887, loss_t: 0.595785, testing: 0.666667, t2y: 1
seq3, epoch4, step: 390, training: 0.8125, loss_tr: 0.743764, loss_t: 0.627907, testing: 0.666667, t2y: 0.666667
seq3, epoch5, step: 400, training: 1, loss_tr: 0.780109, loss_t: 0.648574, testing: 0.666667, t2y: 0.833333
seq3, epoch5, step: 410, training: 1, loss_tr: 0.614152, loss_t: 0.65204, testing: 0.666667, t2y: 1
seq3, epoch5, step: 420, training: 1, loss_tr: 0.404179, loss_t: 0.604973, testing: 0.666667, t2y: 0.833333
seq3, epoch5, step: 430, training: 0.9375, loss_tr: 0.447848, loss_t: 0.578067, testing: 0.666667, t2y: 1
seq3, epoch5, step: 440, training: 1, loss_tr: 0.496364, loss_t: 0.593042, testing: 0.666667, t2y: 0.666667
seq3, epoch5, step: 450, training: 0.875, loss_tr: 0.469045, loss_t: 0.610829, testing: 0.666667, t2y: 0.666667
seq3, epoch5, step: 460, training: 1, loss_tr: 0.475631, loss_t: 0.587754, testing: 0.666667, t2y: 1
seq3, epoch5, step: 470, training: 0.9375, loss_tr: 0.453043, loss_t: 0.567733, testing: 0.666667, t2y: 0.833333
seq3, epoch6, step: 480, training: 1, loss_tr: 0.48682, loss_t: 0.529213, testing: 0.666667, t2y: 1
seq3, epoch6, step: 490, training: 0.9375, loss_tr: 0.423993, loss_t: 0.50405, testing: 0.722222, t2y: 1
seq3, epoch6, step: 500, training: 1, loss_tr: 0.405289, loss_t: 0.486253, testing: 0.722222, t2y: 0.833333
seq3, epoch6, step: 510, training: 1, loss_tr: 0.375297, loss_t: 0.477383, testing: 0.722222, t2y: 1
 
The list of Classification Accuracy: [1.0, 0.83333333333333337, 0.66666666666666663]
 [1.0, 1.0, 1.0]
 Mean Classification Accuracy is 0.833333333333, and top2 mean accuracy is 1.0
__________________________________________________________________________________________________
 
-------------------------------------------------------------------------
---------------------------- RUN 1 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq1, epoch0, step: 0, training: 0.1875, loss_tr: 2.18575, loss_t: 2.37944, testing: 0, t2y: 0.333333
seq1, epoch0, step: 10, training: 0.25, loss_tr: 2.34262, loss_t: 2.23738, testing: 0, t2y: 0.166667
seq1, epoch0, step: 20, training: 0.125, loss_tr: 2.38822, loss_t: 2.05294, testing: 0.0555556, t2y: 0.333333
seq1, epoch0, step: 30, training: 0.125, loss_tr: 2.24369, loss_t: 1.86197, testing: 0.111111, t2y: 0.5
seq1, epoch0, step: 40, training: 0.4375, loss_tr: 2.18665, loss_t: 1.77998, testing: 0.166667, t2y: 0.5
seq1, epoch0, step: 50, training: 0.0625, loss_tr: 2.05449, loss_t: 1.73403, testing: 0.166667, t2y: 0.5
seq1, epoch0, step: 60, training: 0.5, loss_tr: 2.16767, loss_t: 1.61549, testing: 0.166667, t2y: 0.666667
seq1, epoch0, step: 70, training: 0.25, loss_tr: 2.07794, loss_t: 1.52714, testing: 0.222222, t2y: 0.666667
seq1, epoch1, step: 80, training: 0.5625, loss_tr: 2.21716, loss_t: 1.42396, testing: 0.333333, t2y: 0.666667
seq1, epoch1, step: 90, training: 0.4375, loss_tr: 2.15664, loss_t: 1.3561, testing: 0.444444, t2y: 0.833333
seq1, epoch1, step: 100, training: 0.6875, loss_tr: 2.02529, loss_t: 1.27018, testing: 0.555556, t2y: 0.833333
seq1, epoch1, step: 110, training: 0.8125, loss_tr: 1.88296, loss_t: 1.19448, testing: 0.611111, t2y: 0.833333
seq1, epoch1, step: 120, training: 0.75, loss_tr: 1.69023, loss_t: 1.14432, testing: 0.666667, t2y: 0.833333
seq1, epoch1, step: 130, training: 0.4375, loss_tr: 1.65521, loss_t: 1.12515, testing: 0.611111, t2y: 0.666667
seq1, epoch1, step: 140, training: 0.75, loss_tr: 1.54811, loss_t: 1.11051, testing: 0.555556, t2y: 0.833333
seq1, epoch1, step: 150, training: 0.75, loss_tr: 1.65578, loss_t: 1.07796, testing: 0.555556, t2y: 0.833333
seq1, epoch2, step: 160, training: 0.8125, loss_tr: 1.60056, loss_t: 1.03035, testing: 0.611111, t2y: 0.833333
seq1, epoch2, step: 170, training: 0.5, loss_tr: 1.53614, loss_t: 0.976239, testing: 0.666667, t2y: 0.833333
seq1, epoch2, step: 180, training: 0.875, loss_tr: 1.37671, loss_t: 0.950646, testing: 0.722222, t2y: 0.833333
seq1, epoch2, step: 190, training: 0.8125, loss_tr: 1.32725, loss_t: 0.928246, testing: 0.777778, t2y: 0.833333
seq1, epoch2, step: 200, training: 0.3125, loss_tr: 1.35384, loss_t: 0.914563, testing: 0.777778, t2y: 0.833333
seq1, epoch2, step: 210, training: 0.5625, loss_tr: 1.30865, loss_t: 0.900384, testing: 0.777778, t2y: 0.833333
seq1, epoch2, step: 220, training: 0.875, loss_tr: 1.10977, loss_t: 0.85543, testing: 0.722222, t2y: 1
seq1, epoch2, step: 230, training: 0.625, loss_tr: 1.05922, loss_t: 0.808856, testing: 0.722222, t2y: 1
seq1, epoch3, step: 240, training: 0.625, loss_tr: 1.13402, loss_t: 0.749194, testing: 0.722222, t2y: 0.833333
seq1, epoch3, step: 250, training: 1, loss_tr: 1.10149, loss_t: 0.728219, testing: 0.777778, t2y: 0.833333
seq1, epoch3, step: 260, training: 0.9375, loss_tr: 0.997648, loss_t: 0.689204, testing: 0.888889, t2y: 1
seq1, epoch3, step: 270, training: 0.9375, loss_tr: 0.833082, loss_t: 0.667107, testing: 0.888889, t2y: 1
seq1, epoch3, step: 280, training: 0.875, loss_tr: 0.900322, loss_t: 0.639285, testing: 0.888889, t2y: 0.833333
seq1, epoch3, step: 290, training: 0.9375, loss_tr: 0.855246, loss_t: 0.631048, testing: 0.833333, t2y: 0.833333
seq1, epoch3, step: 300, training: 0.8125, loss_tr: 0.91603, loss_t: 0.639603, testing: 0.777778, t2y: 0.833333
seq1, epoch3, step: 310, training: 0.75, loss_tr: 1.00261, loss_t: 0.630785, testing: 0.777778, t2y: 0.833333
seq1, epoch4, step: 320, training: 0.9375, loss_tr: 0.915519, loss_t: 0.600997, testing: 0.833333, t2y: 1
seq1, epoch4, step: 330, training: 0.8125, loss_tr: 0.863091, loss_t: 0.562247, testing: 0.888889, t2y: 0.833333
seq1, epoch4, step: 340, training: 0.8125, loss_tr: 0.77597, loss_t: 0.546828, testing: 0.888889, t2y: 0.833333
seq1, epoch4, step: 350, training: 0.875, loss_tr: 0.813884, loss_t: 0.538424, testing: 0.888889, t2y: 1
seq1, epoch4, step: 360, training: 1, loss_tr: 0.781917, loss_t: 0.530397, testing: 0.888889, t2y: 1
seq1, epoch4, step: 370, training: 0.9375, loss_tr: 0.615139, loss_t: 0.515733, testing: 0.888889, t2y: 0.833333
seq1, epoch4, step: 380, training: 1, loss_tr: 0.651634, loss_t: 0.50277, testing: 0.833333, t2y: 1
seq1, epoch4, step: 390, training: 1, loss_tr: 0.640707, loss_t: 0.46839, testing: 0.888889, t2y: 1
seq1, epoch5, step: 400, training: 1, loss_tr: 0.745185, loss_t: 0.453044, testing: 0.888889, t2y: 0.833333
seq1, epoch5, step: 410, training: 1, loss_tr: 0.683316, loss_t: 0.431598, testing: 0.888889, t2y: 1
seq1, epoch5, step: 420, training: 1, loss_tr: 0.564439, loss_t: 0.430956, testing: 0.888889, t2y: 1
seq1, epoch5, step: 430, training: 1, loss_tr: 0.432295, loss_t: 0.411766, testing: 0.888889, t2y: 1
seq1, epoch5, step: 440, training: 0.875, loss_tr: 0.406893, loss_t: 0.41268, testing: 0.888889, t2y: 1
seq1, epoch5, step: 450, training: 1, loss_tr: 0.487153, loss_t: 0.396391, testing: 0.888889, t2y: 1
seq1, epoch5, step: 460, training: 0.9375, loss_tr: 0.498824, loss_t: 0.386292, testing: 0.888889, t2y: 1
seq1, epoch5, step: 470, training: 1, loss_tr: 0.528856, loss_t: 0.361152, testing: 0.888889, t2y: 1
seq1, epoch6, step: 480, training: 0.9375, loss_tr: 0.527902, loss_t: 0.346062, testing: 0.888889, t2y: 1
seq1, epoch6, step: 490, training: 1, loss_tr: 0.530654, loss_t: 0.342981, testing: 0.888889, t2y: 1
seq1, epoch6, step: 500, training: 1, loss_tr: 0.425018, loss_t: 0.357059, testing: 0.888889, t2y: 1
seq1, epoch6, step: 510, training: 1, loss_tr: 0.484742, loss_t: 0.356118, testing: 0.833333, t2y: 1
 
****************************************
current sequence is 2
****************************************
seq2, epoch0, step: 0, training: 0.25, loss_tr: 4.4692, loss_t: 2.94009, testing: 0.166667, t2y: 0.333333
seq2, epoch0, step: 10, training: 0, loss_tr: 3.92317, loss_t: 2.60287, testing: 0.166667, t2y: 0.166667
seq2, epoch0, step: 20, training: 0.1875, loss_tr: 3.37335, loss_t: 2.26603, testing: 0.222222, t2y: 0.333333
seq2, epoch0, step: 30, training: 0.1875, loss_tr: 2.70374, loss_t: 1.90477, testing: 0.277778, t2y: 0.333333
seq2, epoch0, step: 40, training: 0.3125, loss_tr: 2.41846, loss_t: 1.81416, testing: 0.333333, t2y: 0.333333
seq2, epoch0, step: 50, training: 0.3125, loss_tr: 2.1103, loss_t: 1.6868, testing: 0.333333, t2y: 0.5
seq2, epoch0, step: 60, training: 0.6875, loss_tr: 1.93814, loss_t: 1.57023, testing: 0.333333, t2y: 0.5
seq2, epoch0, step: 70, training: 0.4375, loss_tr: 1.86076, loss_t: 1.52328, testing: 0.333333, t2y: 0.333333
seq2, epoch1, step: 80, training: 0.5625, loss_tr: 1.73721, loss_t: 1.4917, testing: 0.333333, t2y: 0.5
seq2, epoch1, step: 90, training: 0.75, loss_tr: 1.50437, loss_t: 1.46392, testing: 0.333333, t2y: 0.5
seq2, epoch1, step: 100, training: 0.9375, loss_tr: 1.39716, loss_t: 1.42186, testing: 0.333333, t2y: 0.666667
seq2, epoch1, step: 110, training: 0.4375, loss_tr: 1.5993, loss_t: 1.36708, testing: 0.388889, t2y: 0.666667
seq2, epoch1, step: 120, training: 0.5625, loss_tr: 1.57533, loss_t: 1.29547, testing: 0.444444, t2y: 0.666667
seq2, epoch1, step: 130, training: 0.5625, loss_tr: 1.63933, loss_t: 1.23467, testing: 0.444444, t2y: 0.666667
seq2, epoch1, step: 140, training: 0.6875, loss_tr: 1.32278, loss_t: 1.18849, testing: 0.5, t2y: 0.833333
seq2, epoch1, step: 150, training: 0.6875, loss_tr: 1.37639, loss_t: 1.19339, testing: 0.444444, t2y: 0.833333
seq2, epoch2, step: 160, training: 0.6875, loss_tr: 1.1683, loss_t: 1.15828, testing: 0.555556, t2y: 0.833333
seq2, epoch2, step: 170, training: 0.5625, loss_tr: 1.33227, loss_t: 1.14115, testing: 0.444444, t2y: 0.833333
seq2, epoch2, step: 180, training: 0.6875, loss_tr: 1.39618, loss_t: 1.05134, testing: 0.666667, t2y: 1
seq2, epoch2, step: 190, training: 0.75, loss_tr: 1.76984, loss_t: 1.00565, testing: 0.555556, t2y: 0.666667
seq2, epoch2, step: 200, training: 0.875, loss_tr: 1.66969, loss_t: 0.964002, testing: 0.666667, t2y: 0.666667
seq2, epoch2, step: 210, training: 0.75, loss_tr: 1.44637, loss_t: 0.973784, testing: 0.5, t2y: 0.833333
seq2, epoch2, step: 220, training: 0.9375, loss_tr: 1.04285, loss_t: 0.952979, testing: 0.611111, t2y: 0.833333
seq2, epoch2, step: 230, training: 0.8125, loss_tr: 0.935642, loss_t: 0.920282, testing: 0.611111, t2y: 1
seq2, epoch3, step: 240, training: 0.875, loss_tr: 0.98413, loss_t: 0.900933, testing: 0.611111, t2y: 0.666667
seq2, epoch3, step: 250, training: 0.875, loss_tr: 0.952809, loss_t: 0.905075, testing: 0.611111, t2y: 0.833333
seq2, epoch3, step: 260, training: 1, loss_tr: 0.940096, loss_t: 0.894418, testing: 0.555556, t2y: 1
seq2, epoch3, step: 270, training: 0.8125, loss_tr: 0.994687, loss_t: 0.848541, testing: 0.611111, t2y: 1
seq2, epoch3, step: 280, training: 0.9375, loss_tr: 0.927651, loss_t: 0.805466, testing: 0.555556, t2y: 1
seq2, epoch3, step: 290, training: 1, loss_tr: 0.942524, loss_t: 0.801427, testing: 0.611111, t2y: 0.666667
seq2, epoch3, step: 300, training: 0.8125, loss_tr: 0.924371, loss_t: 0.799929, testing: 0.611111, t2y: 0.833333
seq2, epoch3, step: 310, training: 0.8125, loss_tr: 1.0242, loss_t: 0.79127, testing: 0.611111, t2y: 1
seq2, epoch4, step: 320, training: 1, loss_tr: 0.863024, loss_t: 0.752543, testing: 0.666667, t2y: 1
seq2, epoch4, step: 330, training: 0.9375, loss_tr: 0.787415, loss_t: 0.753903, testing: 0.611111, t2y: 0.833333
seq2, epoch4, step: 340, training: 1, loss_tr: 0.723939, loss_t: 0.738803, testing: 0.666667, t2y: 0.833333
seq2, epoch4, step: 350, training: 0.875, loss_tr: 0.817193, loss_t: 0.726948, testing: 0.611111, t2y: 0.833333
seq2, epoch4, step: 360, training: 0.875, loss_tr: 0.776312, loss_t: 0.690644, testing: 0.666667, t2y: 1
seq2, epoch4, step: 370, training: 0.9375, loss_tr: 0.775772, loss_t: 0.683802, testing: 0.666667, t2y: 0.666667
seq2, epoch4, step: 380, training: 1, loss_tr: 0.67184, loss_t: 0.673946, testing: 0.666667, t2y: 0.833333
seq2, epoch4, step: 390, training: 0.9375, loss_tr: 0.626741, loss_t: 0.657093, testing: 0.666667, t2y: 1
seq2, epoch5, step: 400, training: 0.75, loss_tr: 0.694328, loss_t: 0.644342, testing: 0.611111, t2y: 1
seq2, epoch5, step: 410, training: 1, loss_tr: 0.71576, loss_t: 0.652312, testing: 0.611111, t2y: 0.666667
seq2, epoch5, step: 420, training: 1, loss_tr: 0.675052, loss_t: 0.650138, testing: 0.611111, t2y: 0.666667
seq2, epoch5, step: 430, training: 0.875, loss_tr: 0.581431, loss_t: 0.62278, testing: 0.666667, t2y: 0.833333
seq2, epoch5, step: 440, training: 0.9375, loss_tr: 0.576359, loss_t: 0.586214, testing: 0.666667, t2y: 0.833333
seq2, epoch5, step: 450, training: 1, loss_tr: 0.5711, loss_t: 0.583055, testing: 0.666667, t2y: 0.833333
seq2, epoch5, step: 460, training: 0.9375, loss_tr: 0.470436, loss_t: 0.578224, testing: 0.666667, t2y: 0.833333
seq2, epoch5, step: 470, training: 0.9375, loss_tr: 0.438478, loss_t: 0.561977, testing: 0.666667, t2y: 1
seq2, epoch6, step: 480, training: 0.9375, loss_tr: 0.486618, loss_t: 0.542685, testing: 0.611111, t2y: 0.833333
seq2, epoch6, step: 490, training: 0.9375, loss_tr: 0.520001, loss_t: 0.52661, testing: 0.666667, t2y: 1
seq2, epoch6, step: 500, training: 1, loss_tr: 0.535653, loss_t: 0.526381, testing: 0.666667, t2y: 1
seq2, epoch6, step: 510, training: 0.875, loss_tr: 0.563122, loss_t: 0.516712, testing: 0.722222, t2y: 1
 
****************************************
current sequence is 3
****************************************
seq3, epoch0, step: 0, training: 0.4375, loss_tr: 2.23191, loss_t: 2.88959, testing: 0.166667, t2y: 0.333333
seq3, epoch0, step: 10, training: 0.3125, loss_tr: 2.43827, loss_t: 2.63665, testing: 0.166667, t2y: 0.333333
seq3, epoch0, step: 20, training: 0.1875, loss_tr: 2.72733, loss_t: 2.32687, testing: 0.111111, t2y: 0.333333
seq3, epoch0, step: 30, training: 0.1875, loss_tr: 2.82452, loss_t: 2.01356, testing: 0.0555556, t2y: 0.166667
seq3, epoch0, step: 40, training: 0.4375, loss_tr: 2.69298, loss_t: 1.91524, testing: 0, t2y: 0.5
seq3, epoch0, step: 50, training: 0.5625, loss_tr: 2.5716, loss_t: 1.85834, testing: 0, t2y: 0.666667
seq3, epoch0, step: 60, training: 0.1875, loss_tr: 2.18412, loss_t: 1.80392, testing: 0.0555556, t2y: 0.666667
seq3, epoch0, step: 70, training: 0.375, loss_tr: 2.05943, loss_t: 1.77538, testing: 0.111111, t2y: 0.333333
seq3, epoch1, step: 80, training: 0.5625, loss_tr: 1.92843, loss_t: 1.73698, testing: 0.222222, t2y: 0.5
seq3, epoch1, step: 90, training: 0.4375, loss_tr: 1.95529, loss_t: 1.66444, testing: 0.277778, t2y: 0.5
seq3, epoch1, step: 100, training: 0.5, loss_tr: 1.88244, loss_t: 1.62798, testing: 0.333333, t2y: 0.5
seq3, epoch1, step: 110, training: 0.5, loss_tr: 1.84067, loss_t: 1.53343, testing: 0.333333, t2y: 0.833333
seq3, epoch1, step: 120, training: 0.5625, loss_tr: 2.00763, loss_t: 1.43907, testing: 0.388889, t2y: 1
seq3, epoch1, step: 130, training: 0.875, loss_tr: 1.76257, loss_t: 1.32403, testing: 0.444444, t2y: 0.666667
seq3, epoch1, step: 140, training: 0.6875, loss_tr: 1.57613, loss_t: 1.31688, testing: 0.388889, t2y: 0.5
seq3, epoch1, step: 150, training: 0.625, loss_tr: 1.33346, loss_t: 1.29251, testing: 0.333333, t2y: 0.833333
seq3, epoch2, step: 160, training: 0.625, loss_tr: 1.45613, loss_t: 1.24683, testing: 0.333333, t2y: 1
seq3, epoch2, step: 170, training: 0.625, loss_tr: 1.33356, loss_t: 1.18187, testing: 0.5, t2y: 0.666667
seq3, epoch2, step: 180, training: 0.875, loss_tr: 1.36641, loss_t: 1.17056, testing: 0.555556, t2y: 0.666667
seq3, epoch2, step: 190, training: 0.875, loss_tr: 1.24192, loss_t: 1.14681, testing: 0.555556, t2y: 1
seq3, epoch2, step: 200, training: 0.625, loss_tr: 1.22421, loss_t: 1.13291, testing: 0.5, t2y: 0.666667
seq3, epoch2, step: 210, training: 0.6875, loss_tr: 1.16104, loss_t: 1.08925, testing: 0.5, t2y: 0.666667
seq3, epoch2, step: 220, training: 0.625, loss_tr: 1.22968, loss_t: 1.07887, testing: 0.555556, t2y: 0.833333
seq3, epoch2, step: 230, training: 0.75, loss_tr: 1.22079, loss_t: 1.04587, testing: 0.611111, t2y: 1
seq3, epoch3, step: 240, training: 0.9375, loss_tr: 1.09602, loss_t: 1.05541, testing: 0.666667, t2y: 0.666667
seq3, epoch3, step: 250, training: 0.8125, loss_tr: 0.92125, loss_t: 1.04145, testing: 0.611111, t2y: 0.833333
seq3, epoch3, step: 260, training: 0.75, loss_tr: 0.943563, loss_t: 1.02452, testing: 0.611111, t2y: 0.833333
seq3, epoch3, step: 270, training: 0.75, loss_tr: 1.05458, loss_t: 1.0184, testing: 0.611111, t2y: 1
seq3, epoch3, step: 280, training: 0.625, loss_tr: 1.1581, loss_t: 0.981761, testing: 0.666667, t2y: 0.833333
seq3, epoch3, step: 290, training: 0.9375, loss_tr: 0.957191, loss_t: 0.911091, testing: 0.722222, t2y: 1
seq3, epoch3, step: 300, training: 0.875, loss_tr: 0.867467, loss_t: 0.845358, testing: 0.722222, t2y: 1
seq3, epoch3, step: 310, training: 0.6875, loss_tr: 0.769067, loss_t: 0.884833, testing: 0.722222, t2y: 0.666667
seq3, epoch4, step: 320, training: 0.875, loss_tr: 0.903211, loss_t: 0.939273, testing: 0.611111, t2y: 0.833333
seq3, epoch4, step: 330, training: 0.9375, loss_tr: 0.894258, loss_t: 0.899525, testing: 0.666667, t2y: 1
seq3, epoch4, step: 340, training: 0.875, loss_tr: 0.862953, loss_t: 0.830108, testing: 0.666667, t2y: 1
seq3, epoch4, step: 350, training: 0.875, loss_tr: 0.809145, loss_t: 0.799467, testing: 0.722222, t2y: 1
seq3, epoch4, step: 360, training: 0.75, loss_tr: 0.675052, loss_t: 0.840127, testing: 0.611111, t2y: 0.666667
seq3, epoch4, step: 370, training: 1, loss_tr: 0.671014, loss_t: 0.821834, testing: 0.666667, t2y: 1
seq3, epoch4, step: 380, training: 1, loss_tr: 0.632543, loss_t: 0.773032, testing: 0.722222, t2y: 1
seq3, epoch4, step: 390, training: 0.875, loss_tr: 0.686663, loss_t: 0.747003, testing: 0.777778, t2y: 1
seq3, epoch5, step: 400, training: 1, loss_tr: 0.557498, loss_t: 0.712603, testing: 0.777778, t2y: 1
seq3, epoch5, step: 410, training: 0.9375, loss_tr: 0.60627, loss_t: 0.689555, testing: 0.777778, t2y: 1
seq3, epoch5, step: 420, training: 1, loss_tr: 0.587271, loss_t: 0.65184, testing: 0.833333, t2y: 1
seq3, epoch5, step: 430, training: 1, loss_tr: 0.667122, loss_t: 0.694481, testing: 0.777778, t2y: 0.833333
seq3, epoch5, step: 440, training: 0.9375, loss_tr: 0.45578, loss_t: 0.734548, testing: 0.722222, t2y: 0.833333
seq3, epoch5, step: 450, training: 0.9375, loss_tr: 0.576375, loss_t: 0.751865, testing: 0.666667, t2y: 1
seq3, epoch5, step: 460, training: 1, loss_tr: 0.546361, loss_t: 0.719997, testing: 0.666667, t2y: 1
seq3, epoch5, step: 470, training: 1, loss_tr: 0.631401, loss_t: 0.668977, testing: 0.722222, t2y: 1
seq3, epoch6, step: 480, training: 0.9375, loss_tr: 0.48088, loss_t: 0.619695, testing: 0.777778, t2y: 1
seq3, epoch6, step: 490, training: 0.9375, loss_tr: 0.576343, loss_t: 0.632036, testing: 0.777778, t2y: 1
seq3, epoch6, step: 500, training: 1, loss_tr: 0.609575, loss_t: 0.667798, testing: 0.722222, t2y: 1
seq3, epoch6, step: 510, training: 1, loss_tr: 0.583325, loss_t: 0.684083, testing: 0.722222, t2y: 1
 
The list of Classification Accuracy: [0.83333333333333337, 0.66666666666666663, 0.83333333333333337]
 [1.0, 1.0, 1.0]
 Mean Classification Accuracy is 0.777777777778, and top2 mean accuracy is 1.0
__________________________________________________________________________________________________
 
-------------------------------------------------------------------------
---------------------------- RUN 2 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq1, epoch0, step: 0, training: 0.125, loss_tr: 2.97331, loss_t: 2.62747, testing: 0.166667, t2y: 0.333333
seq1, epoch0, step: 10, training: 0.1875, loss_tr: 2.77956, loss_t: 2.33894, testing: 0.166667, t2y: 0.5
seq1, epoch0, step: 20, training: 0.1875, loss_tr: 2.48391, loss_t: 2.06931, testing: 0.222222, t2y: 0.333333
seq1, epoch0, step: 30, training: 0.25, loss_tr: 2.17794, loss_t: 1.74568, testing: 0.333333, t2y: 0.5
seq1, epoch0, step: 40, training: 0.3125, loss_tr: 2.22624, loss_t: 1.63875, testing: 0.388889, t2y: 0.833333
seq1, epoch0, step: 50, training: 0.625, loss_tr: 2.23364, loss_t: 1.52245, testing: 0.444444, t2y: 0.666667
seq1, epoch0, step: 60, training: 0.3125, loss_tr: 2.41189, loss_t: 1.43837, testing: 0.444444, t2y: 0.833333
seq1, epoch0, step: 70, training: 0.625, loss_tr: 2.19012, loss_t: 1.43086, testing: 0.5, t2y: 0.666667
seq1, epoch1, step: 80, training: 0.6875, loss_tr: 2.16118, loss_t: 1.37253, testing: 0.5, t2y: 0.833333
seq1, epoch1, step: 90, training: 0.5625, loss_tr: 1.82366, loss_t: 1.28193, testing: 0.444444, t2y: 1
seq1, epoch1, step: 100, training: 0.375, loss_tr: 1.63826, loss_t: 1.19158, testing: 0.388889, t2y: 0.666667
seq1, epoch1, step: 110, training: 0.5, loss_tr: 1.42337, loss_t: 1.17291, testing: 0.388889, t2y: 0.833333
seq1, epoch1, step: 120, training: 0.25, loss_tr: 1.54456, loss_t: 1.19673, testing: 0.388889, t2y: 0.833333
seq1, epoch1, step: 130, training: 0.6875, loss_tr: 1.65346, loss_t: 1.13482, testing: 0.444444, t2y: 0.833333
seq1, epoch1, step: 140, training: 0.875, loss_tr: 1.58136, loss_t: 1.03532, testing: 0.444444, t2y: 0.833333
