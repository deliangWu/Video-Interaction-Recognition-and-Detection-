Wed Apr  5 13:44:42 2017 Finetune the dual-nets model with two independent feature variables on UT-Interaction set1! 
****************************************
current sequence is 1
****************************************
step 0, training: 0.133333, testing: 0.166667, anv: 0.0166667, best 0.0166667 
step 20, training: 0.266667, testing: 0.166667, anv: 0.0333333, best 0.0333333 
step 40, training: 0, testing: 0.166667, anv: 0.05, best 0.05 
step 60, training: 0.2, testing: 0.166667, anv: 0.0666667, best 0.0666667 
step 80, training: 0.2, testing: 0.166667, anv: 0.0833333, best 0.0833333 
step 100, training: 0.133333, testing: 0.166667, anv: 0.1, best 0.1 
step 120, training: 0.2, testing: 0.333333, anv: 0.133333, best 0.133333 
step 140, training: 0.133333, testing: 0.166667, anv: 0.15, best 0.15 
step 160, training: 0.266667, testing: 0, anv: 0.15, best 0.15 
step 180, training: 0.133333, testing: 0.333333, anv: 0.183333, best 0.183333 
step 200, training: 0.266667, testing: 0.166667, anv: 0.183333, best 0.183333 
step 220, training: 0.4, testing: 0.333333, anv: 0.2, best 0.2 
step 240, training: 0.2, testing: 0.333333, anv: 0.216667, best 0.216667 
step 260, training: 0.2, testing: 0.333333, anv: 0.233333, best 0.233333 
step 280, training: 0.2, testing: 0.333333, anv: 0.25, best 0.25 
step 300, training: 0.333333, testing: 0.333333, anv: 0.266667, best 0.266667 
step 320, training: 0.4, testing: 0.333333, anv: 0.266667, best 0.266667 
step 340, training: 0.266667, testing: 0.333333, anv: 0.283333, best 0.283333 
step 360, training: 0.133333, testing: 0.333333, anv: 0.316667, best 0.316667 
step 380, training: 0.333333, testing: 0.333333, anv: 0.316667, best 0.316667 
step 400, training: 0.333333, testing: 0.333333, anv: 0.333333, best 0.333333 
step 420, training: 0.2, testing: 0.333333, anv: 0.333333, best 0.333333 
step 440, training: 0.266667, testing: 0.166667, anv: 0.316667, best 0.333333 
step 460, training: 0.666667, testing: 0.166667, anv: 0.3, best 0.333333 
step 480, training: 0.333333, testing: 0.333333, anv: 0.3, best 0.333333 
step 500, training: 0.0666667, testing: 0.333333, anv: 0.3, best 0.333333 
step 520, training: 0.4, testing: 0.333333, anv: 0.3, best 0.333333 
step 540, training: 0.2, testing: 0.5, anv: 0.316667, best 0.333333 
step 560, training: 0.266667, testing: 0.333333, anv: 0.316667, best 0.333333 
step 580, training: 0.4, testing: 0.333333, anv: 0.316667, best 0.333333 
step 600, training: 0.4, testing: 0.333333, anv: 0.316667, best 0.333333 
step 620, training: 0.4, testing: 0.333333, anv: 0.316667, best 0.333333 
step 640, training: 0.2, testing: 0.5, anv: 0.35, best 0.35 
step 660, training: 0.4, testing: 0.5, anv: 0.383333, best 0.383333 
step 680, training: 0.133333, testing: 0.333333, anv: 0.383333, best 0.383333 
step 700, training: 0.2, testing: 0.333333, anv: 0.383333, best 0.383333 
step 720, training: 0.466667, testing: 0.333333, anv: 0.383333, best 0.383333 
step 740, training: 0.533333, testing: 0.5, anv: 0.383333, best 0.383333 
step 760, training: 0.333333, testing: 0.5, anv: 0.4, best 0.4 
step 780, training: 0.4, testing: 0.5, anv: 0.416667, best 0.416667 
step 800, training: 0.6, testing: 0.5, anv: 0.433333, best 0.433333 
step 820, training: 0.466667, testing: 0.5, anv: 0.45, best 0.45 
step 840, training: 0.466667, testing: 0.5, anv: 0.45, best 0.45 
step 860, training: 0.533333, testing: 0.5, anv: 0.45, best 0.45 
step 880, training: 0.466667, testing: 0.5, anv: 0.466667, best 0.466667 
step 900, training: 0.466667, testing: 0.5, anv: 0.483333, best 0.483333 
step 920, training: 0.266667, testing: 0.5, anv: 0.5, best 0.5 
step 940, training: 0.4, testing: 0.5, anv: 0.5, best 0.5 
step 960, training: 0.266667, testing: 0.5, anv: 0.5, best 0.5 
step 980, training: 0.266667, testing: 0.5, anv: 0.5, best 0.5 
step 1000, training: 0.333333, testing: 0.5, anv: 0.5, best 0.5 
step 1020, training: 0.4, testing: 0.5, anv: 0.5, best 0.5 
step 1040, training: 0.2, testing: 0.5, anv: 0.5, best 0.5 
step 1060, training: 0.533333, testing: 0.5, anv: 0.5, best 0.5 
step 1080, training: 0.466667, testing: 0.5, anv: 0.5, best 0.5 
step 1100, training: 0.2, testing: 0.5, anv: 0.5, best 0.5 
step 1120, training: 0.733333, testing: 0.5, anv: 0.5, best 0.5 
step 1140, training: 0.333333, testing: 0.5, anv: 0.5, best 0.5 
step 1160, training: 0.533333, testing: 0.5, anv: 0.5, best 0.5 
step 1180, training: 0.466667, testing: 0.5, anv: 0.5, best 0.5 
step 1200, training: 0.4, testing: 0.5, anv: 0.5, best 0.5 
step 1220, training: 0.666667, testing: 0.5, anv: 0.5, best 0.5 
step 1240, training: 0.666667, testing: 0.5, anv: 0.5, best 0.5 
step 1260, training: 0.533333, testing: 0.5, anv: 0.5, best 0.5 
step 1280, training: 0.333333, testing: 0.5, anv: 0.5, best 0.5 
step 1300, training: 0.333333, testing: 0.5, anv: 0.5, best 0.5 
step 1320, training: 0.533333, testing: 0.5, anv: 0.5, best 0.5 
step 1340, training: 0.4, testing: 0.5, anv: 0.5, best 0.5 
step 1360, training: 0.666667, testing: 0.5, anv: 0.5, best 0.5 
step 1380, training: 0.466667, testing: 0.5, anv: 0.5, best 0.5 
step 1400, training: 0.666667, testing: 0.5, anv: 0.5, best 0.5 
step 1420, training: 0.266667, testing: 0.5, anv: 0.5, best 0.5 
step 1440, training: 0.733333, testing: 0.5, anv: 0.5, best 0.5 
step 1460, training: 0.666667, testing: 0.5, anv: 0.5, best 0.5 
step 1480, training: 0.666667, testing: 0.5, anv: 0.5, best 0.5 
step 1500, training: 0.6, testing: 0.666667, anv: 0.516667, best 0.516667 
step 1520, training: 0.466667, testing: 0.5, anv: 0.516667, best 0.516667 
step 1540, training: 0.6, testing: 0.5, anv: 0.516667, best 0.516667 
step 1560, training: 0.533333, testing: 0.5, anv: 0.516667, best 0.516667 
step 1580, training: 0.533333, testing: 0.5, anv: 0.516667, best 0.516667 
step 1600, training: 0.466667, testing: 0.5, anv: 0.516667, best 0.516667 
step 1620, training: 0.6, testing: 0.5, anv: 0.516667, best 0.516667 
step 1640, training: 0.533333, testing: 0.5, anv: 0.516667, best 0.516667 
step 1660, training: 0.4, testing: 0.5, anv: 0.516667, best 0.516667 
step 1680, training: 0.6, testing: 0.5, anv: 0.516667, best 0.516667 
step 1700, training: 0.533333, testing: 0.5, anv: 0.5, best 0.516667 
step 1720, training: 0.333333, testing: 0.5, anv: 0.5, best 0.516667 
step 1740, training: 0.4, testing: 0.5, anv: 0.5, best 0.516667 
step 1760, training: 0.866667, testing: 0.5, anv: 0.5, best 0.516667 
step 1780, training: 0.6, testing: 0.5, anv: 0.5, best 0.516667 
