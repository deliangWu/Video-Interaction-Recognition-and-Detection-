Mon Jun 12 08:50:19 2017 Train the 3D-ConvNet on UT-Interaction dataset set2 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 11
****************************************
seq11, epoch0, step: 0, training: 0.4375, loss_tr: 1.60091, loss_t: 1.83484, testing: 0.166667, t2y: 0.333333
seq11, epoch0, step: 10, training: 0.375, loss_tr: 1.65165, loss_t: 1.79489, testing: 0.222222, t2y: 0.5
seq11, epoch0, step: 20, training: 0.5625, loss_tr: 1.6006, loss_t: 1.69034, testing: 0.277778, t2y: 0.666667
seq11, epoch0, step: 30, training: 0.3125, loss_tr: 1.55883, loss_t: 1.56317, testing: 0.333333, t2y: 0.666667
seq11, epoch0, step: 40, training: 0.6875, loss_tr: 1.37253, loss_t: 1.43243, testing: 0.388889, t2y: 0.666667
seq11, epoch0, step: 50, training: 0.25, loss_tr: 1.4303, loss_t: 1.36286, testing: 0.388889, t2y: 0.5
seq11, epoch0, step: 60, training: 0.6875, loss_tr: 1.35912, loss_t: 1.2679, testing: 0.5, t2y: 0.833333
seq11, epoch0, step: 70, training: 0.4375, loss_tr: 1.38974, loss_t: 1.20201, testing: 0.555556, t2y: 0.666667
seq11, epoch1, step: 80, training: 0.75, loss_tr: 1.18795, loss_t: 1.11675, testing: 0.666667, t2y: 1
seq11, epoch1, step: 90, training: 0.75, loss_tr: 1.05016, loss_t: 1.0695, testing: 0.722222, t2y: 0.833333
seq11, epoch1, step: 100, training: 0.75, loss_tr: 0.945651, loss_t: 1.02174, testing: 0.777778, t2y: 0.833333
seq11, epoch1, step: 110, training: 0.625, loss_tr: 0.904427, loss_t: 1.05038, testing: 0.722222, t2y: 0.666667
seq11, epoch1, step: 120, training: 0.875, loss_tr: 0.894691, loss_t: 1.08677, testing: 0.611111, t2y: 0.833333
seq11, epoch1, step: 130, training: 0.9375, loss_tr: 0.880532, loss_t: 1.05492, testing: 0.555556, t2y: 0.666667
seq11, epoch1, step: 140, training: 0.6875, loss_tr: 0.861733, loss_t: 0.968091, testing: 0.555556, t2y: 0.833333
seq11, epoch1, step: 150, training: 0.8125, loss_tr: 0.826022, loss_t: 0.858288, testing: 0.611111, t2y: 0.833333
seq11, epoch2, step: 160, training: 0.9375, loss_tr: 0.770101, loss_t: 0.844265, testing: 0.611111, t2y: 0.833333
seq11, epoch2, step: 170, training: 0.9375, loss_tr: 0.73241, loss_t: 0.775669, testing: 0.666667, t2y: 1
seq11, epoch2, step: 180, training: 0.875, loss_tr: 0.684789, loss_t: 0.7117, testing: 0.777778, t2y: 1
seq11, epoch2, step: 190, training: 0.9375, loss_tr: 0.583862, loss_t: 0.665754, testing: 0.777778, t2y: 1
seq11, epoch2, step: 200, training: 0.8125, loss_tr: 0.51293, loss_t: 0.654417, testing: 0.833333, t2y: 1
seq11, epoch2, step: 210, training: 0.6875, loss_tr: 0.517626, loss_t: 0.75087, testing: 0.722222, t2y: 0.833333
seq11, epoch2, step: 220, training: 0.75, loss_tr: 0.523295, loss_t: 0.726197, testing: 0.777778, t2y: 1
seq11, epoch2, step: 230, training: 0.5, loss_tr: 0.619654, loss_t: 0.841469, testing: 0.666667, t2y: 0.833333
seq11, epoch3, step: 240, training: 0.9375, loss_tr: 0.533327, loss_t: 0.749844, testing: 0.722222, t2y: 0.833333
seq11, epoch3, step: 250, training: 0.9375, loss_tr: 0.527426, loss_t: 0.747235, testing: 0.666667, t2y: 1
seq11, epoch3, step: 260, training: 0.9375, loss_tr: 0.37209, loss_t: 0.608718, testing: 0.722222, t2y: 0.833333
seq11, epoch3, step: 270, training: 0.9375, loss_tr: 0.358867, loss_t: 0.548922, testing: 0.666667, t2y: 1
seq11, epoch3, step: 280, training: 0.8125, loss_tr: 0.293203, loss_t: 0.597821, testing: 0.666667, t2y: 0.833333
seq11, epoch3, step: 290, training: 1, loss_tr: 0.220784, loss_t: 0.516967, testing: 0.777778, t2y: 1
seq11, epoch3, step: 300, training: 0.9375, loss_tr: 0.15679, loss_t: 0.511431, testing: 0.833333, t2y: 1
seq11, epoch3, step: 310, training: 0.9375, loss_tr: 0.118807, loss_t: 0.361775, testing: 0.888889, t2y: 1
seq11, epoch4, step: 320, training: 0.625, loss_tr: 0.182067, loss_t: 0.467164, testing: 0.777778, t2y: 1
seq11, epoch4, step: 330, training: 0.9375, loss_tr: 0.177048, loss_t: 0.476444, testing: 0.777778, t2y: 1
seq11, epoch4, step: 340, training: 1, loss_tr: 0.13686, loss_t: 0.559592, testing: 0.722222, t2y: 1
seq11, epoch4, step: 350, training: 1, loss_tr: 0.0526028, loss_t: 0.495724, testing: 0.722222, t2y: 0.833333
seq11, epoch4, step: 360, training: 0.875, loss_tr: 0.073239, loss_t: 0.534321, testing: 0.666667, t2y: 1
seq11, epoch4, step: 370, training: 0.9375, loss_tr: 0.107264, loss_t: 0.530122, testing: 0.666667, t2y: 0.833333
seq11, epoch4, step: 380, training: 1, loss_tr: 0.107515, loss_t: 0.514583, testing: 0.722222, t2y: 1
seq11, epoch4, step: 390, training: 1, loss_tr: 0.088046, loss_t: 0.43679, testing: 0.722222, t2y: 1
seq11, epoch5, step: 400, training: 0.9375, loss_tr: 0.0660523, loss_t: 0.452308, testing: 0.722222, t2y: 1
seq11, epoch5, step: 410, training: 1, loss_tr: 0.0545247, loss_t: 0.5274, testing: 0.666667, t2y: 1
seq11, epoch5, step: 420, training: 1, loss_tr: 0.0473032, loss_t: 0.539399, testing: 0.666667, t2y: 1
seq11, epoch5, step: 430, training: 1, loss_tr: 0.0301612, loss_t: 0.622636, testing: 0.722222, t2y: 1
seq11, epoch5, step: 440, training: 1, loss_tr: 0.0300182, loss_t: 0.575891, testing: 0.722222, t2y: 1
seq11, epoch5, step: 450, training: 0.9375, loss_tr: 0.0234952, loss_t: 0.663967, testing: 0.722222, t2y: 1
seq11, epoch5, step: 460, training: 1, loss_tr: 0.0925729, loss_t: 0.515458, testing: 0.666667, t2y: 1
seq11, epoch5, step: 470, training: 0.9375, loss_tr: 0.106921, loss_t: 0.535518, testing: 0.722222, t2y: 1
seq11, epoch6, step: 480, training: 1, loss_tr: 0.110993, loss_t: 0.473258, testing: 0.777778, t2y: 1
seq11, epoch6, step: 490, training: 0.9375, loss_tr: 0.0493897, loss_t: 0.497695, testing: 0.777778, t2y: 1
seq11, epoch6, step: 500, training: 1, loss_tr: 0.0342792, loss_t: 0.397939, testing: 0.777778, t2y: 1
seq11, epoch6, step: 510, training: 1, loss_tr: 0.0200556, loss_t: 0.40372, testing: 0.722222, t2y: 1
 
****************************************
current sequence is 12
****************************************
seq12, epoch0, step: 0, training: 0.3125, loss_tr: 1.6977, loss_t: 1.95975, testing: 0.166667, t2y: 0.333333
seq12, epoch0, step: 10, training: 0.3125, loss_tr: 1.65983, loss_t: 1.95723, testing: 0.166667, t2y: 0.333333
seq12, epoch0, step: 20, training: 0.25, loss_tr: 1.66532, loss_t: 1.89054, testing: 0.166667, t2y: 0.5
seq12, epoch0, step: 30, training: 0.1875, loss_tr: 1.73349, loss_t: 1.81561, testing: 0.222222, t2y: 0.5
seq12, epoch0, step: 40, training: 0.25, loss_tr: 1.65819, loss_t: 1.6689, testing: 0.277778, t2y: 0.5
seq12, epoch0, step: 50, training: 0.375, loss_tr: 1.58665, loss_t: 1.57512, testing: 0.333333, t2y: 0.333333
seq12, epoch0, step: 60, training: 0.375, loss_tr: 1.34193, loss_t: 1.48912, testing: 0.333333, t2y: 0.5
seq12, epoch0, step: 70, training: 0.4375, loss_tr: 1.29908, loss_t: 1.43876, testing: 0.388889, t2y: 0.5
seq12, epoch1, step: 80, training: 0.6875, loss_tr: 1.13365, loss_t: 1.4044, testing: 0.388889, t2y: 0.5
seq12, epoch1, step: 90, training: 0.4375, loss_tr: 1.12451, loss_t: 1.38348, testing: 0.388889, t2y: 0.5
seq12, epoch1, step: 100, training: 0.6875, loss_tr: 1.00107, loss_t: 1.39825, testing: 0.333333, t2y: 0.5
seq12, epoch1, step: 110, training: 0.5625, loss_tr: 1.04846, loss_t: 1.41349, testing: 0.333333, t2y: 0.333333
seq12, epoch1, step: 120, training: 0.625, loss_tr: 0.944385, loss_t: 1.41352, testing: 0.333333, t2y: 0.5
seq12, epoch1, step: 130, training: 0.8125, loss_tr: 0.906355, loss_t: 1.41172, testing: 0.333333, t2y: 0.333333
seq12, epoch1, step: 140, training: 0.8125, loss_tr: 0.703404, loss_t: 1.45803, testing: 0.333333, t2y: 0.333333
seq12, epoch1, step: 150, training: 0.8125, loss_tr: 0.618961, loss_t: 1.47049, testing: 0.333333, t2y: 0.5
seq12, epoch2, step: 160, training: 0.5625, loss_tr: 0.637262, loss_t: 1.5236, testing: 0.277778, t2y: 0.5
seq12, epoch2, step: 170, training: 0.6875, loss_tr: 0.716782, loss_t: 1.51173, testing: 0.333333, t2y: 0.5
seq12, epoch2, step: 180, training: 0.875, loss_tr: 0.669264, loss_t: 1.5361, testing: 0.333333, t2y: 0.5
seq12, epoch2, step: 190, training: 0.8125, loss_tr: 0.542675, loss_t: 1.5238, testing: 0.444444, t2y: 0.666667
seq12, epoch2, step: 200, training: 0.625, loss_tr: 0.492744, loss_t: 1.50459, testing: 0.444444, t2y: 0.666667
seq12, epoch2, step: 210, training: 0.875, loss_tr: 0.498665, loss_t: 1.49689, testing: 0.444444, t2y: 0.666667
seq12, epoch2, step: 220, training: 0.9375, loss_tr: 0.503888, loss_t: 1.5396, testing: 0.388889, t2y: 0.5
seq12, epoch2, step: 230, training: 0.625, loss_tr: 0.398911, loss_t: 1.59604, testing: 0.333333, t2y: 0.5
seq12, epoch3, step: 240, training: 1, loss_tr: 0.321931, loss_t: 1.60715, testing: 0.388889, t2y: 0.5
seq12, epoch3, step: 250, training: 1, loss_tr: 0.247699, loss_t: 1.59026, testing: 0.444444, t2y: 0.666667
seq12, epoch3, step: 260, training: 0.9375, loss_tr: 0.264089, loss_t: 1.57606, testing: 0.5, t2y: 0.666667
seq12, epoch3, step: 270, training: 0.875, loss_tr: 0.224709, loss_t: 1.59952, testing: 0.5, t2y: 0.666667
seq12, epoch3, step: 280, training: 1, loss_tr: 0.213974, loss_t: 1.66514, testing: 0.5, t2y: 0.5
seq12, epoch3, step: 290, training: 1, loss_tr: 0.138355, loss_t: 1.6811, testing: 0.555556, t2y: 0.666667
seq12, epoch3, step: 300, training: 0.875, loss_tr: 0.143893, loss_t: 1.76557, testing: 0.555556, t2y: 0.5
seq12, epoch3, step: 310, training: 0.9375, loss_tr: 0.117349, loss_t: 1.71647, testing: 0.555556, t2y: 0.5
seq12, epoch4, step: 320, training: 1, loss_tr: 0.103346, loss_t: 1.74079, testing: 0.5, t2y: 0.833333
seq12, epoch4, step: 330, training: 0.875, loss_tr: 0.0975914, loss_t: 1.76464, testing: 0.5, t2y: 0.666667
seq12, epoch4, step: 340, training: 1, loss_tr: 0.085838, loss_t: 1.85229, testing: 0.5, t2y: 0.666667
seq12, epoch4, step: 350, training: 1, loss_tr: 0.0643442, loss_t: 1.89069, testing: 0.5, t2y: 0.666667
seq12, epoch4, step: 360, training: 1, loss_tr: 0.0567856, loss_t: 1.88582, testing: 0.444444, t2y: 0.666667
seq12, epoch4, step: 370, training: 1, loss_tr: 0.0463369, loss_t: 1.8619, testing: 0.444444, t2y: 0.5
seq12, epoch4, step: 380, training: 1, loss_tr: 0.0482846, loss_t: 1.8902, testing: 0.444444, t2y: 0.666667
seq12, epoch4, step: 390, training: 1, loss_tr: 0.0382202, loss_t: 1.90091, testing: 0.5, t2y: 0.5
seq12, epoch5, step: 400, training: 0.875, loss_tr: 0.0782894, loss_t: 1.93335, testing: 0.5, t2y: 0.666667
seq12, epoch5, step: 410, training: 1, loss_tr: 0.0828176, loss_t: 1.90937, testing: 0.5, t2y: 0.5
seq12, epoch5, step: 420, training: 1, loss_tr: 0.0791042, loss_t: 1.92085, testing: 0.444444, t2y: 0.666667
seq12, epoch5, step: 430, training: 1, loss_tr: 0.0335391, loss_t: 1.91525, testing: 0.444444, t2y: 0.5
seq12, epoch5, step: 440, training: 1, loss_tr: 0.0233111, loss_t: 1.9234, testing: 0.444444, t2y: 0.666667
seq12, epoch5, step: 450, training: 1, loss_tr: 0.0210834, loss_t: 1.95398, testing: 0.5, t2y: 0.833333
seq12, epoch5, step: 460, training: 1, loss_tr: 0.0221095, loss_t: 1.94059, testing: 0.5, t2y: 0.833333
seq12, epoch5, step: 470, training: 1, loss_tr: 0.0201968, loss_t: 1.91574, testing: 0.5, t2y: 0.666667
seq12, epoch6, step: 480, training: 0.9375, loss_tr: 0.0115694, loss_t: 1.92414, testing: 0.5, t2y: 0.5
seq12, epoch6, step: 490, training: 1, loss_tr: 0.0061103, loss_t: 1.94828, testing: 0.555556, t2y: 0.833333
seq12, epoch6, step: 500, training: 1, loss_tr: 0.00591847, loss_t: 1.97805, testing: 0.555556, t2y: 0.833333
seq12, epoch6, step: 510, training: 1, loss_tr: 0.00805506, loss_t: 1.91416, testing: 0.555556, t2y: 0.666667
 
****************************************
current sequence is 13
****************************************
seq13, epoch0, step: 0, training: 0.25, loss_tr: 1.80102, loss_t: 1.89736, testing: 0.166667, t2y: 0.5
seq13, epoch0, step: 10, training: 0.1875, loss_tr: 1.76394, loss_t: 1.87434, testing: 0.166667, t2y: 0.5
seq13, epoch0, step: 20, training: 0.3125, loss_tr: 1.73388, loss_t: 1.8133, testing: 0.222222, t2y: 0.333333
seq13, epoch0, step: 30, training: 0.3125, loss_tr: 1.68281, loss_t: 1.7016, testing: 0.222222, t2y: 0.5
seq13, epoch0, step: 40, training: 0.4375, loss_tr: 1.5609, loss_t: 1.5629, testing: 0.333333, t2y: 0.666667
seq13, epoch0, step: 50, training: 0.5, loss_tr: 1.41308, loss_t: 1.43434, testing: 0.388889, t2y: 0.666667
seq13, epoch0, step: 60, training: 0.4375, loss_tr: 1.2609, loss_t: 1.35296, testing: 0.555556, t2y: 0.666667
seq13, epoch0, step: 70, training: 0.5625, loss_tr: 1.18894, loss_t: 1.30382, testing: 0.555556, t2y: 0.666667
seq13, epoch1, step: 80, training: 0.5625, loss_tr: 1.09441, loss_t: 1.31297, testing: 0.5, t2y: 0.666667
seq13, epoch1, step: 90, training: 0.5625, loss_tr: 1.09171, loss_t: 1.26902, testing: 0.444444, t2y: 0.833333
seq13, epoch1, step: 100, training: 0.625, loss_tr: 1.05739, loss_t: 1.24466, testing: 0.444444, t2y: 0.666667
seq13, epoch1, step: 110, training: 0.625, loss_tr: 1.02908, loss_t: 1.18249, testing: 0.555556, t2y: 0.666667
seq13, epoch1, step: 120, training: 0.5625, loss_tr: 0.9748, loss_t: 1.15972, testing: 0.555556, t2y: 0.666667
seq13, epoch1, step: 130, training: 0.6875, loss_tr: 0.895171, loss_t: 1.1253, testing: 0.555556, t2y: 0.833333
seq13, epoch1, step: 140, training: 0.5625, loss_tr: 0.874251, loss_t: 1.08895, testing: 0.555556, t2y: 0.833333
seq13, epoch1, step: 150, training: 0.6875, loss_tr: 0.819006, loss_t: 1.07725, testing: 0.611111, t2y: 0.833333
seq13, epoch2, step: 160, training: 0.9375, loss_tr: 0.759586, loss_t: 1.03186, testing: 0.666667, t2y: 0.666667
seq13, epoch2, step: 170, training: 0.875, loss_tr: 0.660325, loss_t: 0.986345, testing: 0.666667, t2y: 0.833333
seq13, epoch2, step: 180, training: 0.8125, loss_tr: 0.616508, loss_t: 0.950926, testing: 0.666667, t2y: 0.833333
seq13, epoch2, step: 190, training: 0.8125, loss_tr: 0.596636, loss_t: 0.97011, testing: 0.666667, t2y: 0.666667
seq13, epoch2, step: 200, training: 0.6875, loss_tr: 0.626282, loss_t: 1.01907, testing: 0.666667, t2y: 0.666667
seq13, epoch2, step: 210, training: 0.9375, loss_tr: 0.5325, loss_t: 0.988249, testing: 0.666667, t2y: 0.666667
seq13, epoch2, step: 220, training: 0.6875, loss_tr: 0.521978, loss_t: 0.966394, testing: 0.666667, t2y: 0.833333
seq13, epoch2, step: 230, training: 0.75, loss_tr: 0.464923, loss_t: 0.909845, testing: 0.611111, t2y: 0.833333
seq13, epoch3, step: 240, training: 1, loss_tr: 0.422671, loss_t: 0.89017, testing: 0.611111, t2y: 0.833333
seq13, epoch3, step: 250, training: 0.875, loss_tr: 0.376062, loss_t: 0.863039, testing: 0.555556, t2y: 0.666667
seq13, epoch3, step: 260, training: 1, loss_tr: 0.270512, loss_t: 0.881917, testing: 0.666667, t2y: 0.833333
seq13, epoch3, step: 270, training: 1, loss_tr: 0.248073, loss_t: 0.88458, testing: 0.611111, t2y: 0.833333
seq13, epoch3, step: 280, training: 0.875, loss_tr: 0.19566, loss_t: 0.888723, testing: 0.611111, t2y: 0.833333
seq13, epoch3, step: 290, training: 0.8125, loss_tr: 0.256073, loss_t: 0.965102, testing: 0.555556, t2y: 0.833333
seq13, epoch3, step: 300, training: 0.75, loss_tr: 0.304959, loss_t: 0.943858, testing: 0.666667, t2y: 0.833333
seq13, epoch3, step: 310, training: 0.9375, loss_tr: 0.345183, loss_t: 0.955796, testing: 0.722222, t2y: 1
seq13, epoch4, step: 320, training: 0.875, loss_tr: 0.293524, loss_t: 0.803813, testing: 0.722222, t2y: 0.666667
seq13, epoch4, step: 330, training: 0.8125, loss_tr: 0.207592, loss_t: 0.817433, testing: 0.666667, t2y: 0.833333
seq13, epoch4, step: 340, training: 0.9375, loss_tr: 0.150706, loss_t: 0.779915, testing: 0.611111, t2y: 1
seq13, epoch4, step: 350, training: 0.8125, loss_tr: 0.127322, loss_t: 0.782296, testing: 0.611111, t2y: 0.666667
seq13, epoch4, step: 360, training: 0.9375, loss_tr: 0.109178, loss_t: 0.825613, testing: 0.555556, t2y: 0.833333
seq13, epoch4, step: 370, training: 1, loss_tr: 0.0846185, loss_t: 0.828769, testing: 0.555556, t2y: 0.833333
