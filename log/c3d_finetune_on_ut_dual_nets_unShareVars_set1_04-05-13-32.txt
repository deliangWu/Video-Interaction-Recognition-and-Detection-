Wed Apr  5 13:32:35 2017 Finetune the dual-nets model with two independent feature variables on UT-Interaction set1! 
****************************************
current sequence is 1
****************************************
step 0, training: 0.266667, testing: 0.166667, anv: 0.0166667, best 0.0166667 
step 20, training: 0.266667, testing: 0.333333, anv: 0.05, best 0.05 
step 40, training: 0.333333, testing: 0.333333, anv: 0.0833333, best 0.0833333 
step 60, training: 0.133333, testing: 0.166667, anv: 0.1, best 0.1 
step 80, training: 0.6, testing: 0.333333, anv: 0.133333, best 0.133333 
step 100, training: 0.6, testing: 0.5, anv: 0.183333, best 0.183333 
step 120, training: 0.6, testing: 0.666667, anv: 0.25, best 0.25 
step 140, training: 0.4, testing: 0.166667, anv: 0.266667, best 0.266667 
step 160, training: 0.8, testing: 0.5, anv: 0.316667, best 0.316667 
step 180, training: 0.733333, testing: 0.5, anv: 0.366667, best 0.366667 
step 200, training: 0.933333, testing: 0.333333, anv: 0.383333, best 0.383333 
step 220, training: 0.866667, testing: 0.5, anv: 0.4, best 0.4 
step 240, training: 0.733333, testing: 0.666667, anv: 0.433333, best 0.433333 
step 260, training: 1, testing: 0.666667, anv: 0.483333, best 0.483333 
step 280, training: 0.866667, testing: 0.666667, anv: 0.516667, best 0.516667 
step 300, training: 1, testing: 0.666667, anv: 0.533333, best 0.533333 
step 320, training: 1, testing: 0.666667, anv: 0.533333, best 0.533333 
step 340, training: 0.933333, testing: 0.666667, anv: 0.583333, best 0.583333 
step 360, training: 1, testing: 0.666667, anv: 0.6, best 0.6 
step 380, training: 1, testing: 0.833333, anv: 0.633333, best 0.633333 
step 400, training: 1, testing: 0.666667, anv: 0.666667, best 0.666667 
step 420, training: 1, testing: 0.833333, anv: 0.7, best 0.7 
step 440, training: 1, testing: 0.833333, anv: 0.716667, best 0.716667 
step 460, training: 1, testing: 0.666667, anv: 0.716667, best 0.716667 
step 480, training: 1, testing: 0.833333, anv: 0.733333, best 0.733333 
step 500, training: 1, testing: 0.666667, anv: 0.733333, best 0.733333 
step 520, training: 0.8, testing: 0.666667, anv: 0.733333, best 0.733333 
step 540, training: 1, testing: 0.833333, anv: 0.75, best 0.75 
step 560, training: 1, testing: 0.666667, anv: 0.75, best 0.75 
step 580, training: 1, testing: 0.833333, anv: 0.75, best 0.75 
step 600, training: 1, testing: 0.666667, anv: 0.75, best 0.75 
step 620, training: 1, testing: 0.833333, anv: 0.75, best 0.75 
step 640, training: 1, testing: 0.833333, anv: 0.75, best 0.75 
step 660, training: 1, testing: 0.666667, anv: 0.75, best 0.75 
step 680, training: 1, testing: 0.666667, anv: 0.733333, best 0.75 
step 700, training: 1, testing: 0.666667, anv: 0.733333, best 0.75 
step 720, training: 1, testing: 0.5, anv: 0.716667, best 0.75 
step 740, training: 1, testing: 0.666667, anv: 0.7, best 0.75 
step 760, training: 1, testing: 0.833333, anv: 0.716667, best 0.75 
step 780, training: 1, testing: 0.666667, anv: 0.7, best 0.75 
step 800, training: 1, testing: 0.666667, anv: 0.7, best 0.75 
step 820, training: 1, testing: 0.833333, anv: 0.7, best 0.75 
step 840, training: 1, testing: 0.666667, anv: 0.683333, best 0.75 
step 860, training: 1, testing: 0.666667, anv: 0.683333, best 0.75 
step 880, training: 1, testing: 0.833333, anv: 0.7, best 0.75 
