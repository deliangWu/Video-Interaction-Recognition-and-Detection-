Tue Jun 13 18:25:39 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 2
****************************************
seq: 2, epoch: 0, step: 0, training: 0.125, testing: 0.0714286, loss_tr: 1.89576, loss_t: 1.91027  
seq: 2, epoch: 0, step: 10, training: 0.625, testing: 0.642857, loss_tr: 1.46339, loss_t: 1.4465  
seq: 2, epoch: 0, step: 20, training: 0.6875, testing: 0.642857, loss_tr: 1.19253, loss_t: 1.36192  
seq: 2, epoch: 0, step: 30, training: 0.5625, testing: 0.642857, loss_tr: 1.39593, loss_t: 1.23935  
seq: 2, epoch: 0, step: 40, training: 0.6875, testing: 0.642857, loss_tr: 1.11863, loss_t: 1.25326  
seq: 2, epoch: 0, step: 50, training: 0.625, testing: 0.642857, loss_tr: 1.36658, loss_t: 1.30338  
seq: 2, epoch: 0, step: 60, training: 0.5625, testing: 0.642857, loss_tr: 1.47822, loss_t: 1.24787  
seq: 2, epoch: 0, step: 70, training: 0.75, testing: 0.642857, loss_tr: 0.949251, loss_t: 1.22954  
seq: 2, epoch: 0, step: 80, training: 0.5625, testing: 0.642857, loss_tr: 1.51415, loss_t: 1.26717  
seq: 2, epoch: 0, step: 90, training: 0.6875, testing: 0.642857, loss_tr: 1.13159, loss_t: 1.2483  
seq: 2, epoch: 0, step: 100, training: 0.5625, testing: 0.642857, loss_tr: 1.54907, loss_t: 1.27765  
seq: 2, epoch: 0, step: 110, training: 0.625, testing: 0.642857, loss_tr: 1.20646, loss_t: 1.20328  
seq: 2, epoch: 0, step: 120, training: 0.6875, testing: 0.642857, loss_tr: 1.10365, loss_t: 1.28944  
seq: 2, epoch: 0, step: 130, training: 0.625, testing: 0.642857, loss_tr: 1.27178, loss_t: 1.21157  
seq: 2, epoch: 0, step: 140, training: 0.375, testing: 0.642857, loss_tr: 1.89945, loss_t: 1.2181  
seq: 2, epoch: 0, step: 150, training: 0.875, testing: 0.642857, loss_tr: 0.654933, loss_t: 1.20656  
seq: 2, epoch: 0, step: 160, training: 0.75, testing: 0.642857, loss_tr: 0.969749, loss_t: 1.22055  
seq: 2, epoch: 0, step: 170, training: 0.5625, testing: 0.642857, loss_tr: 1.3942, loss_t: 1.21154  
seq: 2, epoch: 0, step: 180, training: 0.625, testing: 0.642857, loss_tr: 1.19432, loss_t: 1.18937  
seq: 2, epoch: 0, step: 190, training: 0.75, testing: 0.642857, loss_tr: 0.937284, loss_t: 1.21274  
seq: 2, epoch: 1, step: 200, training: 0.5625, testing: 0.642857, loss_tr: 1.44932, loss_t: 1.21808  
seq: 2, epoch: 1, step: 210, training: 0.8125, testing: 0.642857, loss_tr: 0.867635, loss_t: 1.16118  
seq: 2, epoch: 1, step: 220, training: 0.75, testing: 0.642857, loss_tr: 1.01389, loss_t: 1.31971  
seq: 2, epoch: 1, step: 230, training: 0.5625, testing: 0.642857, loss_tr: 1.31804, loss_t: 1.11424  
seq: 2, epoch: 1, step: 240, training: 0.4375, testing: 0.642857, loss_tr: 1.86269, loss_t: 1.27074  
seq: 2, epoch: 1, step: 250, training: 0.6875, testing: 0.642857, loss_tr: 1.10788, loss_t: 1.10021  
seq: 2, epoch: 1, step: 260, training: 0.625, testing: 0.642857, loss_tr: 1.28227, loss_t: 1.20442  
seq: 2, epoch: 1, step: 270, training: 0.625, testing: 0.642857, loss_tr: 1.11611, loss_t: 1.06926  
seq: 2, epoch: 1, step: 280, training: 0.625, testing: 0.642857, loss_tr: 1.09654, loss_t: 1.04072  
seq: 2, epoch: 1, step: 290, training: 0.5, testing: 0.642857, loss_tr: 1.42086, loss_t: 1.08187  
seq: 2, epoch: 1, step: 300, training: 0.625, testing: 0.642857, loss_tr: 1.21574, loss_t: 1.04506  
seq: 2, epoch: 1, step: 310, training: 0.75, testing: 0.642857, loss_tr: 0.739028, loss_t: 1.0009  
seq: 2, epoch: 1, step: 320, training: 0.6875, testing: 0.642857, loss_tr: 0.899104, loss_t: 0.940356  
seq: 2, epoch: 1, step: 330, training: 0.625, testing: 0.642857, loss_tr: 1.10084, loss_t: 0.922497  
seq: 2, epoch: 1, step: 340, training: 0.8125, testing: 0.642857, loss_tr: 0.744029, loss_t: 0.851495  
seq: 2, epoch: 1, step: 350, training: 0.5, testing: 0.642857, loss_tr: 1.44582, loss_t: 0.804436  
seq: 2, epoch: 1, step: 360, training: 0.625, testing: 0.642857, loss_tr: 1.33803, loss_t: 0.899209  
seq: 2, epoch: 1, step: 370, training: 0.75, testing: 0.642857, loss_tr: 0.706443, loss_t: 0.783161  
seq: 2, epoch: 1, step: 380, training: 0.6875, testing: 0.714286, loss_tr: 1.12947, loss_t: 0.72274  
seq: 2, epoch: 1, step: 390, training: 0.625, testing: 0.714286, loss_tr: 1.15842, loss_t: 0.719844  
seq: 2, epoch: 2, step: 400, training: 0.6875, testing: 0.642857, loss_tr: 0.817565, loss_t: 0.708665  
seq: 2, epoch: 2, step: 410, training: 0.8125, testing: 0.714286, loss_tr: 0.505626, loss_t: 0.683257  
seq: 2, epoch: 2, step: 420, training: 0.625, testing: 0.785714, loss_tr: 1.02213, loss_t: 0.66217  
seq: 2, epoch: 2, step: 430, training: 0.6875, testing: 0.785714, loss_tr: 0.79526, loss_t: 0.622061  
seq: 2, epoch: 2, step: 440, training: 0.4375, testing: 0.714286, loss_tr: 1.49257, loss_t: 0.607718  
seq: 2, epoch: 2, step: 450, training: 0.9375, testing: 0.785714, loss_tr: 0.392247, loss_t: 0.616603  
seq: 2, epoch: 2, step: 460, training: 0.75, testing: 0.785714, loss_tr: 0.93598, loss_t: 0.630366  
seq: 2, epoch: 2, step: 470, training: 0.5, testing: 0.785714, loss_tr: 0.997741, loss_t: 0.609066  
seq: 2, epoch: 2, step: 480, training: 0.6875, testing: 0.785714, loss_tr: 0.909452, loss_t: 0.567378  
seq: 2, epoch: 2, step: 490, training: 0.625, testing: 0.785714, loss_tr: 0.890759, loss_t: 0.548733  
seq: 2, epoch: 2, step: 500, training: 0.625, testing: 0.785714, loss_tr: 1.09866, loss_t: 0.54964  
seq: 2, epoch: 2, step: 510, training: 0.75, testing: 0.928571, loss_tr: 0.807403, loss_t: 0.545353  
seq: 2, epoch: 2, step: 520, training: 0.75, testing: 0.857143, loss_tr: 0.946074, loss_t: 0.548214  
seq: 2, epoch: 2, step: 530, training: 0.8125, testing: 0.785714, loss_tr: 0.806059, loss_t: 0.619199  
seq: 2, epoch: 2, step: 540, training: 0.8125, testing: 0.785714, loss_tr: 0.468026, loss_t: 0.590981  
seq: 2, epoch: 2, step: 550, training: 0.75, testing: 0.785714, loss_tr: 0.509522, loss_t: 0.573411  
seq: 2, epoch: 2, step: 560, training: 0.875, testing: 0.785714, loss_tr: 0.532324, loss_t: 0.587965  
seq: 2, epoch: 2, step: 570, training: 0.6875, testing: 0.785714, loss_tr: 0.833344, loss_t: 0.548281  
seq: 2, epoch: 2, step: 580, training: 0.9375, testing: 0.785714, loss_tr: 0.443191, loss_t: 0.516831  
seq: 2, epoch: 2, step: 590, training: 0.75, testing: 0.857143, loss_tr: 0.631443, loss_t: 0.517111  
seq: 2, epoch: 3, step: 600, training: 0.8125, testing: 0.857143, loss_tr: 0.664504, loss_t: 0.55645  
seq: 2, epoch: 3, step: 610, training: 0.875, testing: 0.785714, loss_tr: 0.431956, loss_t: 0.54022  
seq: 2, epoch: 3, step: 620, training: 0.875, testing: 0.857143, loss_tr: 0.484481, loss_t: 0.539315  
seq: 2, epoch: 3, step: 630, training: 0.75, testing: 0.785714, loss_tr: 0.597763, loss_t: 0.610097  
seq: 2, epoch: 3, step: 640, training: 0.75, testing: 0.857143, loss_tr: 0.752554, loss_t: 0.587286  
seq: 2, epoch: 3, step: 650, training: 0.8125, testing: 0.857143, loss_tr: 0.583943, loss_t: 0.504417  
seq: 2, epoch: 3, step: 660, training: 0.75, testing: 0.857143, loss_tr: 0.554651, loss_t: 0.538974  
seq: 2, epoch: 3, step: 670, training: 0.75, testing: 0.785714, loss_tr: 0.622149, loss_t: 0.52263  
seq: 2, epoch: 3, step: 680, training: 0.75, testing: 0.857143, loss_tr: 0.679497, loss_t: 0.575663  
seq: 2, epoch: 3, step: 690, training: 0.625, testing: 0.857143, loss_tr: 0.945438, loss_t: 0.60522  
seq: 2, epoch: 3, step: 700, training: 0.9375, testing: 0.785714, loss_tr: 0.208906, loss_t: 0.478686  
seq: 2, epoch: 3, step: 710, training: 0.8125, testing: 0.785714, loss_tr: 0.461923, loss_t: 0.492768  
seq: 2, epoch: 3, step: 720, training: 0.625, testing: 0.857143, loss_tr: 0.894483, loss_t: 0.589979  
seq: 2, epoch: 3, step: 730, training: 1, testing: 0.785714, loss_tr: 0.264031, loss_t: 0.614127  
seq: 2, epoch: 3, step: 740, training: 0.8125, testing: 0.785714, loss_tr: 0.617788, loss_t: 0.512514  
seq: 2, epoch: 3, step: 750, training: 0.875, testing: 0.785714, loss_tr: 0.281527, loss_t: 0.583404  
seq: 2, epoch: 3, step: 760, training: 0.8125, testing: 0.857143, loss_tr: 0.424021, loss_t: 0.516436  
seq: 2, epoch: 3, step: 770, training: 0.75, testing: 0.785714, loss_tr: 0.619778, loss_t: 0.649843  
seq: 2, epoch: 3, step: 780, training: 0.75, testing: 0.857143, loss_tr: 0.494068, loss_t: 0.483841  
seq: 2, epoch: 3, step: 790, training: 0.8125, testing: 0.857143, loss_tr: 0.570427, loss_t: 0.545081  
seq: 2, epoch: 4, step: 800, training: 0.6875, testing: 0.857143, loss_tr: 0.622987, loss_t: 0.468345  
seq: 2, epoch: 4, step: 810, training: 0.875, testing: 0.857143, loss_tr: 0.42932, loss_t: 0.544992  
seq: 2, epoch: 4, step: 820, training: 0.875, testing: 0.857143, loss_tr: 0.46194, loss_t: 0.548784  
seq: 2, epoch: 4, step: 830, training: 0.75, testing: 0.857143, loss_tr: 0.431279, loss_t: 0.533979  
seq: 2, epoch: 4, step: 840, training: 0.875, testing: 0.857143, loss_tr: 0.276607, loss_t: 0.514718  
seq: 2, epoch: 4, step: 850, training: 1, testing: 0.857143, loss_tr: 0.237102, loss_t: 0.497703  
seq: 2, epoch: 4, step: 860, training: 1, testing: 0.857143, loss_tr: 0.181851, loss_t: 0.526133  
seq: 2, epoch: 4, step: 870, training: 0.8125, testing: 0.857143, loss_tr: 0.685246, loss_t: 0.554896  
seq: 2, epoch: 4, step: 880, training: 0.875, testing: 0.857143, loss_tr: 0.403685, loss_t: 0.527825  
seq: 2, epoch: 4, step: 890, training: 0.75, testing: 0.857143, loss_tr: 0.897774, loss_t: 0.447458  
seq: 2, epoch: 4, step: 900, training: 0.8125, testing: 0.857143, loss_tr: 0.401259, loss_t: 0.514779  
seq: 2, epoch: 4, step: 910, training: 0.875, testing: 0.857143, loss_tr: 0.40942, loss_t: 0.490585  
seq: 2, epoch: 4, step: 920, training: 0.75, testing: 0.857143, loss_tr: 0.826142, loss_t: 0.551375  
seq: 2, epoch: 4, step: 930, training: 0.875, testing: 0.785714, loss_tr: 0.486753, loss_t: 0.568033  
seq: 2, epoch: 4, step: 940, training: 1, testing: 0.857143, loss_tr: 0.187015, loss_t: 0.496906  
seq: 2, epoch: 4, step: 950, training: 0.9375, testing: 0.857143, loss_tr: 0.308424, loss_t: 0.464107  
seq: 2, epoch: 4, step: 960, training: 0.9375, testing: 0.857143, loss_tr: 0.347704, loss_t: 0.505434  
seq: 2, epoch: 4, step: 970, training: 0.875, testing: 0.857143, loss_tr: 0.307486, loss_t: 0.56875  
seq: 2, epoch: 4, step: 980, training: 0.75, testing: 0.785714, loss_tr: 0.744288, loss_t: 0.542719  
seq: 2, epoch: 4, step: 990, training: 0.875, testing: 0.857143, loss_tr: 0.44504, loss_t: 0.554063  
seq: 2, epoch: 5, step: 1000, training: 0.9375, testing: 0.857143, loss_tr: 0.245206, loss_t: 0.548723  
 
