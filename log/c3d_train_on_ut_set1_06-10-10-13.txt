Sat Jun 10 10:13:42 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq1, epoch0, step: 0, training: 0.3125, loss_tr: 49.6147, loss_t: 94.4641, testing: 0.166667, t2y: 0.333333
seq1, epoch0, step: 10, training: 0.0625, loss_tr: 42.0367, loss_t: 67.3932, testing: 0.166667, t2y: 0.333333
seq1, epoch0, step: 20, training: 0.0625, loss_tr: 26.4058, loss_t: 36.6867, testing: 0.166667, t2y: 0.333333
seq1, epoch0, step: 30, training: 0.1875, loss_tr: 10.4887, loss_t: 5.84333, testing: 0.166667, t2y: 0.333333
seq1, epoch0, step: 40, training: 0.0625, loss_tr: 2.16199, loss_t: 2.02794, testing: 0.166667, t2y: 0.333333
seq1, epoch0, step: 50, training: 0.3125, loss_tr: 1.81829, loss_t: 1.8571, testing: 0.166667, t2y: 0.333333
seq1, epoch0, step: 60, training: 0.0625, loss_tr: 1.81655, loss_t: 1.81375, testing: 0.166667, t2y: 0.333333
seq1, epoch0, step: 70, training: 0.25, loss_tr: 1.79933, loss_t: 1.81473, testing: 0.111111, t2y: 0.333333
seq1, epoch1, step: 80, training: 0.3125, loss_tr: 1.83294, loss_t: 1.80447, testing: 0.111111, t2y: 0.333333
seq1, epoch1, step: 90, training: 0.125, loss_tr: 1.83718, loss_t: 1.80636, testing: 0.111111, t2y: 0.333333
seq1, epoch1, step: 100, training: 0.375, loss_tr: 1.82873, loss_t: 1.8161, testing: 0.166667, t2y: 0.333333
seq1, epoch1, step: 110, training: 0.4375, loss_tr: 1.80402, loss_t: 1.8213, testing: 0.166667, t2y: 0.333333
seq1, epoch1, step: 120, training: 0.375, loss_tr: 1.76824, loss_t: 1.81913, testing: 0.166667, t2y: 0.333333
seq1, epoch1, step: 130, training: 0.3125, loss_tr: 1.75205, loss_t: 1.81364, testing: 0.166667, t2y: 0.333333
seq1, epoch1, step: 140, training: 0.25, loss_tr: 1.77727, loss_t: 1.80624, testing: 0.166667, t2y: 0.333333
seq1, epoch1, step: 150, training: 0.25, loss_tr: 1.80562, loss_t: 1.80647, testing: 0.166667, t2y: 0.333333
seq1, epoch2, step: 160, training: 0.0625, loss_tr: 1.82022, loss_t: 1.8003, testing: 0.166667, t2y: 0.333333
seq1, epoch2, step: 170, training: 0.1875, loss_tr: 1.81689, loss_t: 1.80204, testing: 0.166667, t2y: 0.333333
seq1, epoch2, step: 180, training: 0.125, loss_tr: 1.82704, loss_t: 1.80385, testing: 0.166667, t2y: 0.333333
seq1, epoch2, step: 190, training: 0.25, loss_tr: 1.80486, loss_t: 1.80253, testing: 0.166667, t2y: 0.333333
seq1, epoch2, step: 200, training: 0.1875, loss_tr: 1.81133, loss_t: 1.80088, testing: 0.166667, t2y: 0.333333
seq1, epoch2, step: 210, training: 0.125, loss_tr: 1.78357, loss_t: 1.79572, testing: 0.166667, t2y: 0.333333
seq1, epoch2, step: 220, training: 0.0625, loss_tr: 1.78603, loss_t: 1.79486, testing: 0.166667, t2y: 0.333333
seq1, epoch2, step: 230, training: 0.125, loss_tr: 1.78705, loss_t: 1.79412, testing: 0.166667, t2y: 0.333333
seq1, epoch3, step: 240, training: 0.25, loss_tr: 1.78293, loss_t: 1.79432, testing: 0.166667, t2y: 0.333333
seq1, epoch3, step: 250, training: 0.0625, loss_tr: 1.80171, loss_t: 1.79798, testing: 0.166667, t2y: 0.333333
seq1, epoch3, step: 260, training: 0.3125, loss_tr: 1.78461, loss_t: 1.79951, testing: 0.166667, t2y: 0.333333
seq1, epoch3, step: 270, training: 0.0625, loss_tr: 2.30557, loss_t: 21.2621, testing: 0.166667, t2y: 0.333333
seq1, epoch3, step: 280, training: 0.25, loss_tr: 2.29374, loss_t: 21.2573, testing: 0.166667, t2y: 0.333333
seq1, epoch3, step: 290, training: 0.1875, loss_tr: 2.30381, loss_t: 21.2567, testing: 0.166667, t2y: 0.333333
seq1, epoch3, step: 300, training: 0.125, loss_tr: 1.76793, loss_t: 1.79599, testing: 0.166667, t2y: 0.333333
seq1, epoch3, step: 310, training: 0.3125, loss_tr: 1.77255, loss_t: 1.79831, testing: 0.166667, t2y: 0.333333
seq1, epoch4, step: 320, training: 0.125, loss_tr: 1.78925, loss_t: 1.8007, testing: 0.166667, t2y: 0.333333
seq1, epoch4, step: 330, training: 0.0625, loss_tr: 1.84953, loss_t: 1.80101, testing: 0.166667, t2y: 0.333333
seq1, epoch4, step: 340, training: 0.1875, loss_tr: 1.86138, loss_t: 1.79871, testing: 0.166667, t2y: 0.333333
seq1, epoch4, step: 350, training: 0.1875, loss_tr: 1.85047, loss_t: 1.79738, testing: 0.166667, t2y: 0.333333
seq1, epoch4, step: 360, training: 0.125, loss_tr: 1.81135, loss_t: 1.79466, testing: 0.166667, t2y: 0.333333
seq1, epoch4, step: 370, training: 0, loss_tr: 1.81556, loss_t: 1.79507, testing: 0.166667, t2y: 0.333333
seq1, epoch4, step: 380, training: 0.3125, loss_tr: 1.80633, loss_t: 1.79356, testing: 0.166667, t2y: 0.333333
seq1, epoch4, step: 390, training: 0.0625, loss_tr: 1.81172, loss_t: 1.79663, testing: 0.166667, t2y: 0.333333
seq1, epoch5, step: 400, training: 0.3125, loss_tr: 1.79076, loss_t: 1.79626, testing: 0.166667, t2y: 0.333333
seq1, epoch5, step: 410, training: 0.0625, loss_tr: 1.79747, loss_t: 1.79578, testing: 0.166667, t2y: 0.333333
seq1, epoch5, step: 420, training: 0.0625, loss_tr: 1.78771, loss_t: 1.79257, testing: 0.166667, t2y: 0.333333
seq1, epoch5, step: 430, training: 0.25, loss_tr: 1.79157, loss_t: 1.79249, testing: 0.166667, t2y: 0.333333
seq1, epoch5, step: 440, training: 0.0625, loss_tr: 1.79297, loss_t: 1.79254, testing: 0.166667, t2y: 0.333333
seq1, epoch5, step: 450, training: 0, loss_tr: 1.80836, loss_t: 1.79324, testing: 0.166667, t2y: 0.333333
seq1, epoch5, step: 460, training: 0.125, loss_tr: 1.81222, loss_t: 1.79342, testing: 0.166667, t2y: 0.333333
seq1, epoch5, step: 470, training: 0.125, loss_tr: 1.81226, loss_t: 1.79317, testing: 0.166667, t2y: 0.333333
seq1, epoch6, step: 480, training: 0.25, loss_tr: 1.79662, loss_t: 1.79244, testing: 0.166667, t2y: 0.333333
seq1, epoch6, step: 490, training: 0.1875, loss_tr: 1.79171, loss_t: 1.7931, testing: 0.166667, t2y: 0.333333
seq1, epoch6, step: 500, training: 0.125, loss_tr: 1.79034, loss_t: 1.79379, testing: 0.166667, t2y: 0.333333
seq1, epoch6, step: 510, training: 0.1875, loss_tr: 1.79201, loss_t: 1.79394, testing: 0.166667, t2y: 0.333333
 
****************************************
current sequence is 2
****************************************
seq2, epoch0, step: 0, training: 0.25, loss_tr: 79.3349, loss_t: 106.361, testing: 0.166667, t2y: 0.333333
seq2, epoch0, step: 10, training: 0.125, loss_tr: 55.0097, loss_t: 71.8767, testing: 0.111111, t2y: 0.5
seq2, epoch0, step: 20, training: 0.25, loss_tr: 30.3319, loss_t: 38.6838, testing: 0.111111, t2y: 0.333333
seq2, epoch0, step: 30, training: 0, loss_tr: 4.87348, loss_t: 4.08252, testing: 0.111111, t2y: 0.333333
seq2, epoch0, step: 40, training: 0.1875, loss_tr: 3.50851, loss_t: 3.79524, testing: 0.166667, t2y: 0.333333
seq2, epoch0, step: 50, training: 0.0625, loss_tr: 3.44543, loss_t: 4.51355, testing: 0.166667, t2y: 0.333333
seq2, epoch0, step: 60, training: 0.125, loss_tr: 3.07132, loss_t: 4.2659, testing: 0.166667, t2y: 0.333333
seq2, epoch0, step: 70, training: 0, loss_tr: 2.96284, loss_t: 4.20656, testing: 0.166667, t2y: 0.333333
seq2, epoch1, step: 80, training: 0.1875, loss_tr: 1.96305, loss_t: 1.86162, testing: 0.166667, t2y: 0.333333
seq2, epoch1, step: 90, training: 0.1875, loss_tr: 1.95366, loss_t: 1.86489, testing: 0.166667, t2y: 0.333333
seq2, epoch1, step: 100, training: 0.0625, loss_tr: 1.91253, loss_t: 1.8475, testing: 0.166667, t2y: 0.333333
