Tue Jun 13 16:14:46 2017 Train the 3D-ConvNet on UT-Interaction dataset set1 from scratch! 
-------------------------------------------------------------------------
---------------------------- RUN 0 ------------------------------
-------------------------------------------------------------------------
****************************************
current sequence is 1
****************************************
seq: 1, epoch: 0, step: 0, training: 0.0625, testing: 0.0555556, loss_tr: 1.60571, loss_t: 1.69762  
seq: 1, epoch: 0, step: 10, training: 0.5, testing: 0.722222, loss_tr: 2.04665, loss_t: 1.19191  
seq: 1, epoch: 0, step: 20, training: 0.5625, testing: 0.722222, loss_tr: 1.54042, loss_t: 1.07754  
seq: 1, epoch: 0, step: 30, training: 0.625, testing: 0.722222, loss_tr: 1.20083, loss_t: 1.06988  
seq: 1, epoch: 0, step: 40, training: 0.625, testing: 0.722222, loss_tr: 1.33064, loss_t: 1.07267  
seq: 1, epoch: 0, step: 50, training: 0.75, testing: 0.722222, loss_tr: 0.960237, loss_t: 1.07014  
seq: 1, epoch: 0, step: 60, training: 0.5625, testing: 0.722222, loss_tr: 1.56165, loss_t: 1.07598  
seq: 1, epoch: 0, step: 70, training: 0.8125, testing: 0.722222, loss_tr: 0.744543, loss_t: 1.05685  
seq: 1, epoch: 0, step: 80, training: 0.6875, testing: 0.722222, loss_tr: 1.17414, loss_t: 1.05553  
seq: 1, epoch: 0, step: 90, training: 0.625, testing: 0.722222, loss_tr: 1.3733, loss_t: 1.05423  
seq: 1, epoch: 0, step: 100, training: 0.5625, testing: 0.722222, loss_tr: 1.44746, loss_t: 1.04616  
seq: 1, epoch: 0, step: 110, training: 0.75, testing: 0.722222, loss_tr: 1.03958, loss_t: 1.06692  
seq: 1, epoch: 0, step: 120, training: 0.5, testing: 0.722222, loss_tr: 1.7577, loss_t: 1.06021  
seq: 1, epoch: 0, step: 130, training: 0.75, testing: 0.722222, loss_tr: 0.977463, loss_t: 1.03843  
seq: 1, epoch: 0, step: 140, training: 0.6875, testing: 0.722222, loss_tr: 1.12088, loss_t: 1.03782  
seq: 1, epoch: 0, step: 150, training: 0.8125, testing: 0.722222, loss_tr: 0.788977, loss_t: 1.07405  
seq: 1, epoch: 0, step: 160, training: 0.5, testing: 0.722222, loss_tr: 1.57952, loss_t: 1.02949  
seq: 1, epoch: 0, step: 170, training: 0.4375, testing: 0.722222, loss_tr: 1.61479, loss_t: 1.08608  
seq: 1, epoch: 0, step: 180, training: 0.6875, testing: 0.722222, loss_tr: 1.06719, loss_t: 1.04362  
seq: 1, epoch: 0, step: 190, training: 0.5625, testing: 0.722222, loss_tr: 1.43642, loss_t: 1.031  
seq: 1, epoch: 1, step: 200, training: 0.5, testing: 0.722222, loss_tr: 1.56311, loss_t: 1.03167  
seq: 1, epoch: 1, step: 210, training: 0.5625, testing: 0.722222, loss_tr: 1.38916, loss_t: 1.0219  
seq: 1, epoch: 1, step: 220, training: 0.8125, testing: 0.722222, loss_tr: 0.768592, loss_t: 1.05703  
seq: 1, epoch: 1, step: 230, training: 0.5625, testing: 0.722222, loss_tr: 1.41161, loss_t: 1.0185  
seq: 1, epoch: 1, step: 240, training: 0.5, testing: 0.722222, loss_tr: 1.48377, loss_t: 1.05414  
seq: 1, epoch: 1, step: 250, training: 0.75, testing: 0.722222, loss_tr: 0.925947, loss_t: 1.00986  
seq: 1, epoch: 1, step: 260, training: 0.75, testing: 0.722222, loss_tr: 0.952013, loss_t: 1.0363  
seq: 1, epoch: 1, step: 270, training: 0.75, testing: 0.722222, loss_tr: 0.97341, loss_t: 1.01962  
seq: 1, epoch: 1, step: 280, training: 0.625, testing: 0.722222, loss_tr: 1.2241, loss_t: 1.00053  
seq: 1, epoch: 1, step: 290, training: 0.6875, testing: 0.722222, loss_tr: 1.02502, loss_t: 1.02067  
seq: 1, epoch: 1, step: 300, training: 0.625, testing: 0.722222, loss_tr: 1.29952, loss_t: 1.02038  
seq: 1, epoch: 1, step: 310, training: 0.625, testing: 0.722222, loss_tr: 1.21868, loss_t: 0.970714  
seq: 1, epoch: 1, step: 320, training: 0.5625, testing: 0.722222, loss_tr: 1.3315, loss_t: 0.966192  
seq: 1, epoch: 1, step: 330, training: 0.625, testing: 0.722222, loss_tr: 1.13124, loss_t: 0.950633  
seq: 1, epoch: 1, step: 340, training: 0.625, testing: 0.722222, loss_tr: 1.13507, loss_t: 0.937191  
seq: 1, epoch: 1, step: 350, training: 0.625, testing: 0.722222, loss_tr: 1.25677, loss_t: 0.917956  
seq: 1, epoch: 1, step: 360, training: 0.75, testing: 0.722222, loss_tr: 0.906335, loss_t: 0.904134  
seq: 1, epoch: 1, step: 370, training: 0.5, testing: 0.722222, loss_tr: 1.37114, loss_t: 0.874228  
seq: 1, epoch: 1, step: 380, training: 0.6875, testing: 0.722222, loss_tr: 0.957181, loss_t: 0.830672  
seq: 1, epoch: 2, step: 390, training: 0.625, testing: 0.722222, loss_tr: 1.29581, loss_t: 0.825266  
seq: 1, epoch: 2, step: 400, training: 0.4375, testing: 0.722222, loss_tr: 1.56321, loss_t: 0.772183  
seq: 1, epoch: 2, step: 410, training: 0.75, testing: 0.722222, loss_tr: 0.985148, loss_t: 0.799407  
seq: 1, epoch: 2, step: 420, training: 0.75, testing: 0.722222, loss_tr: 0.874247, loss_t: 0.748899  
seq: 1, epoch: 2, step: 430, training: 0.6875, testing: 0.777778, loss_tr: 0.886528, loss_t: 0.713762  
seq: 1, epoch: 2, step: 440, training: 0.5625, testing: 0.777778, loss_tr: 1.15869, loss_t: 0.692447  
seq: 1, epoch: 2, step: 450, training: 0.875, testing: 0.722222, loss_tr: 0.434328, loss_t: 0.685303  
seq: 1, epoch: 2, step: 460, training: 0.625, testing: 0.722222, loss_tr: 1.25646, loss_t: 0.674345  
seq: 1, epoch: 2, step: 470, training: 0.6875, testing: 0.777778, loss_tr: 1.15333, loss_t: 0.625628  
seq: 1, epoch: 2, step: 480, training: 0.6875, testing: 0.722222, loss_tr: 0.922196, loss_t: 0.619845  
seq: 1, epoch: 2, step: 490, training: 0.875, testing: 0.777778, loss_tr: 0.743296, loss_t: 0.604929  
seq: 1, epoch: 2, step: 500, training: 0.5625, testing: 0.777778, loss_tr: 0.982448, loss_t: 0.58181  
seq: 1, epoch: 2, step: 510, training: 0.6875, testing: 0.777778, loss_tr: 0.904181, loss_t: 0.575574  
seq: 1, epoch: 2, step: 520, training: 0.5625, testing: 0.777778, loss_tr: 1.36019, loss_t: 0.562292  
seq: 1, epoch: 2, step: 530, training: 0.625, testing: 0.777778, loss_tr: 1.04437, loss_t: 0.541417  
seq: 1, epoch: 2, step: 540, training: 0.5, testing: 0.777778, loss_tr: 0.951459, loss_t: 0.531257  
seq: 1, epoch: 2, step: 550, training: 0.875, testing: 0.777778, loss_tr: 0.51946, loss_t: 0.549493  
seq: 1, epoch: 2, step: 560, training: 0.625, testing: 0.777778, loss_tr: 0.940071, loss_t: 0.520222  
seq: 1, epoch: 2, step: 570, training: 0.8125, testing: 0.777778, loss_tr: 0.581104, loss_t: 0.50147  
seq: 1, epoch: 2, step: 580, training: 0.8125, testing: 0.777778, loss_tr: 0.639156, loss_t: 0.482508  
seq: 1, epoch: 3, step: 590, training: 0.6875, testing: 0.777778, loss_tr: 1.04114, loss_t: 0.474563  
seq: 1, epoch: 3, step: 600, training: 0.4375, testing: 0.777778, loss_tr: 1.31507, loss_t: 0.472128  
seq: 1, epoch: 3, step: 610, training: 0.875, testing: 0.888889, loss_tr: 0.493886, loss_t: 0.469406  
seq: 1, epoch: 3, step: 620, training: 0.875, testing: 0.833333, loss_tr: 0.358204, loss_t: 0.479715  
seq: 1, epoch: 3, step: 630, training: 0.75, testing: 0.833333, loss_tr: 0.590204, loss_t: 0.476363  
seq: 1, epoch: 3, step: 640, training: 0.8125, testing: 0.833333, loss_tr: 0.601772, loss_t: 0.4905  
seq: 1, epoch: 3, step: 650, training: 1, testing: 0.777778, loss_tr: 0.172501, loss_t: 0.453599  
seq: 1, epoch: 3, step: 660, training: 0.75, testing: 0.833333, loss_tr: 1.02356, loss_t: 0.42945  
seq: 1, epoch: 3, step: 670, training: 0.75, testing: 0.833333, loss_tr: 0.445344, loss_t: 0.433535  
seq: 1, epoch: 3, step: 680, training: 0.8125, testing: 0.833333, loss_tr: 0.631466, loss_t: 0.463375  
seq: 1, epoch: 3, step: 690, training: 0.8125, testing: 0.833333, loss_tr: 0.487174, loss_t: 0.456901  
seq: 1, epoch: 3, step: 700, training: 0.8125, testing: 0.833333, loss_tr: 0.54457, loss_t: 0.441441  
seq: 1, epoch: 3, step: 710, training: 0.6875, testing: 0.888889, loss_tr: 0.686125, loss_t: 0.388144  
seq: 1, epoch: 3, step: 720, training: 0.75, testing: 0.888889, loss_tr: 0.852867, loss_t: 0.442786  
seq: 1, epoch: 3, step: 730, training: 0.875, testing: 0.833333, loss_tr: 0.627933, loss_t: 0.449147  
seq: 1, epoch: 3, step: 740, training: 0.6875, testing: 0.833333, loss_tr: 0.629086, loss_t: 0.450819  
seq: 1, epoch: 3, step: 750, training: 0.6875, testing: 0.777778, loss_tr: 0.973447, loss_t: 0.41734  
seq: 1, epoch: 3, step: 760, training: 0.8125, testing: 0.833333, loss_tr: 0.614866, loss_t: 0.367788  
seq: 1, epoch: 3, step: 770, training: 0.8125, testing: 0.833333, loss_tr: 0.439948, loss_t: 0.434781  
seq: 1, epoch: 4, step: 780, training: 0.625, testing: 0.833333, loss_tr: 0.881038, loss_t: 0.424294  
seq: 1, epoch: 4, step: 790, training: 0.875, testing: 0.888889, loss_tr: 0.590656, loss_t: 0.464128  
seq: 1, epoch: 4, step: 800, training: 0.6875, testing: 0.888889, loss_tr: 1.04955, loss_t: 0.416508  
seq: 1, epoch: 4, step: 810, training: 0.8125, testing: 0.888889, loss_tr: 0.576223, loss_t: 0.380782  
seq: 1, epoch: 4, step: 820, training: 0.75, testing: 0.888889, loss_tr: 0.50332, loss_t: 0.42709  
seq: 1, epoch: 4, step: 830, training: 0.6875, testing: 0.833333, loss_tr: 0.630399, loss_t: 0.414356  
seq: 1, epoch: 4, step: 840, training: 0.9375, testing: 0.888889, loss_tr: 0.397994, loss_t: 0.387394  
seq: 1, epoch: 4, step: 850, training: 0.75, testing: 0.888889, loss_tr: 0.704889, loss_t: 0.392932  
seq: 1, epoch: 4, step: 860, training: 0.75, testing: 0.777778, loss_tr: 0.692995, loss_t: 0.405041  
seq: 1, epoch: 4, step: 870, training: 0.75, testing: 0.777778, loss_tr: 0.6278, loss_t: 0.410409  
seq: 1, epoch: 4, step: 880, training: 0.75, testing: 0.888889, loss_tr: 0.790128, loss_t: 0.417893  
seq: 1, epoch: 4, step: 890, training: 0.8125, testing: 0.888889, loss_tr: 0.465988, loss_t: 0.417486  
seq: 1, epoch: 4, step: 900, training: 0.8125, testing: 0.888889, loss_tr: 0.388235, loss_t: 0.384947  
seq: 1, epoch: 4, step: 910, training: 0.875, testing: 0.888889, loss_tr: 0.417054, loss_t: 0.419324  
seq: 1, epoch: 4, step: 920, training: 0.8125, testing: 0.888889, loss_tr: 0.44684, loss_t: 0.372645  
seq: 1, epoch: 4, step: 930, training: 0.6875, testing: 0.833333, loss_tr: 0.615578, loss_t: 0.351419  
seq: 1, epoch: 4, step: 940, training: 0.875, testing: 0.833333, loss_tr: 0.346545, loss_t: 0.340089  
seq: 1, epoch: 4, step: 950, training: 0.8125, testing: 0.888889, loss_tr: 0.375304, loss_t: 0.34961  
seq: 1, epoch: 4, step: 960, training: 0.8125, testing: 0.888889, loss_tr: 0.584121, loss_t: 0.381818  
seq: 1, epoch: 5, step: 970, training: 0.875, testing: 0.833333, loss_tr: 0.383415, loss_t: 0.375855  
seq: 1, epoch: 5, step: 980, training: 0.875, testing: 0.833333, loss_tr: 0.386294, loss_t: 0.31446  
seq: 1, epoch: 5, step: 990, training: 0.8125, testing: 0.888889, loss_tr: 0.729096, loss_t: 0.357501  
seq: 1, epoch: 5, step: 1000, training: 0.625, testing: 0.888889, loss_tr: 1.00385, loss_t: 0.394044  
 
